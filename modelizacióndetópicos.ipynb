{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recuperación de Información\n",
    "\n",
    "Nombre: Wilmer Rivas\n",
    "Fecha: 14/01/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.6-py3-none-any.whl (51 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from kagglehub) (24.2)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, tqdm, requests, kagglehub\n",
      "Successfully installed certifi-2024.12.14 charset-normalizer-3.4.1 idna-3.10 kagglehub-0.3.6 requests-2.32.3 tqdm-4.67.1 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/rajneesh231/lex-fridman-podcast-transcript?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12.2M/12.2M [00:02<00:00, 4.65MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\USER\\.cache\\kagglehub\\datasets\\rajneesh231\\lex-fridman-podcast-transcript\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"rajneesh231/lex-fridman-podcast-transcript\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id            guest                    title  \\\n",
      "0   1      Max Tegmark                 Life 3.0   \n",
      "1   2    Christof Koch            Consciousness   \n",
      "2   3    Steven Pinker  AI in the Age of Reason   \n",
      "3   4    Yoshua Bengio            Deep Learning   \n",
      "4   5  Vladimir Vapnik     Statistical Learning   \n",
      "\n",
      "                                                text  \n",
      "0  As part of MIT course 6S099, Artificial Genera...  \n",
      "1  As part of MIT course 6S099 on artificial gene...  \n",
      "2  You've studied the human mind, cognition, lang...  \n",
      "3  What difference between biological neural netw...  \n",
      "4  The following is a conversation with Vladimir ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Cargar el archivo CSV\n",
    "file_path = r'C:\\Users\\USER\\.cache\\kagglehub\\datasets\\rajneesh231\\lex-fridman-podcast-transcript\\versions\\2\\podcastdata_dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T12:27:08.631537Z",
     "iopub.status.busy": "2025-01-14T12:27:08.631210Z",
     "iopub.status.idle": "2025-01-14T12:27:08.648230Z",
     "shell.execute_reply": "2025-01-14T12:27:08.646896Z",
     "shell.execute_reply.started": "2025-01-14T12:27:08.631512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de episodios únicos sin espacios es: 317\n"
     ]
    }
   ],
   "source": [
    "# Limpiar la columna 'title' eliminando espacios iniciales y finales\n",
    "data['title'] = data['title'].str.strip()\n",
    "\n",
    "# Contar títulos únicos de episodios\n",
    "unique_titles = data['title'].nunique()\n",
    "print(f\"El número de episodios únicos sin espacios es: {unique_titles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T12:34:13.269694Z",
     "iopub.status.busy": "2025-01-14T12:34:13.269342Z",
     "iopub.status.idle": "2025-01-14T12:34:13.687475Z",
     "shell.execute_reply": "2025-01-14T12:34:13.686296Z",
     "shell.execute_reply.started": "2025-01-14T12:34:13.269666Z"
    }
   },
   "outputs": [],
   "source": [
    "# Contar palabras en la columna 'text'\n",
    "# Agregar una nueva columna llamada 'word_count' con el conteo de palabras\n",
    "data['word_count'] = data['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# # Mostrar los episodios con su conteo de palabras\n",
    "# for index, row in data.iterrows():\n",
    "#     print(f\"Episodio {row['id']}: {row['word_count']} palabras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T12:34:14.414734Z",
     "iopub.status.busy": "2025-01-14T12:34:14.414358Z",
     "iopub.status.idle": "2025-01-14T12:34:14.715383Z",
     "shell.execute_reply": "2025-01-14T12:34:14.713475Z",
     "shell.execute_reply.started": "2025-01-14T12:34:14.414703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 1: 13424 palabras, 744 oraciones\n",
      "Episodio 2: 10217 palabras, 606 oraciones\n",
      "Episodio 3: 5989 palabras, 335 oraciones\n",
      "Episodio 4: 5993 palabras, 359 oraciones\n",
      "Episodio 5: 6374 palabras, 563 oraciones\n",
      "Episodio 6: 11219 palabras, 514 oraciones\n",
      "Episodio 7: 17372 palabras, 1395 oraciones\n",
      "Episodio 8: 5473 palabras, 324 oraciones\n",
      "Episodio 9: 12453 palabras, 706 oraciones\n",
      "Episodio 10: 7374 palabras, 434 oraciones\n",
      "Episodio 11: 10667 palabras, 496 oraciones\n",
      "Episodio 12: 10608 palabras, 692 oraciones\n",
      "Episodio 13: 9799 palabras, 670 oraciones\n",
      "Episodio 14: 10702 palabras, 549 oraciones\n",
      "Episodio 14: 10702 palabras, 549 oraciones\n",
      "Episodio 15: 10277 palabras, 689 oraciones\n",
      "Episodio 16: 13059 palabras, 795 oraciones\n",
      "Episodio 17: 16251 palabras, 872 oraciones\n",
      "Episodio 18: 5118 palabras, 278 oraciones\n",
      "Episodio 19: 11669 palabras, 564 oraciones\n",
      "Episodio 20: 17893 palabras, 1063 oraciones\n",
      "Episodio 21: 13054 palabras, 877 oraciones\n",
      "Episodio 22: 11890 palabras, 779 oraciones\n",
      "Episodio 23: 11960 palabras, 635 oraciones\n",
      "Episodio 24: 9726 palabras, 625 oraciones\n",
      "Episodio 25: 24567 palabras, 1771 oraciones\n",
      "Episodio 26: 6008 palabras, 383 oraciones\n",
      "Episodio 27: 11906 palabras, 602 oraciones\n",
      "Episodio 28: 6834 palabras, 362 oraciones\n",
      "Episodio 29: 18645 palabras, 1276 oraciones\n",
      "Episodio 30: 8975 palabras, 426 oraciones\n",
      "Episodio 31: 21348 palabras, 1921 oraciones\n",
      "Episodio 32: 8787 palabras, 515 oraciones\n",
      "Episodio 33: 10864 palabras, 604 oraciones\n",
      "Episodio 34: 8132 palabras, 723 oraciones\n",
      "Episodio 35: 16772 palabras, 1023 oraciones\n",
      "Episodio 36: 12577 palabras, 832 oraciones\n",
      "Episodio 37: 8693 palabras, 577 oraciones\n",
      "Episodio 38: 17681 palabras, 1168 oraciones\n",
      "Episodio 39: 4928 palabras, 275 oraciones\n",
      "Episodio 40: 12279 palabras, 639 oraciones\n",
      "Episodio 41: 8318 palabras, 657 oraciones\n",
      "Episodio 42: 10026 palabras, 601 oraciones\n",
      "Episodio 43: 15852 palabras, 968 oraciones\n",
      "Episodio 44: 23584 palabras, 1492 oraciones\n",
      "Episodio 45: 9089 palabras, 750 oraciones\n",
      "Episodio 46: 8670 palabras, 589 oraciones\n",
      "Episodio 47: 15842 palabras, 984 oraciones\n",
      "Episodio 48: 14011 palabras, 1062 oraciones\n",
      "Episodio 49: 5643 palabras, 371 oraciones\n",
      "Episodio 50: 17955 palabras, 660 oraciones\n",
      "Episodio 51: 7741 palabras, 527 oraciones\n",
      "Episodio 52: 6648 palabras, 533 oraciones\n",
      "Episodio 53: 4956 palabras, 327 oraciones\n",
      "Episodio 54: 14098 palabras, 830 oraciones\n",
      "Episodio 55: 14452 palabras, 905 oraciones\n",
      "Episodio 56: 10616 palabras, 1000 oraciones\n",
      "Episodio 57: 17832 palabras, 1062 oraciones\n",
      "Episodio 58: 9409 palabras, 570 oraciones\n",
      "Episodio 59: 13804 palabras, 977 oraciones\n",
      "Episodio 60: 15344 palabras, 998 oraciones\n",
      "Episodio 61: 15756 palabras, 1010 oraciones\n",
      "Episodio 62: 14289 palabras, 881 oraciones\n",
      "Episodio 63: 12998 palabras, 789 oraciones\n",
      "Episodio 64: 11573 palabras, 669 oraciones\n",
      "Episodio 65: 10641 palabras, 688 oraciones\n",
      "Episodio 66: 15856 palabras, 1086 oraciones\n",
      "Episodio 67: 8875 palabras, 547 oraciones\n",
      "Episodio 68: 14529 palabras, 809 oraciones\n",
      "Episodio 69: 15916 palabras, 968 oraciones\n",
      "Episodio 70: 14880 palabras, 1199 oraciones\n",
      "Episodio 71: 12310 palabras, 1176 oraciones\n",
      "Episodio 72: 15162 palabras, 790 oraciones\n",
      "Episodio 73: 15975 palabras, 529 oraciones\n",
      "Episodio 74: 21229 palabras, 1331 oraciones\n",
      "Episodio 75: 15947 palabras, 1078 oraciones\n",
      "Episodio 76: 9386 palabras, 564 oraciones\n",
      "Episodio 77: 11018 palabras, 673 oraciones\n",
      "Episodio 78: 9493 palabras, 469 oraciones\n",
      "Episodio 79: 9731 palabras, 671 oraciones\n",
      "Episodio 80: 15457 palabras, 144 oraciones\n",
      "Episodio 81: 16416 palabras, 915 oraciones\n",
      "Episodio 82: 6478 palabras, 415 oraciones\n",
      "Episodio 83: 18076 palabras, 866 oraciones\n",
      "Episodio 84: 14018 palabras, 760 oraciones\n",
      "Episodio 85: 14522 palabras, 1077 oraciones\n",
      "Episodio 86: 17477 palabras, 831 oraciones\n",
      "Episodio 87: 10303 palabras, 637 oraciones\n",
      "Episodio 88: 27377 palabras, 1945 oraciones\n",
      "Episodio 89: 33770 palabras, 1946 oraciones\n",
      "Episodio 90: 15308 palabras, 1006 oraciones\n",
      "Episodio 91: 7650 palabras, 480 oraciones\n",
      "Episodio 92: 18639 palabras, 1097 oraciones\n",
      "Episodio 93: 10815 palabras, 510 oraciones\n",
      "Episodio 94: 16293 palabras, 1087 oraciones\n",
      "Episodio 95: 19376 palabras, 1196 oraciones\n",
      "Episodio 96: 8981 palabras, 593 oraciones\n",
      "Episodio 97: 15678 palabras, 827 oraciones\n",
      "Episodio 98: 11606 palabras, 782 oraciones\n",
      "Episodio 99: 12699 palabras, 662 oraciones\n",
      "Episodio 101: 31589 palabras, 2092 oraciones\n",
      "Episodio 102: 13228 palabras, 901 oraciones\n",
      "Episodio 103: 39011 palabras, 2234 oraciones\n",
      "Episodio 104: 18087 palabras, 1103 oraciones\n",
      "Episodio 105: 10451 palabras, 665 oraciones\n",
      "Episodio 106: 17393 palabras, 971 oraciones\n",
      "Episodio 107: 10642 palabras, 490 oraciones\n",
      "Episodio 108: 17258 palabras, 790 oraciones\n",
      "Episodio 109: 17554 palabras, 1136 oraciones\n",
      "Episodio 110: 14144 palabras, 880 oraciones\n",
      "Episodio 111: 15667 palabras, 887 oraciones\n",
      "Episodio 112: 17967 palabras, 306 oraciones\n",
      "Episodio 113: 24109 palabras, 1587 oraciones\n",
      "Episodio 114: 26267 palabras, 1664 oraciones\n",
      "Episodio 115: 19044 palabras, 1509 oraciones\n",
      "Episodio 116: 17975 palabras, 1216 oraciones\n",
      "Episodio 117: 23286 palabras, 1552 oraciones\n",
      "Episodio 118: 24645 palabras, 1310 oraciones\n",
      "Episodio 119: 18379 palabras, 1110 oraciones\n",
      "Episodio 120: 22394 palabras, 1494 oraciones\n",
      "Episodio 121: 29646 palabras, 1752 oraciones\n",
      "Episodio 122: 48906 palabras, 2968 oraciones\n",
      "Episodio 123: 21171 palabras, 1514 oraciones\n",
      "Episodio 124: 45903 palabras, 2786 oraciones\n",
      "Episodio 125: 45364 palabras, 2888 oraciones\n",
      "Episodio 126: 12885 palabras, 981 oraciones\n",
      "Episodio 127: 13645 palabras, 1084 oraciones\n",
      "Episodio 128: 35060 palabras, 2925 oraciones\n",
      "Episodio 129: 19648 palabras, 1242 oraciones\n",
      "Episodio 130: 18819 palabras, 1120 oraciones\n",
      "Episodio 131: 29399 palabras, 1965 oraciones\n",
      "Episodio 132: 31272 palabras, 2764 oraciones\n",
      "Episodio 133: 23879 palabras, 1416 oraciones\n",
      "Episodio 134: 27221 palabras, 2207 oraciones\n",
      "Episodio 135: 27400 palabras, 1930 oraciones\n",
      "Episodio 136: 33932 palabras, 1920 oraciones\n",
      "Episodio 137: 24739 palabras, 1346 oraciones\n",
      "Episodio 138: 27433 palabras, 2121 oraciones\n",
      "Episodio 139: 26864 palabras, 1535 oraciones\n",
      "Episodio 140: 20581 palabras, 1310 oraciones\n",
      "Episodio 141: 17964 palabras, 1072 oraciones\n",
      "Episodio 142: 20371 palabras, 1375 oraciones\n",
      "Episodio 143: 30182 palabras, 2018 oraciones\n",
      "Episodio 144: 20517 palabras, 1398 oraciones\n",
      "Episodio 145: 35135 palabras, 1785 oraciones\n",
      "Episodio 146: 22220 palabras, 1308 oraciones\n",
      "Episodio 147: 24391 palabras, 1309 oraciones\n",
      "Episodio 148: 23241 palabras, 1913 oraciones\n",
      "Episodio 149: 27261 palabras, 2052 oraciones\n",
      "Episodio 150: 30330 palabras, 2349 oraciones\n",
      "Episodio 151: 15240 palabras, 1072 oraciones\n",
      "Episodio 152: 11385 palabras, 865 oraciones\n",
      "Episodio 153: 17516 palabras, 1110 oraciones\n",
      "Episodio 154: 25867 palabras, 1688 oraciones\n",
      "Episodio 155: 29848 palabras, 1704 oraciones\n",
      "Episodio 156: 26838 palabras, 2069 oraciones\n",
      "Episodio 157: 14061 palabras, 863 oraciones\n",
      "Episodio 158: 13451 palabras, 725 oraciones\n",
      "Episodio 159: 17509 palabras, 1204 oraciones\n",
      "Episodio 160: 33451 palabras, 2292 oraciones\n",
      "Episodio 161: 25499 palabras, 1826 oraciones\n",
      "Episodio 162: 27132 palabras, 2194 oraciones\n",
      "Episodio 163: 25043 palabras, 1661 oraciones\n",
      "Episodio 164: 30198 palabras, 1900 oraciones\n",
      "Episodio 165: 21467 palabras, 1437 oraciones\n",
      "Episodio 166: 35297 palabras, 2379 oraciones\n",
      "Episodio 167: 33060 palabras, 2398 oraciones\n",
      "Episodio 168: 16440 palabras, 1155 oraciones\n",
      "Episodio 169: 34727 palabras, 2488 oraciones\n",
      "Episodio 170: 13746 palabras, 725 oraciones\n",
      "Episodio 171: 34033 palabras, 952 oraciones\n",
      "Episodio 172: 24131 palabras, 1759 oraciones\n",
      "Episodio 173: 22696 palabras, 1495 oraciones\n",
      "Episodio 174: 21447 palabras, 1635 oraciones\n",
      "Episodio 175: 21053 palabras, 1667 oraciones\n",
      "Episodio 176: 37199 palabras, 2284 oraciones\n",
      "Episodio 177: 18471 palabras, 1139 oraciones\n",
      "Episodio 178: 50109 palabras, 4255 oraciones\n",
      "Episodio 179: 26659 palabras, 1715 oraciones\n",
      "Episodio 180: 22038 palabras, 1475 oraciones\n",
      "Episodio 181: 29455 palabras, 1546 oraciones\n",
      "Episodio 182: 32537 palabras, 2182 oraciones\n",
      "Episodio 183: 24650 palabras, 1583 oraciones\n",
      "Episodio 184: 18780 palabras, 1130 oraciones\n",
      "Episodio 185: 29729 palabras, 1536 oraciones\n",
      "Episodio 186: 23825 palabras, 1415 oraciones\n",
      "Episodio 187: 18307 palabras, 1004 oraciones\n",
      "Episodio 188: 30736 palabras, 1615 oraciones\n",
      "Episodio 189: 17456 palabras, 1188 oraciones\n",
      "Episodio 190: 29760 palabras, 1893 oraciones\n",
      "Episodio 191: 41584 palabras, 1984 oraciones\n",
      "Episodio 192: 59475 palabras, 3883 oraciones\n",
      "Episodio 193: 29525 palabras, 1387 oraciones\n",
      "Episodio 194: 31006 palabras, 1680 oraciones\n",
      "Episodio 195: 18766 palabras, 1458 oraciones\n",
      "Episodio 196: 19146 palabras, 1735 oraciones\n",
      "Episodio 197: 18731 palabras, 1324 oraciones\n",
      "Episodio 198: 21020 palabras, 1319 oraciones\n",
      "Episodio 199: 23444 palabras, 2000 oraciones\n",
      "Episodio 200: 28941 palabras, 1792 oraciones\n",
      "Episodio 201: 23977 palabras, 1448 oraciones\n",
      "Episodio 202: 24315 palabras, 1368 oraciones\n",
      "Episodio 203: 18629 palabras, 1175 oraciones\n",
      "Episodio 204: 23707 palabras, 1647 oraciones\n",
      "Episodio 205: 37679 palabras, 1288 oraciones\n",
      "Episodio 206: 28576 palabras, 1664 oraciones\n",
      "Episodio 208: 25732 palabras, 2043 oraciones\n",
      "Episodio 209: 30092 palabras, 881 oraciones\n",
      "Episodio 210: 25864 palabras, 1552 oraciones\n",
      "Episodio 211: 17150 palabras, 1026 oraciones\n",
      "Episodio 212: 31697 palabras, 1930 oraciones\n",
      "Episodio 213: 20387 palabras, 1677 oraciones\n",
      "Episodio 214: 15390 palabras, 1034 oraciones\n",
      "Episodio 215: 27355 palabras, 1569 oraciones\n",
      "Episodio 216: 34207 palabras, 2620 oraciones\n",
      "Episodio 217: 21938 palabras, 1585 oraciones\n",
      "Episodio 218: 18285 palabras, 1140 oraciones\n",
      "Episodio 219: 18633 palabras, 1591 oraciones\n",
      "Episodio 220: 28456 palabras, 2030 oraciones\n",
      "Episodio 221: 25888 palabras, 1320 oraciones\n",
      "Episodio 222: 18789 palabras, 993 oraciones\n",
      "Episodio 223: 37509 palabras, 3198 oraciones\n",
      "Episodio 224: 36502 palabras, 2755 oraciones\n",
      "Episodio 225: 28319 palabras, 1616 oraciones\n",
      "Episodio 226: 14648 palabras, 997 oraciones\n",
      "Episodio 227: 25917 palabras, 1598 oraciones\n",
      "Episodio 228: 13134 palabras, 1210 oraciones\n",
      "Episodio 229: 21000 palabras, 1218 oraciones\n",
      "Episodio 230: 44613 palabras, 3587 oraciones\n",
      "Episodio 231: 27355 palabras, 1709 oraciones\n",
      "Episodio 232: 16728 palabras, 870 oraciones\n",
      "Episodio 233: 10769 palabras, 770 oraciones\n",
      "Episodio 234: 39990 palabras, 2274 oraciones\n",
      "Episodio 235: 17632 palabras, 1155 oraciones\n",
      "Episodio 236: 25550 palabras, 1797 oraciones\n",
      "Episodio 237: 32110 palabras, 1843 oraciones\n",
      "Episodio 238: 13584 palabras, 871 oraciones\n",
      "Episodio 239: 23649 palabras, 1358 oraciones\n",
      "Episodio 240: 21676 palabras, 1291 oraciones\n",
      "Episodio 241: 34606 palabras, 1868 oraciones\n",
      "Episodio 242: 28083 palabras, 2273 oraciones\n",
      "Episodio 243: 28924 palabras, 1983 oraciones\n",
      "Episodio 244: 27394 palabras, 1608 oraciones\n",
      "Episodio 245: 9629 palabras, 770 oraciones\n",
      "Episodio 246: 22470 palabras, 960 oraciones\n",
      "Episodio 247: 45109 palabras, 2655 oraciones\n",
      "Episodio 248: 21087 palabras, 1242 oraciones\n",
      "Episodio 249: 10495 palabras, 723 oraciones\n",
      "Episodio 250: 30100 palabras, 1838 oraciones\n",
      "Episodio 251: 12335 palabras, 712 oraciones\n",
      "Episodio 252: 22141 palabras, 1538 oraciones\n",
      "Episodio 253: 35098 palabras, 3039 oraciones\n",
      "Episodio 254: 22531 palabras, 1363 oraciones\n",
      "Episodio 255: 20175 palabras, 2000 oraciones\n",
      "Episodio 256: 28837 palabras, 1683 oraciones\n",
      "Episodio 257: 44312 palabras, 3244 oraciones\n",
      "Episodio 258: 27053 palabras, 1663 oraciones\n",
      "Episodio 259: 20326 palabras, 1244 oraciones\n",
      "Episodio 260: 31351 palabras, 732 oraciones\n",
      "Episodio 261: 25238 palabras, 1544 oraciones\n",
      "Episodio 262: 15265 palabras, 1008 oraciones\n",
      "Episodio 263: 19219 palabras, 1205 oraciones\n",
      "Episodio 264: 31746 palabras, 2156 oraciones\n",
      "Episodio 265: 19971 palabras, 1891 oraciones\n",
      "Episodio 266: 18300 palabras, 1193 oraciones\n",
      "Episodio 267: 20696 palabras, 1065 oraciones\n",
      "Episodio 269: 41740 palabras, 2870 oraciones\n",
      "Episodio 270: 20979 palabras, 1353 oraciones\n",
      "Episodio 271: 19050 palabras, 1143 oraciones\n",
      "Episodio 272: 39062 palabras, 3654 oraciones\n",
      "Episodio 273: 28685 palabras, 1725 oraciones\n",
      "Episodio 274: 30637 palabras, 1850 oraciones\n",
      "Episodio 275: 15304 palabras, 326 oraciones\n",
      "Episodio 276: 34869 palabras, 2355 oraciones\n",
      "Episodio 277: 36931 palabras, 2639 oraciones\n",
      "Episodio 278: 22231 palabras, 1590 oraciones\n",
      "Episodio 279: 43876 palabras, 3189 oraciones\n",
      "Episodio 280: 10843 palabras, 804 oraciones\n",
      "Episodio 281: 21712 palabras, 1589 oraciones\n",
      "Episodio 284: 44615 palabras, 2731 oraciones\n",
      "Episodio 285: 30243 palabras, 1835 oraciones\n",
      "Episodio 286: 17938 palabras, 1188 oraciones\n",
      "Episodio 288: 40695 palabras, 3298 oraciones\n",
      "Episodio 289: 21917 palabras, 1320 oraciones\n",
      "Episodio 290: 22803 palabras, 1585 oraciones\n",
      "Episodio 292: 42925 palabras, 2928 oraciones\n",
      "Episodio 293: 30533 palabras, 2020 oraciones\n",
      "Episodio 294: 28493 palabras, 2100 oraciones\n",
      "Episodio 295: 24873 palabras, 1877 oraciones\n",
      "Episodio 296: 24993 palabras, 1638 oraciones\n",
      "Episodio 297: 27571 palabras, 1600 oraciones\n",
      "Episodio 298: 19943 palabras, 1360 oraciones\n",
      "Episodio 299: 23448 palabras, 1277 oraciones\n",
      "Episodio 300: 16887 palabras, 1523 oraciones\n",
      "Episodio 301: 31340 palabras, 2229 oraciones\n",
      "Episodio 302: 21826 palabras, 1422 oraciones\n",
      "Episodio 303: 35054 palabras, 2720 oraciones\n",
      "Episodio 304: 19223 palabras, 1535 oraciones\n",
      "Episodio 305: 19910 palabras, 1164 oraciones\n",
      "Episodio 306: 20334 palabras, 1210 oraciones\n",
      "Episodio 307: 28214 palabras, 1783 oraciones\n",
      "Episodio 308: 27520 palabras, 1702 oraciones\n",
      "Episodio 309: 57667 palabras, 2939 oraciones\n",
      "Episodio 310: 38316 palabras, 2558 oraciones\n",
      "Episodio 311: 35145 palabras, 2433 oraciones\n",
      "Episodio 312: 32437 palabras, 2387 oraciones\n",
      "Episodio 313: 29793 palabras, 2695 oraciones\n",
      "Episodio 314: 37866 palabras, 2531 oraciones\n",
      "Episodio 315: 23159 palabras, 1793 oraciones\n",
      "Episodio 316: 5069 palabras, 445 oraciones\n",
      "Episodio 317: 28369 palabras, 1852 oraciones\n",
      "Episodio 318: 36564 palabras, 2455 oraciones\n",
      "Episodio 319: 28794 palabras, 2068 oraciones\n",
      "Episodio 320: 19902 palabras, 1157 oraciones\n",
      "Episodio 321: 12807 palabras, 964 oraciones\n",
      "Episodio 322: 26034 palabras, 2000 oraciones\n",
      "Episodio 323: 25255 palabras, 2081 oraciones\n",
      "Episodio 324: 29911 palabras, 2143 oraciones\n",
      "Episodio 325: 33714 palabras, 2097 oraciones\n"
     ]
    }
   ],
   "source": [
    "# Contar oraciones en la columna 'text'\n",
    "# Consideramos oraciones separadas por '.', '!', '?'\n",
    "data['sentence_count'] = data['text'].apply(lambda x: len([s for s in str(x).split('.') if s.strip()]) +\n",
    "                                                        len([s for s in str(x).split('!') if s.strip()]) +\n",
    "                                                        len([s for s in str(x).split('?') if s.strip()]) -\n",
    "                                                        len([s for s in str(x).split('!?') if s.strip()]) -\n",
    "                                                        len([s for s in str(x).split('?!') if s.strip()]))\n",
    "\n",
    "# Mostrar los episodios con conteos de palabras y oraciones\n",
    "for index, row in data.iterrows():\n",
    "    print(f\"Episodio {row['id']}: {row['word_count']} palabras, {row['sentence_count']} oraciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltkNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Collecting click\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: regex, click, nltk\n",
      "Successfully installed click-8.1.8 nltk-3.9.1 regex-2024.11.6\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T12:42:18.134646Z",
     "iopub.status.busy": "2025-01-14T12:42:18.134197Z",
     "iopub.status.idle": "2025-01-14T12:42:31.181047Z",
     "shell.execute_reply": "2025-01-14T12:42:31.180060Z",
     "shell.execute_reply.started": "2025-01-14T12:42:18.134613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 1: 13424 palabras, 737 oraciones\n",
      "Episodio 2: 10217 palabras, 603 oraciones\n",
      "Episodio 3: 5989 palabras, 325 oraciones\n",
      "Episodio 4: 5993 palabras, 359 oraciones\n",
      "Episodio 5: 6374 palabras, 551 oraciones\n",
      "Episodio 6: 11219 palabras, 497 oraciones\n",
      "Episodio 7: 17372 palabras, 1386 oraciones\n",
      "Episodio 8: 5473 palabras, 324 oraciones\n",
      "Episodio 9: 12453 palabras, 701 oraciones\n",
      "Episodio 10: 7374 palabras, 430 oraciones\n",
      "Episodio 11: 10667 palabras, 492 oraciones\n",
      "Episodio 12: 10608 palabras, 689 oraciones\n",
      "Episodio 13: 9799 palabras, 665 oraciones\n",
      "Episodio 14: 10702 palabras, 542 oraciones\n",
      "Episodio 14: 10702 palabras, 542 oraciones\n",
      "Episodio 15: 10277 palabras, 683 oraciones\n",
      "Episodio 16: 13059 palabras, 788 oraciones\n",
      "Episodio 17: 16251 palabras, 871 oraciones\n",
      "Episodio 18: 5118 palabras, 277 oraciones\n",
      "Episodio 19: 11669 palabras, 550 oraciones\n",
      "Episodio 20: 17893 palabras, 1055 oraciones\n",
      "Episodio 21: 13054 palabras, 858 oraciones\n",
      "Episodio 22: 11890 palabras, 741 oraciones\n",
      "Episodio 23: 11960 palabras, 630 oraciones\n",
      "Episodio 24: 9726 palabras, 621 oraciones\n",
      "Episodio 25: 24567 palabras, 1759 oraciones\n",
      "Episodio 26: 6008 palabras, 382 oraciones\n",
      "Episodio 27: 11906 palabras, 597 oraciones\n",
      "Episodio 28: 6834 palabras, 359 oraciones\n",
      "Episodio 29: 18645 palabras, 1266 oraciones\n",
      "Episodio 30: 8975 palabras, 424 oraciones\n",
      "Episodio 31: 21348 palabras, 1893 oraciones\n",
      "Episodio 32: 8787 palabras, 514 oraciones\n",
      "Episodio 33: 10864 palabras, 600 oraciones\n",
      "Episodio 34: 8132 palabras, 719 oraciones\n",
      "Episodio 35: 16772 palabras, 997 oraciones\n",
      "Episodio 36: 12577 palabras, 828 oraciones\n",
      "Episodio 37: 8693 palabras, 573 oraciones\n",
      "Episodio 38: 17681 palabras, 1155 oraciones\n",
      "Episodio 39: 4928 palabras, 272 oraciones\n",
      "Episodio 40: 12279 palabras, 632 oraciones\n",
      "Episodio 41: 8318 palabras, 653 oraciones\n",
      "Episodio 42: 10026 palabras, 597 oraciones\n",
      "Episodio 43: 15852 palabras, 962 oraciones\n",
      "Episodio 44: 23584 palabras, 1490 oraciones\n",
      "Episodio 45: 9089 palabras, 744 oraciones\n",
      "Episodio 46: 8670 palabras, 578 oraciones\n",
      "Episodio 47: 15842 palabras, 979 oraciones\n",
      "Episodio 48: 14011 palabras, 1049 oraciones\n",
      "Episodio 49: 5643 palabras, 367 oraciones\n",
      "Episodio 50: 17955 palabras, 654 oraciones\n",
      "Episodio 51: 7741 palabras, 522 oraciones\n",
      "Episodio 52: 6648 palabras, 529 oraciones\n",
      "Episodio 53: 4956 palabras, 326 oraciones\n",
      "Episodio 54: 14098 palabras, 827 oraciones\n",
      "Episodio 55: 14452 palabras, 901 oraciones\n",
      "Episodio 56: 10616 palabras, 997 oraciones\n",
      "Episodio 57: 17832 palabras, 1055 oraciones\n",
      "Episodio 58: 9409 palabras, 565 oraciones\n",
      "Episodio 59: 13804 palabras, 968 oraciones\n",
      "Episodio 60: 15344 palabras, 986 oraciones\n",
      "Episodio 61: 15756 palabras, 1007 oraciones\n",
      "Episodio 62: 14289 palabras, 866 oraciones\n",
      "Episodio 63: 12998 palabras, 788 oraciones\n",
      "Episodio 64: 11573 palabras, 667 oraciones\n",
      "Episodio 65: 10641 palabras, 687 oraciones\n",
      "Episodio 66: 15856 palabras, 1074 oraciones\n",
      "Episodio 67: 8875 palabras, 539 oraciones\n",
      "Episodio 68: 14529 palabras, 806 oraciones\n",
      "Episodio 69: 15916 palabras, 965 oraciones\n",
      "Episodio 70: 14880 palabras, 1183 oraciones\n",
      "Episodio 71: 12310 palabras, 1162 oraciones\n",
      "Episodio 72: 15162 palabras, 782 oraciones\n",
      "Episodio 73: 15975 palabras, 506 oraciones\n",
      "Episodio 74: 21229 palabras, 1319 oraciones\n",
      "Episodio 75: 15947 palabras, 1069 oraciones\n",
      "Episodio 76: 9386 palabras, 559 oraciones\n",
      "Episodio 77: 11018 palabras, 666 oraciones\n",
      "Episodio 78: 9493 palabras, 465 oraciones\n",
      "Episodio 79: 9731 palabras, 670 oraciones\n",
      "Episodio 80: 15457 palabras, 124 oraciones\n",
      "Episodio 81: 16416 palabras, 909 oraciones\n",
      "Episodio 82: 6478 palabras, 410 oraciones\n",
      "Episodio 83: 18076 palabras, 861 oraciones\n",
      "Episodio 84: 14018 palabras, 756 oraciones\n",
      "Episodio 85: 14522 palabras, 1062 oraciones\n",
      "Episodio 86: 17477 palabras, 825 oraciones\n",
      "Episodio 87: 10303 palabras, 629 oraciones\n",
      "Episodio 88: 27377 palabras, 1939 oraciones\n",
      "Episodio 89: 33770 palabras, 1933 oraciones\n",
      "Episodio 90: 15308 palabras, 999 oraciones\n",
      "Episodio 91: 7650 palabras, 474 oraciones\n",
      "Episodio 92: 18639 palabras, 1090 oraciones\n",
      "Episodio 93: 10815 palabras, 507 oraciones\n",
      "Episodio 94: 16293 palabras, 1082 oraciones\n",
      "Episodio 95: 19376 palabras, 1185 oraciones\n",
      "Episodio 96: 8981 palabras, 579 oraciones\n",
      "Episodio 97: 15678 palabras, 824 oraciones\n",
      "Episodio 98: 11606 palabras, 771 oraciones\n",
      "Episodio 99: 12699 palabras, 660 oraciones\n",
      "Episodio 101: 31589 palabras, 2073 oraciones\n",
      "Episodio 102: 13228 palabras, 892 oraciones\n",
      "Episodio 103: 39011 palabras, 2160 oraciones\n",
      "Episodio 104: 18087 palabras, 1087 oraciones\n",
      "Episodio 105: 10451 palabras, 653 oraciones\n",
      "Episodio 106: 17393 palabras, 956 oraciones\n",
      "Episodio 107: 10642 palabras, 483 oraciones\n",
      "Episodio 108: 17258 palabras, 785 oraciones\n",
      "Episodio 109: 17554 palabras, 1123 oraciones\n",
      "Episodio 110: 14144 palabras, 866 oraciones\n",
      "Episodio 111: 15667 palabras, 873 oraciones\n",
      "Episodio 112: 17967 palabras, 297 oraciones\n",
      "Episodio 113: 24109 palabras, 1560 oraciones\n",
      "Episodio 114: 26267 palabras, 1644 oraciones\n",
      "Episodio 115: 19044 palabras, 1485 oraciones\n",
      "Episodio 116: 17975 palabras, 1208 oraciones\n",
      "Episodio 117: 23286 palabras, 1537 oraciones\n",
      "Episodio 118: 24645 palabras, 1304 oraciones\n",
      "Episodio 119: 18379 palabras, 1105 oraciones\n",
      "Episodio 120: 22394 palabras, 1483 oraciones\n",
      "Episodio 121: 29646 palabras, 1739 oraciones\n",
      "Episodio 122: 48906 palabras, 2926 oraciones\n",
      "Episodio 123: 21171 palabras, 1508 oraciones\n",
      "Episodio 124: 45903 palabras, 2738 oraciones\n",
      "Episodio 125: 45364 palabras, 2863 oraciones\n",
      "Episodio 126: 12885 palabras, 968 oraciones\n",
      "Episodio 127: 13645 palabras, 1079 oraciones\n",
      "Episodio 128: 35060 palabras, 2905 oraciones\n",
      "Episodio 129: 19648 palabras, 1240 oraciones\n",
      "Episodio 130: 18819 palabras, 1108 oraciones\n",
      "Episodio 131: 29399 palabras, 1936 oraciones\n",
      "Episodio 132: 31272 palabras, 2739 oraciones\n",
      "Episodio 133: 23879 palabras, 1406 oraciones\n",
      "Episodio 134: 27221 palabras, 2195 oraciones\n",
      "Episodio 135: 27400 palabras, 1921 oraciones\n",
      "Episodio 136: 33932 palabras, 1907 oraciones\n",
      "Episodio 137: 24739 palabras, 1331 oraciones\n",
      "Episodio 138: 27433 palabras, 2096 oraciones\n",
      "Episodio 139: 26864 palabras, 1532 oraciones\n",
      "Episodio 140: 20581 palabras, 1307 oraciones\n",
      "Episodio 141: 17964 palabras, 1066 oraciones\n",
      "Episodio 142: 20371 palabras, 1366 oraciones\n",
      "Episodio 143: 30182 palabras, 2006 oraciones\n",
      "Episodio 144: 20517 palabras, 1387 oraciones\n",
      "Episodio 145: 35135 palabras, 1774 oraciones\n",
      "Episodio 146: 22220 palabras, 1300 oraciones\n",
      "Episodio 147: 24391 palabras, 1296 oraciones\n",
      "Episodio 148: 23241 palabras, 1896 oraciones\n",
      "Episodio 149: 27261 palabras, 2023 oraciones\n",
      "Episodio 150: 30330 palabras, 2307 oraciones\n",
      "Episodio 151: 15240 palabras, 1047 oraciones\n",
      "Episodio 152: 11385 palabras, 857 oraciones\n",
      "Episodio 153: 17516 palabras, 1103 oraciones\n",
      "Episodio 154: 25867 palabras, 1684 oraciones\n",
      "Episodio 155: 29848 palabras, 1699 oraciones\n",
      "Episodio 156: 26838 palabras, 2050 oraciones\n",
      "Episodio 157: 14061 palabras, 861 oraciones\n",
      "Episodio 158: 13451 palabras, 723 oraciones\n",
      "Episodio 159: 17509 palabras, 1200 oraciones\n",
      "Episodio 160: 33451 palabras, 2248 oraciones\n",
      "Episodio 161: 25499 palabras, 1806 oraciones\n",
      "Episodio 162: 27132 palabras, 2180 oraciones\n",
      "Episodio 163: 25043 palabras, 1648 oraciones\n",
      "Episodio 164: 30198 palabras, 1869 oraciones\n",
      "Episodio 165: 21467 palabras, 1431 oraciones\n",
      "Episodio 166: 35297 palabras, 2374 oraciones\n",
      "Episodio 167: 33060 palabras, 2378 oraciones\n",
      "Episodio 168: 16440 palabras, 1153 oraciones\n",
      "Episodio 169: 34727 palabras, 2480 oraciones\n",
      "Episodio 170: 13746 palabras, 712 oraciones\n",
      "Episodio 171: 34033 palabras, 948 oraciones\n",
      "Episodio 172: 24131 palabras, 1753 oraciones\n",
      "Episodio 173: 22696 palabras, 1487 oraciones\n",
      "Episodio 174: 21447 palabras, 1619 oraciones\n",
      "Episodio 175: 21053 palabras, 1665 oraciones\n",
      "Episodio 176: 37199 palabras, 2278 oraciones\n",
      "Episodio 177: 18471 palabras, 1139 oraciones\n",
      "Episodio 178: 50109 palabras, 4172 oraciones\n",
      "Episodio 179: 26659 palabras, 1691 oraciones\n",
      "Episodio 180: 22038 palabras, 1465 oraciones\n",
      "Episodio 181: 29455 palabras, 1535 oraciones\n",
      "Episodio 182: 32537 palabras, 2162 oraciones\n",
      "Episodio 183: 24650 palabras, 1563 oraciones\n",
      "Episodio 184: 18780 palabras, 1124 oraciones\n",
      "Episodio 185: 29729 palabras, 1528 oraciones\n",
      "Episodio 186: 23825 palabras, 1407 oraciones\n",
      "Episodio 187: 18307 palabras, 987 oraciones\n",
      "Episodio 188: 30736 palabras, 1588 oraciones\n",
      "Episodio 189: 17456 palabras, 1182 oraciones\n",
      "Episodio 190: 29760 palabras, 1888 oraciones\n",
      "Episodio 191: 41584 palabras, 1974 oraciones\n",
      "Episodio 192: 59475 palabras, 3863 oraciones\n",
      "Episodio 193: 29525 palabras, 1378 oraciones\n",
      "Episodio 194: 31006 palabras, 1669 oraciones\n",
      "Episodio 195: 18766 palabras, 1433 oraciones\n",
      "Episodio 196: 19146 palabras, 1725 oraciones\n",
      "Episodio 197: 18731 palabras, 1320 oraciones\n",
      "Episodio 198: 21020 palabras, 1313 oraciones\n",
      "Episodio 199: 23444 palabras, 1984 oraciones\n",
      "Episodio 200: 28941 palabras, 1765 oraciones\n",
      "Episodio 201: 23977 palabras, 1433 oraciones\n",
      "Episodio 202: 24315 palabras, 1348 oraciones\n",
      "Episodio 203: 18629 palabras, 1175 oraciones\n",
      "Episodio 204: 23707 palabras, 1644 oraciones\n",
      "Episodio 205: 37679 palabras, 1280 oraciones\n",
      "Episodio 206: 28576 palabras, 1659 oraciones\n",
      "Episodio 208: 25732 palabras, 2040 oraciones\n",
      "Episodio 209: 30092 palabras, 869 oraciones\n",
      "Episodio 210: 25864 palabras, 1524 oraciones\n",
      "Episodio 211: 17150 palabras, 1020 oraciones\n",
      "Episodio 212: 31697 palabras, 1923 oraciones\n",
      "Episodio 213: 20387 palabras, 1653 oraciones\n",
      "Episodio 214: 15390 palabras, 1024 oraciones\n",
      "Episodio 215: 27355 palabras, 1559 oraciones\n",
      "Episodio 216: 34207 palabras, 2611 oraciones\n",
      "Episodio 217: 21938 palabras, 1554 oraciones\n",
      "Episodio 218: 18285 palabras, 1131 oraciones\n",
      "Episodio 219: 18633 palabras, 1539 oraciones\n",
      "Episodio 220: 28456 palabras, 2003 oraciones\n",
      "Episodio 221: 25888 palabras, 1305 oraciones\n",
      "Episodio 222: 18789 palabras, 990 oraciones\n",
      "Episodio 223: 37509 palabras, 3182 oraciones\n",
      "Episodio 224: 36502 palabras, 2727 oraciones\n",
      "Episodio 225: 28319 palabras, 1600 oraciones\n",
      "Episodio 226: 14648 palabras, 985 oraciones\n",
      "Episodio 227: 25917 palabras, 1592 oraciones\n",
      "Episodio 228: 13134 palabras, 1196 oraciones\n",
      "Episodio 229: 21000 palabras, 1216 oraciones\n",
      "Episodio 230: 44613 palabras, 3563 oraciones\n",
      "Episodio 231: 27355 palabras, 1688 oraciones\n",
      "Episodio 232: 16728 palabras, 870 oraciones\n",
      "Episodio 233: 10769 palabras, 768 oraciones\n",
      "Episodio 234: 39990 palabras, 2253 oraciones\n",
      "Episodio 235: 17632 palabras, 1147 oraciones\n",
      "Episodio 236: 25550 palabras, 1787 oraciones\n",
      "Episodio 237: 32110 palabras, 1832 oraciones\n",
      "Episodio 238: 13584 palabras, 866 oraciones\n",
      "Episodio 239: 23649 palabras, 1352 oraciones\n",
      "Episodio 240: 21676 palabras, 1280 oraciones\n",
      "Episodio 241: 34606 palabras, 1857 oraciones\n",
      "Episodio 242: 28083 palabras, 2268 oraciones\n",
      "Episodio 243: 28924 palabras, 1975 oraciones\n",
      "Episodio 244: 27394 palabras, 1559 oraciones\n",
      "Episodio 245: 9629 palabras, 765 oraciones\n",
      "Episodio 246: 22470 palabras, 955 oraciones\n",
      "Episodio 247: 45109 palabras, 2621 oraciones\n",
      "Episodio 248: 21087 palabras, 1238 oraciones\n",
      "Episodio 249: 10495 palabras, 719 oraciones\n",
      "Episodio 250: 30100 palabras, 1826 oraciones\n",
      "Episodio 251: 12335 palabras, 709 oraciones\n",
      "Episodio 252: 22141 palabras, 1521 oraciones\n",
      "Episodio 253: 35098 palabras, 3005 oraciones\n",
      "Episodio 254: 22531 palabras, 1338 oraciones\n",
      "Episodio 255: 20175 palabras, 1991 oraciones\n",
      "Episodio 256: 28837 palabras, 1671 oraciones\n",
      "Episodio 257: 44312 palabras, 3213 oraciones\n",
      "Episodio 258: 27053 palabras, 1651 oraciones\n",
      "Episodio 259: 20326 palabras, 1235 oraciones\n",
      "Episodio 260: 31351 palabras, 720 oraciones\n",
      "Episodio 261: 25238 palabras, 1539 oraciones\n",
      "Episodio 262: 15265 palabras, 1001 oraciones\n",
      "Episodio 263: 19219 palabras, 1195 oraciones\n",
      "Episodio 264: 31746 palabras, 2136 oraciones\n",
      "Episodio 265: 19971 palabras, 1887 oraciones\n",
      "Episodio 266: 18300 palabras, 1183 oraciones\n",
      "Episodio 267: 20696 palabras, 1064 oraciones\n",
      "Episodio 269: 41740 palabras, 2851 oraciones\n",
      "Episodio 270: 20979 palabras, 1348 oraciones\n",
      "Episodio 271: 19050 palabras, 1141 oraciones\n",
      "Episodio 272: 39062 palabras, 3619 oraciones\n",
      "Episodio 273: 28685 palabras, 1712 oraciones\n",
      "Episodio 274: 30637 palabras, 1842 oraciones\n",
      "Episodio 275: 15304 palabras, 326 oraciones\n",
      "Episodio 276: 34869 palabras, 2326 oraciones\n",
      "Episodio 277: 36931 palabras, 2622 oraciones\n",
      "Episodio 278: 22231 palabras, 1584 oraciones\n",
      "Episodio 279: 43876 palabras, 3172 oraciones\n",
      "Episodio 280: 10843 palabras, 802 oraciones\n",
      "Episodio 281: 21712 palabras, 1585 oraciones\n",
      "Episodio 284: 44615 palabras, 2715 oraciones\n",
      "Episodio 285: 30243 palabras, 1818 oraciones\n",
      "Episodio 286: 17938 palabras, 1167 oraciones\n",
      "Episodio 288: 40695 palabras, 3249 oraciones\n",
      "Episodio 289: 21917 palabras, 1316 oraciones\n",
      "Episodio 290: 22803 palabras, 1580 oraciones\n",
      "Episodio 292: 42925 palabras, 2890 oraciones\n",
      "Episodio 293: 30533 palabras, 2015 oraciones\n",
      "Episodio 294: 28493 palabras, 2093 oraciones\n",
      "Episodio 295: 24873 palabras, 1841 oraciones\n",
      "Episodio 296: 24993 palabras, 1626 oraciones\n",
      "Episodio 297: 27571 palabras, 1591 oraciones\n",
      "Episodio 298: 19943 palabras, 1349 oraciones\n",
      "Episodio 299: 23448 palabras, 1270 oraciones\n",
      "Episodio 300: 16887 palabras, 1517 oraciones\n",
      "Episodio 301: 31340 palabras, 2213 oraciones\n",
      "Episodio 302: 21826 palabras, 1410 oraciones\n",
      "Episodio 303: 35054 palabras, 2681 oraciones\n",
      "Episodio 304: 19223 palabras, 1530 oraciones\n",
      "Episodio 305: 19910 palabras, 1152 oraciones\n",
      "Episodio 306: 20334 palabras, 1210 oraciones\n",
      "Episodio 307: 28214 palabras, 1774 oraciones\n",
      "Episodio 308: 27520 palabras, 1690 oraciones\n",
      "Episodio 309: 57667 palabras, 2924 oraciones\n",
      "Episodio 310: 38316 palabras, 2537 oraciones\n",
      "Episodio 311: 35145 palabras, 2414 oraciones\n",
      "Episodio 312: 32437 palabras, 2379 oraciones\n",
      "Episodio 313: 29793 palabras, 2684 oraciones\n",
      "Episodio 314: 37866 palabras, 2507 oraciones\n",
      "Episodio 315: 23159 palabras, 1783 oraciones\n",
      "Episodio 316: 5069 palabras, 377 oraciones\n",
      "Episodio 317: 28369 palabras, 1841 oraciones\n",
      "Episodio 318: 36564 palabras, 2434 oraciones\n",
      "Episodio 319: 28794 palabras, 2052 oraciones\n",
      "Episodio 320: 19902 palabras, 1150 oraciones\n",
      "Episodio 321: 12807 palabras, 961 oraciones\n",
      "Episodio 322: 26034 palabras, 1983 oraciones\n",
      "Episodio 323: 25255 palabras, 2064 oraciones\n",
      "Episodio 324: 29911 palabras, 2124 oraciones\n",
      "Episodio 325: 33714 palabras, 2089 oraciones\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Contar oraciones en la columna 'text' usando nltk\n",
    "data['sentence_count'] = data['text'].apply(lambda x: len(sent_tokenize(str(x))))\n",
    "\n",
    "# Mostrar los episodios con conteos de palabras y oraciones\n",
    "for index, row in data.iterrows():\n",
    "    print(f\"Episodio {row['id']}: {row['word_count']} palabras, {row['sentence_count']} oraciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T12:55:53.065331Z",
     "iopub.status.busy": "2025-01-14T12:55:53.064950Z",
     "iopub.status.idle": "2025-01-14T12:55:53.098487Z",
     "shell.execute_reply": "2025-01-14T12:55:53.097112Z",
     "shell.execute_reply.started": "2025-01-14T12:55:53.065301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 1 (Life 3.0):\n",
      "- 13424 palabras\n",
      "- 737 oraciones\n"
     ]
    }
   ],
   "source": [
    "# Solicitar al usuario el índice del episodio que quiere analizar\n",
    "# episodio_id = int(input(\"Ingresa el ID del episodio que deseas analizar: \"))\n",
    "episodio_id = 1  # Cambia este valor según el episodio que desees analizar\n",
    "\n",
    "# Filtrar el episodio con el ID seleccionado\n",
    "episodio = data[data['id'] == episodio_id]\n",
    "\n",
    "if episodio.empty:\n",
    "    print(f\"No se encontró el episodio con ID {episodio_id}.\")\n",
    "else:\n",
    "    # Calcular word count y sentence count para el episodio de forma temporal (sin modificar directamente)\n",
    "    word_count = episodio['text'].apply(lambda x: len(str(x).split())).iloc[0]\n",
    "    sentence_count = episodio['text'].apply(lambda x: len(sent_tokenize(str(x)))).iloc[0]\n",
    "    \n",
    "    # Mostrar los resultados\n",
    "    print(f\"Episodio {episodio_id} ({episodio['title'].iloc[0]}):\")\n",
    "    print(f\"- {word_count} palabras\")\n",
    "    print(f\"- {sentence_count} oraciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T13:05:55.980143Z",
     "iopub.status.busy": "2025-01-14T13:05:55.979742Z",
     "iopub.status.idle": "2025-01-14T13:06:09.542736Z",
     "shell.execute_reply": "2025-01-14T13:06:09.541677Z",
     "shell.execute_reply.started": "2025-01-14T13:05:55.980110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para el episodio 1:\n",
      "st_id: 1\n",
      "Texto: As part of MIT course 6S099, Artificial General Intelligence, I've gotten the chance to sit down with Max Tegmark.\n",
      "Palabras: 19\n",
      "Embedding: vector_680\n",
      "\n",
      "st_id: 2\n",
      "Texto: He is a professor here at MIT.\n",
      "Palabras: 7\n",
      "Embedding: vector_146\n",
      "\n",
      "st_id: 3\n",
      "Texto: He's a physicist, spent a large part of his career studying the mysteries of our cosmological universe.\n",
      "Palabras: 17\n",
      "Embedding: vector_762\n",
      "\n",
      "st_id: 4\n",
      "Texto: But he's also studied and delved into the beneficial possibilities and the existential risks of artificial intelligence.\n",
      "Palabras: 17\n",
      "Embedding: vector_277\n",
      "\n",
      "st_id: 5\n",
      "Texto: Amongst many other things, he is the cofounder of the Future of Life Institute, author of two books, both of which I highly recommend.\n",
      "Palabras: 24\n",
      "Embedding: vector_285\n",
      "\n",
      "st_id: 6\n",
      "Texto: First, Our Mathematical Universe.\n",
      "Palabras: 4\n",
      "Embedding: vector_865\n",
      "\n",
      "st_id: 7\n",
      "Texto: Second is Life 3.0.\n",
      "Palabras: 4\n",
      "Embedding: vector_126\n",
      "\n",
      "st_id: 8\n",
      "Texto: He's truly an out of the box thinker and a fun personality, so I really enjoy talking to him.\n",
      "Palabras: 19\n",
      "Embedding: vector_903\n",
      "\n",
      "st_id: 9\n",
      "Texto: If you'd like to see more of these videos in the future, please subscribe and also click the little bell icon to make sure you don't miss any videos.\n",
      "Palabras: 29\n",
      "Embedding: vector_458\n",
      "\n",
      "st_id: 10\n",
      "Texto: Also, Twitter, LinkedIn, agi.mit.edu if you wanna watch other lectures or conversations like this one.\n",
      "Palabras: 15\n",
      "Embedding: vector_533\n",
      "\n",
      "st_id: 11\n",
      "Texto: Better yet, go read Max's book, Life 3.0.\n",
      "Palabras: 8\n",
      "Embedding: vector_520\n",
      "\n",
      "st_id: 12\n",
      "Texto: Chapter seven on goals is my favorite.\n",
      "Palabras: 7\n",
      "Embedding: vector_833\n",
      "\n",
      "st_id: 13\n",
      "Texto: It's really where philosophy and engineering come together and it opens with a quote by Dostoevsky.\n",
      "Palabras: 16\n",
      "Embedding: vector_987\n",
      "\n",
      "st_id: 14\n",
      "Texto: The mystery of human existence lies not in just staying alive but in finding something to live for.\n",
      "Palabras: 18\n",
      "Embedding: vector_647\n",
      "\n",
      "st_id: 15\n",
      "Texto: Lastly, I believe that every failure rewards us with an opportunity to learn and in that sense, I've been very fortunate to fail in so many new and exciting ways and this conversation was no different.\n",
      "Palabras: 36\n",
      "Embedding: vector_6\n",
      "\n",
      "st_id: 16\n",
      "Texto: I've learned about something called radio frequency interference, RFI, look it up.\n",
      "Palabras: 12\n",
      "Embedding: vector_258\n",
      "\n",
      "st_id: 17\n",
      "Texto: Apparently, music and conversations from local radio stations can bleed into the audio that you're recording in such a way that it almost completely ruins that audio.\n",
      "Palabras: 27\n",
      "Embedding: vector_604\n",
      "\n",
      "st_id: 18\n",
      "Texto: It's an exceptionally difficult sound source to remove.\n",
      "Palabras: 8\n",
      "Embedding: vector_755\n",
      "\n",
      "st_id: 19\n",
      "Texto: So, I've gotten the opportunity to learn how to avoid RFI in the future during recording sessions.\n",
      "Palabras: 17\n",
      "Embedding: vector_617\n",
      "\n",
      "st_id: 20\n",
      "Texto: I've also gotten the opportunity to learn how to use Adobe Audition and iZotope RX 6 to do some noise, some audio repair.\n",
      "Palabras: 23\n",
      "Embedding: vector_282\n",
      "\n",
      "st_id: 21\n",
      "Texto: Of course, this is an exceptionally difficult noise to remove.\n",
      "Palabras: 10\n",
      "Embedding: vector_51\n",
      "\n",
      "st_id: 22\n",
      "Texto: I am an engineer.\n",
      "Palabras: 4\n",
      "Embedding: vector_661\n",
      "\n",
      "st_id: 23\n",
      "Texto: I'm not an audio engineer.\n",
      "Palabras: 5\n",
      "Embedding: vector_806\n",
      "\n",
      "st_id: 24\n",
      "Texto: Neither is anybody else in our group but we did our best.\n",
      "Palabras: 12\n",
      "Embedding: vector_645\n",
      "\n",
      "st_id: 25\n",
      "Texto: Nevertheless, I thank you for your patience and I hope you're still able to enjoy this conversation.\n",
      "Palabras: 17\n",
      "Embedding: vector_707\n",
      "\n",
      "st_id: 26\n",
      "Texto: Do you think there's intelligent life out there in the universe?\n",
      "Palabras: 11\n",
      "Embedding: vector_329\n",
      "\n",
      "st_id: 27\n",
      "Texto: Let's open up with an easy question.\n",
      "Palabras: 7\n",
      "Embedding: vector_329\n",
      "\n",
      "st_id: 28\n",
      "Texto: I have a minority view here actually.\n",
      "Palabras: 7\n",
      "Embedding: vector_661\n",
      "\n",
      "st_id: 29\n",
      "Texto: When I give public lectures, I often ask for a show of hands who thinks there's intelligent life out there somewhere else and almost everyone put their hands up and when I ask why, they'll be like, oh, there's so many galaxies out there, there's gotta be.\n",
      "Palabras: 47\n",
      "Embedding: vector_857\n",
      "\n",
      "st_id: 30\n",
      "Texto: But I'm a numbers nerd, right?\n",
      "Palabras: 6\n",
      "Embedding: vector_261\n",
      "\n",
      "st_id: 31\n",
      "Texto: So when you look more carefully at it, it's not so clear at all.\n",
      "Palabras: 14\n",
      "Embedding: vector_446\n",
      "\n",
      "st_id: 32\n",
      "Texto: When we talk about our universe, first of all, we don't mean all of space.\n",
      "Palabras: 15\n",
      "Embedding: vector_568\n",
      "\n",
      "st_id: 33\n",
      "Texto: We actually mean, I don't know, you can throw me the universe if you want, it's behind you there.\n",
      "Palabras: 19\n",
      "Embedding: vector_651\n",
      "\n",
      "st_id: 34\n",
      "Texto: It's, we simply mean the spherical region of space from which light has a time to reach us so far during the 14.8 billion year, 13.8 billion years since our Big Bang.\n",
      "Palabras: 32\n",
      "Embedding: vector_81\n",
      "\n",
      "st_id: 35\n",
      "Texto: There's more space here but this is what we call a universe because that's all we have access to.\n",
      "Palabras: 19\n",
      "Embedding: vector_525\n",
      "\n",
      "st_id: 36\n",
      "Texto: So is there intelligent life here that's gotten to the point of building telescopes and computers?\n",
      "Palabras: 16\n",
      "Embedding: vector_921\n",
      "\n",
      "st_id: 37\n",
      "Texto: My guess is no, actually.\n",
      "Palabras: 5\n",
      "Embedding: vector_813\n",
      "\n",
      "st_id: 38\n",
      "Texto: The probability of it happening on any given planet is some number we don't know what it is.\n",
      "Palabras: 18\n",
      "Embedding: vector_45\n",
      "\n",
      "st_id: 39\n",
      "Texto: And what we do know is that the number can't be super high because there's over a billion Earth like planets in the Milky Way galaxy alone, many of which are billions of years older than Earth.\n",
      "Palabras: 37\n",
      "Embedding: vector_157\n",
      "\n",
      "st_id: 40\n",
      "Texto: And aside from some UFO believers, there isn't much evidence that any superduran civilization has come here at all.\n",
      "Palabras: 19\n",
      "Embedding: vector_842\n",
      "\n",
      "st_id: 41\n",
      "Texto: And so that's the famous Fermi paradox, right?\n",
      "Palabras: 8\n",
      "Embedding: vector_814\n",
      "\n",
      "st_id: 42\n",
      "Texto: And then if you work the numbers, what you find is that if you have no clue what the probability is of getting life on a given planet, so it could be 10 to the minus 10, 10 to the minus 20, or 10 to the minus two, or any power of 10 is sort of equally likely if you wanna be really open minded, that translates into it being equally likely that our nearest neighbor is 10 to the 16 meters away, 10 to the 17 meters away, 10 to the 18.\n",
      "Palabras: 93\n",
      "Embedding: vector_11\n",
      "\n",
      "st_id: 43\n",
      "Texto: By the time you get much less than 10 to the 16 already, we pretty much know there is nothing else that close.\n",
      "Palabras: 23\n",
      "Embedding: vector_422\n",
      "\n",
      "st_id: 44\n",
      "Texto: And when you get beyond 10.\n",
      "Palabras: 6\n",
      "Embedding: vector_835\n",
      "\n",
      "st_id: 45\n",
      "Texto: Because they would have discovered us.\n",
      "Palabras: 6\n",
      "Embedding: vector_665\n",
      "\n",
      "st_id: 46\n",
      "Texto: Yeah, they would have been discovered as long ago, or if they're really close, we would have probably noted some engineering projects that they're doing.\n",
      "Palabras: 25\n",
      "Embedding: vector_509\n",
      "\n",
      "st_id: 47\n",
      "Texto: And if it's beyond 10 to the 26 meters, that's already outside of here.\n",
      "Palabras: 14\n",
      "Embedding: vector_267\n",
      "\n",
      "st_id: 48\n",
      "Texto: So my guess is actually that we are the only life in here that's gotten the point of building advanced tech, which I think is very, puts a lot of responsibility on our shoulders, not screw up.\n",
      "Palabras: 37\n",
      "Embedding: vector_52\n",
      "\n",
      "st_id: 49\n",
      "Texto: I think people who take for granted that it's okay for us to screw up, have an accidental nuclear war or go extinct somehow because there's a sort of Star Trek like situation out there where some other life forms are gonna come and bail us out and it doesn't matter as much.\n",
      "Palabras: 53\n",
      "Embedding: vector_775\n",
      "\n",
      "st_id: 50\n",
      "Texto: I think they're leveling us into a false sense of security.\n",
      "Palabras: 11\n",
      "Embedding: vector_710\n",
      "\n",
      "st_id: 51\n",
      "Texto: I think it's much more prudent to say, let's be really grateful for this amazing opportunity we've had and make the best of it just in case it is down to us.\n",
      "Palabras: 32\n",
      "Embedding: vector_710\n",
      "\n",
      "st_id: 52\n",
      "Texto: So from a physics perspective, do you think intelligent life, so it's unique from a sort of statistical view of the size of the universe, but from the basic matter of the universe, how difficult is it for intelligent life to come about?\n",
      "Palabras: 43\n",
      "Embedding: vector_787\n",
      "\n",
      "st_id: 53\n",
      "Texto: The kind of advanced tech building life is implied in your statement that it's really difficult to create something like a human species.\n",
      "Palabras: 23\n",
      "Embedding: vector_311\n",
      "\n",
      "st_id: 54\n",
      "Texto: Well, I think what we know is that going from no life to having life that can do a level of tech, there's some sort of two going beyond that than actually settling our whole universe with life.\n",
      "Palabras: 38\n",
      "Embedding: vector_506\n",
      "\n",
      "st_id: 55\n",
      "Texto: There's some major roadblock there, which is some great filter as it's sometimes called, which is tough to get through.\n",
      "Palabras: 20\n",
      "Embedding: vector_505\n",
      "\n",
      "st_id: 56\n",
      "Texto: It's either that roadblock is either behind us or in front of us.\n",
      "Palabras: 13\n",
      "Embedding: vector_885\n",
      "\n",
      "st_id: 57\n",
      "Texto: I'm hoping very much that it's behind us.\n",
      "Palabras: 8\n",
      "Embedding: vector_760\n",
      "\n",
      "st_id: 58\n",
      "Texto: I'm super excited every time we get a new report from NASA saying they failed to find any life on Mars.\n",
      "Palabras: 21\n",
      "Embedding: vector_114\n",
      "\n",
      "st_id: 59\n",
      "Texto: I'm like, yes, awesome.\n",
      "Palabras: 4\n",
      "Embedding: vector_200\n",
      "\n",
      "st_id: 60\n",
      "Texto: Because that suggests that the hard part, maybe it was getting the first ribosome or some very low level kind of stepping stone so that we're home free.\n",
      "Palabras: 28\n",
      "Embedding: vector_816\n",
      "\n",
      "st_id: 61\n",
      "Texto: Because if that's true, then the future is really only limited by our own imagination.\n",
      "Palabras: 15\n",
      "Embedding: vector_397\n",
      "\n",
      "st_id: 62\n",
      "Texto: It would be much suckier if it turns out that this level of life is kind of a dime a dozen, but maybe there's some other problem.\n",
      "Palabras: 27\n",
      "Embedding: vector_715\n",
      "\n",
      "st_id: 63\n",
      "Texto: Like as soon as a civilization gets advanced technology, within a hundred years, they get into some stupid fight with themselves and poof.\n",
      "Palabras: 23\n",
      "Embedding: vector_933\n",
      "\n",
      "st_id: 64\n",
      "Texto: That would be a bummer.\n",
      "Palabras: 5\n",
      "Embedding: vector_959\n",
      "\n",
      "st_id: 65\n",
      "Texto: Yeah, so you've explored the mysteries of the universe, the cosmological universe, the one that's sitting between us today.\n",
      "Palabras: 19\n",
      "Embedding: vector_351\n",
      "\n",
      "st_id: 66\n",
      "Texto: I think you've also begun to explore the other universe, which is sort of the mystery, the mysterious universe of the mind of intelligence, of intelligent life.\n",
      "Palabras: 27\n",
      "Embedding: vector_155\n",
      "\n",
      "st_id: 67\n",
      "Texto: So is there a common thread between your interest or the way you think about space and intelligence?\n",
      "Palabras: 18\n",
      "Embedding: vector_253\n",
      "\n",
      "st_id: 68\n",
      "Texto: Oh yeah, when I was a teenager, I was already very fascinated by the biggest questions.\n",
      "Palabras: 16\n",
      "Embedding: vector_603\n",
      "\n",
      "st_id: 69\n",
      "Texto: And I felt that the two biggest mysteries of all in science were our universe out there and our universe in here.\n",
      "Palabras: 22\n",
      "Embedding: vector_374\n",
      "\n",
      "st_id: 70\n",
      "Texto: So it's quite natural after having spent a quarter of a century on my career, thinking a lot about this one, that I'm now indulging in the luxury of doing research on this one.\n",
      "Palabras: 34\n",
      "Embedding: vector_559\n",
      "\n",
      "st_id: 71\n",
      "Texto: It's just so cool.\n",
      "Palabras: 4\n",
      "Embedding: vector_954\n",
      "\n",
      "st_id: 72\n",
      "Texto: I feel the time is ripe now for you trans greatly deepening our understanding of this.\n",
      "Palabras: 16\n",
      "Embedding: vector_551\n",
      "\n",
      "st_id: 73\n",
      "Texto: Just start exploring this one.\n",
      "Palabras: 5\n",
      "Embedding: vector_764\n",
      "\n",
      "st_id: 74\n",
      "Texto: Yeah, because I think a lot of people view intelligence as something mysterious that can only exist in biological organisms like us, and therefore dismiss all talk about artificial general intelligence as science fiction.\n",
      "Palabras: 34\n",
      "Embedding: vector_800\n",
      "\n",
      "st_id: 75\n",
      "Texto: But from my perspective as a physicist, I am a blob of quarks and electrons moving around in a certain pattern and processing information in certain ways.\n",
      "Palabras: 27\n",
      "Embedding: vector_338\n",
      "\n",
      "st_id: 76\n",
      "Texto: And this is also a blob of quarks and electrons.\n",
      "Palabras: 10\n",
      "Embedding: vector_350\n",
      "\n",
      "st_id: 77\n",
      "Texto: I'm not smarter than the water bottle because I'm made of different kinds of quarks.\n",
      "Palabras: 15\n",
      "Embedding: vector_275\n",
      "\n",
      "st_id: 78\n",
      "Texto: I'm made of up quarks and down quarks, exact same kind as this.\n",
      "Palabras: 13\n",
      "Embedding: vector_10\n",
      "\n",
      "st_id: 79\n",
      "Texto: There's no secret sauce, I think, in me.\n",
      "Palabras: 8\n",
      "Embedding: vector_475\n",
      "\n",
      "st_id: 80\n",
      "Texto: It's all about the pattern of the information processing.\n",
      "Palabras: 9\n",
      "Embedding: vector_471\n",
      "\n",
      "st_id: 81\n",
      "Texto: And this means that there's no law of physics saying that we can't create technology, which can help us by being incredibly intelligent and help us crack mysteries that we couldn't.\n",
      "Palabras: 31\n",
      "Embedding: vector_299\n",
      "\n",
      "st_id: 82\n",
      "Texto: In other words, I think we've really only seen the tip of the intelligence iceberg so far.\n",
      "Palabras: 17\n",
      "Embedding: vector_980\n",
      "\n",
      "st_id: 83\n",
      "Texto: Yeah, so the perceptronium.\n",
      "Palabras: 4\n",
      "Embedding: vector_486\n",
      "\n",
      "st_id: 84\n",
      "Texto: Yeah.\n",
      "Palabras: 1\n",
      "Embedding: vector_21\n",
      "\n",
      "st_id: 85\n",
      "Texto: So you coined this amazing term.\n",
      "Palabras: 6\n",
      "Embedding: vector_530\n",
      "\n",
      "st_id: 86\n",
      "Texto: It's a hypothetical state of matter, sort of thinking from a physics perspective, what is the kind of matter that can help, as you're saying, subjective experience emerge, consciousness emerge.\n",
      "Palabras: 30\n",
      "Embedding: vector_981\n",
      "\n",
      "st_id: 87\n",
      "Texto: So how do you think about consciousness from this physics perspective?\n",
      "Palabras: 11\n",
      "Embedding: vector_794\n",
      "\n",
      "st_id: 88\n",
      "Texto: Very good question.\n",
      "Palabras: 3\n",
      "Embedding: vector_106\n",
      "\n",
      "st_id: 89\n",
      "Texto: So again, I think many people have underestimated our ability to make progress on this by convincing themselves it's hopeless because somehow we're missing some ingredient that we need.\n",
      "Palabras: 29\n",
      "Embedding: vector_567\n",
      "\n",
      "st_id: 90\n",
      "Texto: There's some new consciousness particle or whatever.\n",
      "Palabras: 7\n",
      "Embedding: vector_194\n",
      "\n",
      "st_id: 91\n",
      "Texto: I happen to think that we're not missing anything and that it's not the interesting thing about consciousness that gives us this amazing subjective experience of colors and sounds and emotions.\n",
      "Palabras: 31\n",
      "Embedding: vector_599\n",
      "\n",
      "st_id: 92\n",
      "Texto: It's rather something at the higher level about the patterns of information processing.\n",
      "Palabras: 13\n",
      "Embedding: vector_988\n",
      "\n",
      "st_id: 93\n",
      "Texto: And that's why I like to think about this idea of perceptronium.\n",
      "Palabras: 12\n",
      "Embedding: vector_521\n",
      "\n",
      "st_id: 94\n",
      "Texto: What does it mean for an arbitrary physical system to be conscious in terms of what its particles are doing or its information is doing?\n",
      "Palabras: 25\n",
      "Embedding: vector_137\n",
      "\n",
      "st_id: 95\n",
      "Texto: I don't think, I hate carbon chauvinism, this attitude you have to be made of carbon atoms to be smart or conscious.\n",
      "Palabras: 22\n",
      "Embedding: vector_622\n",
      "\n",
      "st_id: 96\n",
      "Texto: There's something about the information processing that this kind of matter performs.\n",
      "Palabras: 12\n",
      "Embedding: vector_19\n",
      "\n",
      "st_id: 97\n",
      "Texto: Yeah, and you can see I have my favorite equations here describing various fundamental aspects of the world.\n",
      "Palabras: 18\n",
      "Embedding: vector_565\n",
      "\n",
      "st_id: 98\n",
      "Texto: I feel that I think one day, maybe someone who's watching this will come up with the equations that information processing has to satisfy to be conscious.\n",
      "Palabras: 27\n",
      "Embedding: vector_921\n",
      "\n",
      "st_id: 99\n",
      "Texto: I'm quite convinced there is big discovery to be made there because let's face it, we know that so many things are made up of information.\n",
      "Palabras: 26\n",
      "Embedding: vector_96\n",
      "\n",
      "st_id: 100\n",
      "Texto: We know that some information processing is conscious because we are conscious.\n",
      "Palabras: 12\n",
      "Embedding: vector_935\n",
      "\n",
      "st_id: 101\n",
      "Texto: But we also know that a lot of information processing is not conscious.\n",
      "Palabras: 13\n",
      "Embedding: vector_790\n",
      "\n",
      "st_id: 102\n",
      "Texto: Like most of the information processing happening in your brain right now is not conscious.\n",
      "Palabras: 15\n",
      "Embedding: vector_775\n",
      "\n",
      "st_id: 103\n",
      "Texto: There are like 10 megabytes per second coming in even just through your visual system.\n",
      "Palabras: 15\n",
      "Embedding: vector_995\n",
      "\n",
      "st_id: 104\n",
      "Texto: You're not conscious about your heartbeat regulation or most things.\n",
      "Palabras: 10\n",
      "Embedding: vector_730\n",
      "\n",
      "st_id: 105\n",
      "Texto: Even if I just ask you to like read what it says here, you look at it and then, oh, now you know what it said.\n",
      "Palabras: 26\n",
      "Embedding: vector_209\n",
      "\n",
      "st_id: 106\n",
      "Texto: But you're not aware of how the computation actually happened.\n",
      "Palabras: 10\n",
      "Embedding: vector_574\n",
      "\n",
      "st_id: 107\n",
      "Texto: Your consciousness is like the CEO that got an email at the end with the final answer.\n",
      "Palabras: 17\n",
      "Embedding: vector_916\n",
      "\n",
      "st_id: 108\n",
      "Texto: So what is it that makes a difference?\n",
      "Palabras: 8\n",
      "Embedding: vector_311\n",
      "\n",
      "st_id: 109\n",
      "Texto: I think that's both a great science mystery.\n",
      "Palabras: 8\n",
      "Embedding: vector_3\n",
      "\n",
      "st_id: 110\n",
      "Texto: We're actually studying it a little bit in my lab here at MIT, but I also think it's just a really urgent question to answer.\n",
      "Palabras: 25\n",
      "Embedding: vector_220\n",
      "\n",
      "st_id: 111\n",
      "Texto: For starters, I mean, if you're an emergency room doctor and you have an unresponsive patient coming in, wouldn't it be great if in addition to having a CT scanner, you had a consciousness scanner that could figure out whether this person is actually having locked in syndrome or is actually comatose.\n",
      "Palabras: 52\n",
      "Embedding: vector_781\n",
      "\n",
      "st_id: 112\n",
      "Texto: And in the future, imagine if we build robots or the machine that we can have really good conversations with, which I think is very likely to happen.\n",
      "Palabras: 28\n",
      "Embedding: vector_889\n",
      "\n",
      "st_id: 113\n",
      "Texto: Wouldn't you want to know if your home helper robot is actually experiencing anything or just like a zombie, I mean, would you prefer it?\n",
      "Palabras: 25\n",
      "Embedding: vector_27\n",
      "\n",
      "st_id: 114\n",
      "Texto: What would you prefer?\n",
      "Palabras: 4\n",
      "Embedding: vector_880\n",
      "\n",
      "st_id: 115\n",
      "Texto: Would you prefer that it's actually unconscious so that you don't have to feel guilty about switching it off or giving boring chores or what would you prefer?\n",
      "Palabras: 28\n",
      "Embedding: vector_445\n",
      "\n",
      "st_id: 116\n",
      "Texto: Well, certainly we would prefer, I would prefer the appearance of consciousness.\n",
      "Palabras: 12\n",
      "Embedding: vector_361\n",
      "\n",
      "st_id: 117\n",
      "Texto: But the question is whether the appearance of consciousness is different than consciousness itself.\n",
      "Palabras: 14\n",
      "Embedding: vector_346\n",
      "\n",
      "st_id: 118\n",
      "Texto: And sort of to ask that as a question, do you think we need to understand what consciousness is, solve the hard problem of consciousness in order to build something like an AGI system?\n",
      "Palabras: 34\n",
      "Embedding: vector_315\n",
      "\n",
      "st_id: 119\n",
      "Texto: No, I don't think that.\n",
      "Palabras: 5\n",
      "Embedding: vector_719\n",
      "\n",
      "st_id: 120\n",
      "Texto: And I think we will probably be able to build things even if we don't answer that question.\n",
      "Palabras: 18\n",
      "Embedding: vector_385\n",
      "\n",
      "st_id: 121\n",
      "Texto: But if we want to make sure that what happens is a good thing, we better solve it first.\n",
      "Palabras: 19\n",
      "Embedding: vector_679\n",
      "\n",
      "st_id: 122\n",
      "Texto: So it's a wonderful controversy you're raising there where you have basically three points of view about the hard problem.\n",
      "Palabras: 20\n",
      "Embedding: vector_2\n",
      "\n",
      "st_id: 123\n",
      "Texto: So there are two different points of view.\n",
      "Palabras: 8\n",
      "Embedding: vector_970\n",
      "\n",
      "st_id: 124\n",
      "Texto: They both conclude that the hard problem of consciousness is BS.\n",
      "Palabras: 11\n",
      "Embedding: vector_839\n",
      "\n",
      "st_id: 125\n",
      "Texto: On one hand, you have some people like Daniel Dennett who say that consciousness is just BS because consciousness is the same thing as intelligence.\n",
      "Palabras: 25\n",
      "Embedding: vector_357\n",
      "\n",
      "st_id: 126\n",
      "Texto: There's no difference.\n",
      "Palabras: 3\n",
      "Embedding: vector_820\n",
      "\n",
      "st_id: 127\n",
      "Texto: So anything which acts conscious is conscious, just like we are.\n",
      "Palabras: 11\n",
      "Embedding: vector_239\n",
      "\n",
      "st_id: 128\n",
      "Texto: And then there are also a lot of people, including many top AI researchers I know, who say, oh, consciousness is just bullshit because, of course, machines can never be conscious.\n",
      "Palabras: 31\n",
      "Embedding: vector_11\n",
      "\n",
      "st_id: 129\n",
      "Texto: They're always going to be zombies.\n",
      "Palabras: 6\n",
      "Embedding: vector_544\n",
      "\n",
      "st_id: 130\n",
      "Texto: You never have to feel guilty about how you treat them.\n",
      "Palabras: 11\n",
      "Embedding: vector_405\n",
      "\n",
      "st_id: 131\n",
      "Texto: And then there's a third group of people, including Giulio Tononi, for example, and Krzysztof Koch and a number of others.\n",
      "Palabras: 21\n",
      "Embedding: vector_22\n",
      "\n",
      "st_id: 132\n",
      "Texto: I would put myself also in this middle camp who say that actually some information processing is conscious and some is not.\n",
      "Palabras: 22\n",
      "Embedding: vector_81\n",
      "\n",
      "st_id: 133\n",
      "Texto: So let's find the equation which can be used to determine which it is.\n",
      "Palabras: 14\n",
      "Embedding: vector_147\n",
      "\n",
      "st_id: 134\n",
      "Texto: And I think we've just been a little bit lazy, kind of running away from this problem for a long time.\n",
      "Palabras: 21\n",
      "Embedding: vector_802\n",
      "\n",
      "st_id: 135\n",
      "Texto: It's been almost taboo to even mention the C word in a lot of circles because, but we should stop making excuses.\n",
      "Palabras: 22\n",
      "Embedding: vector_585\n",
      "\n",
      "st_id: 136\n",
      "Texto: This is a science question and there are ways we can even test any theory that makes predictions for this.\n",
      "Palabras: 20\n",
      "Embedding: vector_727\n",
      "\n",
      "st_id: 137\n",
      "Texto: And coming back to this helper robot, I mean, so you said you'd want your helper robot to certainly act conscious and treat you, like have conversations with you and stuff.\n",
      "Palabras: 31\n",
      "Embedding: vector_40\n",
      "\n",
      "st_id: 138\n",
      "Texto: I think so.\n",
      "Palabras: 3\n",
      "Embedding: vector_324\n",
      "\n",
      "st_id: 139\n",
      "Texto: But wouldn't you, would you feel, would you feel a little bit creeped out if you realized that it was just a glossed up tape recorder, you know, that was just zombie and was a faking emotion?\n",
      "Palabras: 37\n",
      "Embedding: vector_606\n",
      "\n",
      "st_id: 140\n",
      "Texto: Would you prefer that it actually had an experience or would you prefer that it's actually not experiencing anything so you feel, you don't have to feel guilty about what you do to it?\n",
      "Palabras: 34\n",
      "Embedding: vector_990\n",
      "\n",
      "st_id: 141\n",
      "Texto: It's such a difficult question because, you know, it's like when you're in a relationship and you say, well, I love you.\n",
      "Palabras: 22\n",
      "Embedding: vector_277\n",
      "\n",
      "st_id: 142\n",
      "Texto: And the other person said, I love you back.\n",
      "Palabras: 9\n",
      "Embedding: vector_840\n",
      "\n",
      "st_id: 143\n",
      "Texto: It's like asking, well, do they really love you back or are they just saying they love you back?\n",
      "Palabras: 19\n",
      "Embedding: vector_8\n",
      "\n",
      "st_id: 144\n",
      "Texto: Don't you really want them to actually love you?\n",
      "Palabras: 9\n",
      "Embedding: vector_620\n",
      "\n",
      "st_id: 145\n",
      "Texto: It's hard to, it's hard to really know the difference between everything seeming like there's consciousness present, there's intelligence present, there's affection, passion, love, and it actually being there.\n",
      "Palabras: 29\n",
      "Embedding: vector_849\n",
      "\n",
      "st_id: 146\n",
      "Texto: I'm not sure, do you have?\n",
      "Palabras: 6\n",
      "Embedding: vector_597\n",
      "\n",
      "st_id: 147\n",
      "Texto: But like, can I ask you a question about this?\n",
      "Palabras: 10\n",
      "Embedding: vector_293\n",
      "\n",
      "st_id: 148\n",
      "Texto: Like to make it a bit more pointed.\n",
      "Palabras: 8\n",
      "Embedding: vector_795\n",
      "\n",
      "st_id: 149\n",
      "Texto: So Mass General Hospital is right across the river, right?\n",
      "Palabras: 10\n",
      "Embedding: vector_916\n",
      "\n",
      "st_id: 150\n",
      "Texto: Yes.\n",
      "Palabras: 1\n",
      "Embedding: vector_995\n",
      "\n",
      "st_id: 151\n",
      "Texto: Suppose you're going in for a medical procedure and they're like, you know, for anesthesia, what we're going to do is we're going to give you muscle relaxants so you won't be able to move and you're going to feel excruciating pain during the whole surgery, but you won't be able to do anything about it.\n",
      "Palabras: 56\n",
      "Embedding: vector_258\n",
      "\n",
      "st_id: 152\n",
      "Texto: But then we're going to give you this drug that erases your memory of it.\n",
      "Palabras: 15\n",
      "Embedding: vector_373\n",
      "\n",
      "st_id: 153\n",
      "Texto: Would you be cool about that?\n",
      "Palabras: 6\n",
      "Embedding: vector_93\n",
      "\n",
      "st_id: 154\n",
      "Texto: What's the difference that you're conscious about it or not if there's no behavioral change, right?\n",
      "Palabras: 16\n",
      "Embedding: vector_571\n",
      "\n",
      "st_id: 155\n",
      "Texto: Right, that's a really, that's a really clear way to put it.\n",
      "Palabras: 12\n",
      "Embedding: vector_474\n",
      "\n",
      "st_id: 156\n",
      "Texto: That's, yeah, it feels like in that sense, experiencing it is a valuable quality.\n",
      "Palabras: 14\n",
      "Embedding: vector_42\n",
      "\n",
      "st_id: 157\n",
      "Texto: So actually being able to have subjective experiences, at least in that case, is valuable.\n",
      "Palabras: 15\n",
      "Embedding: vector_906\n",
      "\n",
      "st_id: 158\n",
      "Texto: And I think we humans have a little bit of a bad track record also of making these self serving arguments that other entities aren't conscious.\n",
      "Palabras: 26\n",
      "Embedding: vector_303\n",
      "\n",
      "st_id: 159\n",
      "Texto: You know, people often say, oh, these animals can't feel pain.\n",
      "Palabras: 11\n",
      "Embedding: vector_320\n",
      "\n",
      "st_id: 160\n",
      "Texto: It's okay to boil lobsters because we ask them if it hurt and they didn't say anything.\n",
      "Palabras: 17\n",
      "Embedding: vector_516\n",
      "\n",
      "st_id: 161\n",
      "Texto: And now there was just a paper out saying, lobsters do feel pain when you boil them and they're banning it in Switzerland.\n",
      "Palabras: 23\n",
      "Embedding: vector_681\n",
      "\n",
      "st_id: 162\n",
      "Texto: And we did this with slaves too often and said, oh, they don't mind.\n",
      "Palabras: 14\n",
      "Embedding: vector_376\n",
      "\n",
      "st_id: 163\n",
      "Texto: They don't maybe aren't conscious or women don't have souls or whatever.\n",
      "Palabras: 12\n",
      "Embedding: vector_154\n",
      "\n",
      "st_id: 164\n",
      "Texto: So I'm a little bit nervous when I hear people just take as an axiom that machines can't have experience ever.\n",
      "Palabras: 21\n",
      "Embedding: vector_378\n",
      "\n",
      "st_id: 165\n",
      "Texto: I think this is just a really fascinating science question is what it is.\n",
      "Palabras: 14\n",
      "Embedding: vector_653\n",
      "\n",
      "st_id: 166\n",
      "Texto: Let's research it and try to figure out what it is that makes the difference between unconscious intelligent behavior and conscious intelligent behavior.\n",
      "Palabras: 23\n",
      "Embedding: vector_303\n",
      "\n",
      "st_id: 167\n",
      "Texto: So in terms of, so if you think of a Boston Dynamics human or robot being sort of with a broom being pushed around, it starts pushing on a consciousness question.\n",
      "Palabras: 31\n",
      "Embedding: vector_315\n",
      "\n",
      "st_id: 168\n",
      "Texto: So let me ask, do you think an AGI system like a few neuroscientists believe needs to have a physical embodiment?\n",
      "Palabras: 21\n",
      "Embedding: vector_14\n",
      "\n",
      "st_id: 169\n",
      "Texto: Needs to have a body or something like a body?\n",
      "Palabras: 10\n",
      "Embedding: vector_114\n",
      "\n",
      "st_id: 170\n",
      "Texto: No, I don't think so.\n",
      "Palabras: 5\n",
      "Embedding: vector_178\n",
      "\n",
      "st_id: 171\n",
      "Texto: You mean to have a conscious experience?\n",
      "Palabras: 7\n",
      "Embedding: vector_342\n",
      "\n",
      "st_id: 172\n",
      "Texto: To have consciousness.\n",
      "Palabras: 3\n",
      "Embedding: vector_800\n",
      "\n",
      "st_id: 173\n",
      "Texto: I do think it helps a lot to have a physical embodiment to learn the kind of things about the world that are important to us humans, for sure.\n",
      "Palabras: 29\n",
      "Embedding: vector_703\n",
      "\n",
      "st_id: 174\n",
      "Texto: But I don't think the physical embodiment is necessary after you've learned it to just have the experience.\n",
      "Palabras: 18\n",
      "Embedding: vector_908\n",
      "\n",
      "st_id: 175\n",
      "Texto: Think about when you're dreaming, right?\n",
      "Palabras: 6\n",
      "Embedding: vector_206\n",
      "\n",
      "st_id: 176\n",
      "Texto: Your eyes are closed.\n",
      "Palabras: 4\n",
      "Embedding: vector_677\n",
      "\n",
      "st_id: 177\n",
      "Texto: You're not getting any sensory input.\n",
      "Palabras: 6\n",
      "Embedding: vector_75\n",
      "\n",
      "st_id: 178\n",
      "Texto: You're not behaving or moving in any way but there's still an experience there, right?\n",
      "Palabras: 15\n",
      "Embedding: vector_660\n",
      "\n",
      "st_id: 179\n",
      "Texto: And so clearly the experience that you have when you see something cool in your dreams isn't coming from your eyes.\n",
      "Palabras: 21\n",
      "Embedding: vector_813\n",
      "\n",
      "st_id: 180\n",
      "Texto: It's just the information processing itself in your brain which is that experience, right?\n",
      "Palabras: 14\n",
      "Embedding: vector_447\n",
      "\n",
      "st_id: 181\n",
      "Texto: But if I put it another way, I'll say because it comes from neuroscience is the reason you want to have a body and a physical something like a physical, you know, a physical system is because you want to be able to preserve something.\n",
      "Palabras: 45\n",
      "Embedding: vector_848\n",
      "\n",
      "st_id: 182\n",
      "Texto: In order to have a self, you could argue, would you need to have some kind of embodiment of self to want to preserve?\n",
      "Palabras: 24\n",
      "Embedding: vector_405\n",
      "\n",
      "st_id: 183\n",
      "Texto: Well, now we're getting a little bit anthropomorphic into anthropomorphizing things.\n",
      "Palabras: 11\n",
      "Embedding: vector_643\n",
      "\n",
      "st_id: 184\n",
      "Texto: Maybe talking about self preservation instincts.\n",
      "Palabras: 6\n",
      "Embedding: vector_91\n",
      "\n",
      "st_id: 185\n",
      "Texto: I mean, we are evolved organisms, right?\n",
      "Palabras: 7\n",
      "Embedding: vector_205\n",
      "\n",
      "st_id: 186\n",
      "Texto: So Darwinian evolution endowed us and other evolved organism with a self preservation instinct because those that didn't have those self preservation genes We can now, I think, quite convincingly answer that question of no, it's enough to have just one kind.\n",
      "Palabras: 42\n",
      "Embedding: vector_480\n",
      "\n",
      "st_id: 187\n",
      "Texto: If you look under the hood of AlphaZero, there's only one kind of neuron and it's ridiculously simple mathematical thing.\n",
      "Palabras: 20\n",
      "Embedding: vector_218\n",
      "\n",
      "st_id: 188\n",
      "Texto: So it's just like in physics, it's not, if you have a gas with waves in it, it's not the detailed nature of the molecule that matter, it's the collective behavior somehow.\n",
      "Palabras: 32\n",
      "Embedding: vector_651\n",
      "\n",
      "st_id: 189\n",
      "Texto: Similarly, it's this higher level structure of the network that matters, not that you have 20 kinds of neurons.\n",
      "Palabras: 19\n",
      "Embedding: vector_402\n",
      "\n",
      "st_id: 190\n",
      "Texto: I think our brain is such a complicated mess because it wasn't evolved just to be intelligent, it was involved to also be self assembling and self repairing, right?\n",
      "Palabras: 29\n",
      "Embedding: vector_266\n",
      "\n",
      "st_id: 191\n",
      "Texto: And evolutionarily attainable.\n",
      "Palabras: 3\n",
      "Embedding: vector_500\n",
      "\n",
      "st_id: 192\n",
      "Texto: And so on and so on.\n",
      "Palabras: 6\n",
      "Embedding: vector_78\n",
      "\n",
      "st_id: 193\n",
      "Texto: So I think it's pretty, my hunch is that we're going to understand how to build AGI before we fully understand how our brains work, just like we understood how to build flying machines long before we were able to build a mechanical bird.\n",
      "Palabras: 44\n",
      "Embedding: vector_191\n",
      "\n",
      "st_id: 194\n",
      "Texto: Yeah, that's right.\n",
      "Palabras: 3\n",
      "Embedding: vector_581\n",
      "\n",
      "st_id: 195\n",
      "Texto: You've given the example exactly of mechanical birds and airplanes and airplanes do a pretty good job of flying without really mimicking bird flight.\n",
      "Palabras: 24\n",
      "Embedding: vector_68\n",
      "\n",
      "st_id: 196\n",
      "Texto: And even now after 100 years later, did you see the Ted talk with this German mechanical bird?\n",
      "Palabras: 18\n",
      "Embedding: vector_672\n",
      "\n",
      "st_id: 197\n",
      "Texto: I heard you mention it.\n",
      "Palabras: 5\n",
      "Embedding: vector_162\n",
      "\n",
      "st_id: 198\n",
      "Texto: Check it out, it's amazing.\n",
      "Palabras: 5\n",
      "Embedding: vector_416\n",
      "\n",
      "st_id: 199\n",
      "Texto: But even after that, right, we still don't fly in mechanical birds because it turned out the way we came up with was simpler and it's better for our purposes.\n",
      "Palabras: 30\n",
      "Embedding: vector_212\n",
      "\n",
      "st_id: 200\n",
      "Texto: And I think it might be the same there.\n",
      "Palabras: 9\n",
      "Embedding: vector_686\n",
      "\n",
      "st_id: 201\n",
      "Texto: That's one lesson.\n",
      "Palabras: 3\n",
      "Embedding: vector_108\n",
      "\n",
      "st_id: 202\n",
      "Texto: And another lesson, it's more what our paper was about.\n",
      "Palabras: 10\n",
      "Embedding: vector_33\n",
      "\n",
      "st_id: 203\n",
      "Texto: First, as a physicist thought it was fascinating how there's a very close mathematical relationship actually between our artificial neural networks and a lot of things that we've studied for in physics go by nerdy names like the renormalization group equation and Hamiltonians and yada, yada, yada.\n",
      "Palabras: 47\n",
      "Embedding: vector_991\n",
      "\n",
      "st_id: 204\n",
      "Texto: And when you look a little more closely at this, you have, at first I was like, well, there's something crazy here that doesn't make sense.\n",
      "Palabras: 26\n",
      "Embedding: vector_758\n",
      "\n",
      "st_id: 205\n",
      "Texto: Because we know that if you even want to build a super simple neural network to tell apart cat pictures and dog pictures, right, that you can do that very, very well now.\n",
      "Palabras: 33\n",
      "Embedding: vector_76\n",
      "\n",
      "st_id: 206\n",
      "Texto: But if you think about it a little bit, you convince yourself it must be impossible because if I have one megapixel, even if each pixel is just black or white, there's two to the power of 1 million possible images, which is way more than there are atoms in our universe, right, so in order to, and then for each one of those, I have to assign a number, which is the probability that it's a dog.\n",
      "Palabras: 78\n",
      "Embedding: vector_420\n",
      "\n",
      "st_id: 207\n",
      "Texto: So an arbitrary function of images is a list of more numbers than there are atoms in our universe.\n",
      "Palabras: 19\n",
      "Embedding: vector_110\n",
      "\n",
      "st_id: 208\n",
      "Texto: So clearly I can't store that under the hood of my GPU or my computer, yet somehow it works.\n",
      "Palabras: 19\n",
      "Embedding: vector_421\n",
      "\n",
      "st_id: 209\n",
      "Texto: So what does that mean?\n",
      "Palabras: 5\n",
      "Embedding: vector_244\n",
      "\n",
      "st_id: 210\n",
      "Texto: Well, it means that out of all of the problems that you could try to solve with a neural network, almost all of them are impossible to solve with a reasonably sized one.\n",
      "Palabras: 33\n",
      "Embedding: vector_783\n",
      "\n",
      "st_id: 211\n",
      "Texto: But then what we showed in our paper was that the fraction, the kind of problems, the fraction of all the problems that you could possibly pose, that we actually care about given the laws of physics is also an infinite testimony, tiny little part.\n",
      "Palabras: 45\n",
      "Embedding: vector_924\n",
      "\n",
      "st_id: 212\n",
      "Texto: And amazingly, they're basically the same part.\n",
      "Palabras: 7\n",
      "Embedding: vector_590\n",
      "\n",
      "st_id: 213\n",
      "Texto: Yeah, it's almost like our world was created for, I mean, they kind of come together.\n",
      "Palabras: 16\n",
      "Embedding: vector_794\n",
      "\n",
      "st_id: 214\n",
      "Texto: Yeah, well, you could say maybe where the world was created for us, but I have a more modest interpretation, which is that the world was created for us, but I have a more modest interpretation, which is that instead evolution endowed us with neural networks precisely for that reason.\n",
      "Palabras: 50\n",
      "Embedding: vector_4\n",
      "\n",
      "st_id: 215\n",
      "Texto: Because this particular architecture, as opposed to the one in your laptop, is very, very well adapted to solving the kind of problems that nature kept presenting our ancestors with.\n",
      "Palabras: 30\n",
      "Embedding: vector_504\n",
      "\n",
      "st_id: 216\n",
      "Texto: So it makes sense that why do we have a brain in the first place?\n",
      "Palabras: 15\n",
      "Embedding: vector_479\n",
      "\n",
      "st_id: 217\n",
      "Texto: It's to be able to make predictions about the future and so on.\n",
      "Palabras: 13\n",
      "Embedding: vector_874\n",
      "\n",
      "st_id: 218\n",
      "Texto: So if we had a sucky system, which could never solve it, we wouldn't have a world.\n",
      "Palabras: 17\n",
      "Embedding: vector_200\n",
      "\n",
      "st_id: 219\n",
      "Texto: So this is, I think, a very beautiful fact.\n",
      "Palabras: 9\n",
      "Embedding: vector_647\n",
      "\n",
      "st_id: 220\n",
      "Texto: Yeah.\n",
      "Palabras: 1\n",
      "Embedding: vector_21\n",
      "\n",
      "st_id: 221\n",
      "Texto: We also realize that there's been earlier work on why deeper networks are good, but we were able to show an additional cool fact there, which is that even incredibly simple problems, like suppose I give you a thousand numbers and ask you to multiply them together, and you can write a few lines of code, boom, done, trivial.\n",
      "Palabras: 59\n",
      "Embedding: vector_822\n",
      "\n",
      "st_id: 222\n",
      "Texto: If you just try to do that with a neural network that has only one single hidden layer in it, you can do it, but you're going to need two to the power of a thousand neurons to multiply a thousand numbers, which is, again, more neurons than there are atoms in our universe.\n",
      "Palabras: 54\n",
      "Embedding: vector_196\n",
      "\n",
      "st_id: 223\n",
      "Texto: That's fascinating.\n",
      "Palabras: 2\n",
      "Embedding: vector_392\n",
      "\n",
      "st_id: 224\n",
      "Texto: But if you allow yourself to make it a deep network with many layers, you only need 4,000 neurons.\n",
      "Palabras: 19\n",
      "Embedding: vector_572\n",
      "\n",
      "st_id: 225\n",
      "Texto: It's perfectly feasible.\n",
      "Palabras: 3\n",
      "Embedding: vector_888\n",
      "\n",
      "st_id: 226\n",
      "Texto: That's really interesting.\n",
      "Palabras: 3\n",
      "Embedding: vector_911\n",
      "\n",
      "st_id: 227\n",
      "Texto: Yeah.\n",
      "Palabras: 1\n",
      "Embedding: vector_21\n",
      "\n",
      "st_id: 228\n",
      "Texto: So on another architecture type, I mean, you mentioned Schrodinger's equation, and what are your thoughts about quantum computing and the role of this kind of computational unit in creating an intelligence system?\n",
      "Palabras: 33\n",
      "Embedding: vector_743\n",
      "\n",
      "st_id: 229\n",
      "Texto: In some Hollywood movies that I will not mention by name because I don't want to spoil them.\n",
      "Palabras: 18\n",
      "Embedding: vector_159\n",
      "\n",
      "st_id: 230\n",
      "Texto: The way they get AGI is building a quantum computer.\n",
      "Palabras: 10\n",
      "Embedding: vector_974\n",
      "\n",
      "st_id: 231\n",
      "Texto: Because the word quantum sounds cool and so on.\n",
      "Palabras: 9\n",
      "Embedding: vector_839\n",
      "\n",
      "st_id: 232\n",
      "Texto: That's right.\n",
      "Palabras: 2\n",
      "Embedding: vector_356\n",
      "\n",
      "st_id: 233\n",
      "Texto: First of all, I think we don't need quantum computers to build AGI.\n",
      "Palabras: 13\n",
      "Embedding: vector_392\n",
      "\n",
      "st_id: 234\n",
      "Texto: I suspect your brain is not a quantum computer in any profound sense.\n",
      "Palabras: 13\n",
      "Embedding: vector_202\n",
      "\n",
      "st_id: 235\n",
      "Texto: So you don't even wrote a paper about that a lot many years ago.\n",
      "Palabras: 14\n",
      "Embedding: vector_786\n",
      "\n",
      "st_id: 236\n",
      "Texto: I calculated the so called decoherence time, how long it takes until the quantum computerness of what your neurons are doing gets erased by just random noise from the environment.\n",
      "Palabras: 30\n",
      "Embedding: vector_595\n",
      "\n",
      "st_id: 237\n",
      "Texto: And it's about 10 to the minus 21 seconds.\n",
      "Palabras: 9\n",
      "Embedding: vector_780\n",
      "\n",
      "st_id: 238\n",
      "Texto: So as cool as it would be to have a quantum computer in my head, I don't think that fast.\n",
      "Palabras: 20\n",
      "Embedding: vector_220\n",
      "\n",
      "st_id: 239\n",
      "Texto: On the other hand, there are very cool things you could do with quantum computers.\n",
      "Palabras: 15\n",
      "Embedding: vector_429\n",
      "\n",
      "st_id: 240\n",
      "Texto: Or I think we'll be able to do soon when we get bigger ones.\n",
      "Palabras: 14\n",
      "Embedding: vector_599\n",
      "\n",
      "st_id: 241\n",
      "Texto: That might actually help machine learning do even better than the brain.\n",
      "Palabras: 12\n",
      "Embedding: vector_145\n",
      "\n",
      "st_id: 242\n",
      "Texto: So for example, one, this is just a moonshot, but learning is very much same thing as search.\n",
      "Palabras: 18\n",
      "Embedding: vector_621\n",
      "\n",
      "st_id: 243\n",
      "Texto: If you're trying to train a neural network to get really learned to do something really well, you have some loss function, you have a bunch of knobs you can turn, represented by a bunch of numbers, and you're trying to tweak them so that it becomes as good as possible at this thing.\n",
      "Palabras: 54\n",
      "Embedding: vector_602\n",
      "\n",
      "st_id: 244\n",
      "Texto: So if you think of a landscape with some valley, where each dimension of the landscape corresponds to some number you can change, you're trying to find the minimum.\n",
      "Palabras: 29\n",
      "Embedding: vector_45\n",
      "\n",
      "st_id: 245\n",
      "Texto: And it's well known that if you have a very high dimensional landscape, complicated things, it's super hard to find the minimum.\n",
      "Palabras: 22\n",
      "Embedding: vector_251\n",
      "\n",
      "st_id: 246\n",
      "Texto: Quantum mechanics is amazingly good at this.\n",
      "Palabras: 7\n",
      "Embedding: vector_856\n",
      "\n",
      "st_id: 247\n",
      "Texto: Like if I want to know what's the lowest energy state this water can possibly have, incredibly hard to compute, but nature will happily figure this out for you if you just cool it down, make it very, very cold.\n",
      "Palabras: 40\n",
      "Embedding: vector_996\n",
      "\n",
      "st_id: 248\n",
      "Texto: If you put a ball somewhere, it'll roll down to its minimum.\n",
      "Palabras: 12\n",
      "Embedding: vector_769\n",
      "\n",
      "st_id: 249\n",
      "Texto: And this happens metaphorically at the energy landscape too.\n",
      "Palabras: 9\n",
      "Embedding: vector_731\n",
      "\n",
      "st_id: 250\n",
      "Texto: And quantum mechanics even uses some clever tricks, which today's machine learning systems don't.\n",
      "Palabras: 14\n",
      "Embedding: vector_871\n",
      "\n",
      "st_id: 251\n",
      "Texto: Like if you're trying to find the minimum and you get stuck in the little local minimum here, in quantum mechanics you can actually tunnel through the barrier and get unstuck again.\n",
      "Palabras: 32\n",
      "Embedding: vector_159\n",
      "\n",
      "st_id: 252\n",
      "Texto: That's really interesting.\n",
      "Palabras: 3\n",
      "Embedding: vector_911\n",
      "\n",
      "st_id: 253\n",
      "Texto: Yeah, so it may be, for example, that we'll one day use quantum computers that help train neural networks better.\n",
      "Palabras: 20\n",
      "Embedding: vector_505\n",
      "\n",
      "st_id: 254\n",
      "Texto: That's really interesting.\n",
      "Palabras: 3\n",
      "Embedding: vector_911\n",
      "\n",
      "st_id: 255\n",
      "Texto: Okay, so as a component of kind of the learning process, for example.\n",
      "Palabras: 13\n",
      "Embedding: vector_650\n",
      "\n",
      "st_id: 256\n",
      "Texto: Yeah.\n",
      "Palabras: 1\n",
      "Embedding: vector_21\n",
      "\n",
      "st_id: 257\n",
      "Texto: Let me ask sort of wrapping up here a little bit, let me return to the questions of our human nature and love, as I mentioned.\n",
      "Palabras: 26\n",
      "Embedding: vector_875\n",
      "\n",
      "st_id: 258\n",
      "Texto: So do you think, you mentioned sort of a helper robot, but you could think of also personal robots.\n",
      "Palabras: 19\n",
      "Embedding: vector_125\n",
      "\n",
      "st_id: 259\n",
      "Texto: Do you think the way we human beings fall in love and get connected to each other is possible to achieve in an AI system and human level AI intelligence system?\n",
      "Palabras: 31\n",
      "Embedding: vector_315\n",
      "\n",
      "st_id: 260\n",
      "Texto: Do you think we would ever see that kind of connection?\n",
      "Palabras: 11\n",
      "Embedding: vector_310\n",
      "\n",
      "st_id: 261\n",
      "Texto: Or, you know, in all this discussion about solving complex goals, is this kind of human social connection, do you think that's one of the goals on the peaks and valleys with the raising sea levels that we'll be able to achieve?\n",
      "Palabras: 42\n",
      "Embedding: vector_98\n",
      "\n",
      "st_id: 262\n",
      "Texto: Or do you think that's something that's ultimately, or at least in the short term, relative to the other goals is not achievable?\n",
      "Palabras: 23\n",
      "Embedding: vector_606\n",
      "\n",
      "st_id: 263\n",
      "Texto: I think it's all possible.\n",
      "Palabras: 5\n",
      "Embedding: vector_861\n",
      "\n",
      "st_id: 264\n",
      "Texto: And I mean, in recent, there's a very wide range of guesses, as you know, among AI researchers, when we're going to get AGI.\n",
      "Palabras: 24\n",
      "Embedding: vector_803\n",
      "\n",
      "st_id: 265\n",
      "Texto: Some people, you know, like our friend Rodney Brooks says it's going to be hundreds of years at least.\n",
      "Palabras: 19\n",
      "Embedding: vector_667\n",
      "\n",
      "st_id: 266\n",
      "Texto: And then there are many others who think it's going to happen much sooner.\n",
      "Palabras: 14\n",
      "Embedding: vector_182\n",
      "\n",
      "st_id: 267\n",
      "Texto: And recent polls, maybe half or so of AI researchers think we're going to get AGI within decades.\n",
      "Palabras: 18\n",
      "Embedding: vector_479\n",
      "\n",
      "st_id: 268\n",
      "Texto: So if that happens, of course, then I think these things are all possible.\n",
      "Palabras: 14\n",
      "Embedding: vector_885\n",
      "\n",
      "st_id: 269\n",
      "Texto: But in terms of whether it will happen, I think we shouldn't spend so much time asking what do we think will happen in the future?\n",
      "Palabras: 26\n",
      "Embedding: vector_751\n",
      "\n",
      "st_id: 270\n",
      "Texto: As if we are just some sort of pathetic, your passive bystanders, you know, waiting for the future to happen to us.\n",
      "Palabras: 22\n",
      "Embedding: vector_519\n",
      "\n",
      "st_id: 271\n",
      "Texto: Hey, we're the ones creating this future, right?\n",
      "Palabras: 8\n",
      "Embedding: vector_246\n",
      "\n",
      "st_id: 272\n",
      "Texto: So we should be proactive about it and ask ourselves what sort of future we would like to have happen.\n",
      "Palabras: 20\n",
      "Embedding: vector_117\n",
      "\n",
      "st_id: 273\n",
      "Texto: We're going to make it like that.\n",
      "Palabras: 7\n",
      "Embedding: vector_41\n",
      "\n",
      "st_id: 274\n",
      "Texto: Well, what I prefer is just some sort of incredibly boring, zombie like future where there's all these mechanical things happening and there's no passion, no emotion, no experience, maybe even.\n",
      "Palabras: 31\n",
      "Embedding: vector_442\n",
      "\n",
      "st_id: 275\n",
      "Texto: No, I would of course, much rather prefer it if all the things that we find that we value the most about humanity are our subjective experience, passion, inspiration, love, you know.\n",
      "Palabras: 32\n",
      "Embedding: vector_666\n",
      "\n",
      "st_id: 276\n",
      "Texto: If we can create a future where those things do happen, where those things do exist, you know, I think ultimately it's not our universe giving meaning to us, it's us giving meaning to our universe.\n",
      "Palabras: 36\n",
      "Embedding: vector_698\n",
      "\n",
      "st_id: 277\n",
      "Texto: And if we build more advanced intelligence, let's make sure we build it in such a way that meaning is part of it.\n",
      "Palabras: 23\n",
      "Embedding: vector_789\n",
      "\n",
      "st_id: 278\n",
      "Texto: A lot of people that seriously study this problem and think of it from different angles have trouble in the majority of cases, if they think through that happen, are the ones that are not beneficial to humanity.\n",
      "Palabras: 38\n",
      "Embedding: vector_362\n",
      "\n",
      "st_id: 279\n",
      "Texto: And so, yeah, so what are your thoughts?\n",
      "Palabras: 8\n",
      "Embedding: vector_612\n",
      "\n",
      "st_id: 280\n",
      "Texto: What's should people, you know, I really don't like people to be terrified.\n",
      "Palabras: 13\n",
      "Embedding: vector_907\n",
      "\n",
      "st_id: 281\n",
      "Texto: What's a way for people to think about it in a way we can solve it and we can make it better?\n",
      "Palabras: 22\n",
      "Embedding: vector_299\n",
      "\n",
      "st_id: 282\n",
      "Texto: No, I don't think panicking is going to help in any way.\n",
      "Palabras: 12\n",
      "Embedding: vector_8\n",
      "\n",
      "st_id: 283\n",
      "Texto: It's not going to increase chances of things going well either.\n",
      "Palabras: 11\n",
      "Embedding: vector_65\n",
      "\n",
      "st_id: 284\n",
      "Texto: Even if you are in a situation where there is a real threat, does it help if everybody just freaks out?\n",
      "Palabras: 21\n",
      "Embedding: vector_285\n",
      "\n",
      "st_id: 285\n",
      "Texto: No, of course, of course not.\n",
      "Palabras: 6\n",
      "Embedding: vector_836\n",
      "\n",
      "st_id: 286\n",
      "Texto: I think, yeah, there are of course ways in which things can go horribly wrong.\n",
      "Palabras: 15\n",
      "Embedding: vector_701\n",
      "\n",
      "st_id: 287\n",
      "Texto: First of all, it's important when we think about this thing, about the problems and risks, to also remember how huge the upsides can be if we get it right, right?\n",
      "Palabras: 31\n",
      "Embedding: vector_985\n",
      "\n",
      "st_id: 288\n",
      "Texto: Everything we love about society and civilization is a product of intelligence.\n",
      "Palabras: 12\n",
      "Embedding: vector_10\n",
      "\n",
      "st_id: 289\n",
      "Texto: So if we can amplify our intelligence with machine intelligence and not anymore lose our loved one to what we're told is an incurable disease and things like this, of course, we should aspire to that.\n",
      "Palabras: 36\n",
      "Embedding: vector_778\n",
      "\n",
      "st_id: 290\n",
      "Texto: So that can be a motivator, I think, reminding ourselves that the reason we try to solve problems is not just because we're trying to avoid gloom, but because we're trying to do something great.\n",
      "Palabras: 35\n",
      "Embedding: vector_906\n",
      "\n",
      "st_id: 291\n",
      "Texto: But then in terms of the risks, I think the really important question is to ask, what can we do today that will actually help make the outcome good, right?\n",
      "Palabras: 30\n",
      "Embedding: vector_96\n",
      "\n",
      "st_id: 292\n",
      "Texto: And dismissing the risk is not one of them.\n",
      "Palabras: 9\n",
      "Embedding: vector_474\n",
      "\n",
      "st_id: 293\n",
      "Texto: I find it quite funny often when I'm in discussion panels about these things, how the people who work for companies, always be like, oh, nothing to worry about, nothing to worry about, nothing to worry about.\n",
      "Palabras: 37\n",
      "Embedding: vector_189\n",
      "\n",
      "st_id: 294\n",
      "Texto: And it's only academics sometimes express concerns.\n",
      "Palabras: 7\n",
      "Embedding: vector_311\n",
      "\n",
      "st_id: 295\n",
      "Texto: That's not surprising at all if you think about it.\n",
      "Palabras: 10\n",
      "Embedding: vector_287\n",
      "\n",
      "st_id: 296\n",
      "Texto: Right.\n",
      "Palabras: 1\n",
      "Embedding: vector_688\n",
      "\n",
      "st_id: 297\n",
      "Texto: Upton Sinclair quipped, right, that it's hard to make a man believe in something when his income depends on not believing in it.\n",
      "Palabras: 23\n",
      "Embedding: vector_928\n",
      "\n",
      "st_id: 298\n",
      "Texto: And frankly, we know a lot of these people in companies that they're just as concerned as anyone else.\n",
      "Palabras: 19\n",
      "Embedding: vector_516\n",
      "\n",
      "st_id: 299\n",
      "Texto: But if you're the CEO of a company, that's not something you want to go on record saying when you have silly journalists who are gonna put a picture of a Terminator robot when they quote you.\n",
      "Palabras: 37\n",
      "Embedding: vector_333\n",
      "\n",
      "st_id: 300\n",
      "Texto: So the issues are real.\n",
      "Palabras: 5\n",
      "Embedding: vector_481\n",
      "\n",
      "st_id: 301\n",
      "Texto: And the way I think about what the issue is, is basically the real choice we have is, first of all, are we gonna just dismiss the risks and say, well, let's just go ahead and build machines that can do everything we can do better and cheaper.\n",
      "Palabras: 48\n",
      "Embedding: vector_864\n",
      "\n",
      "st_id: 302\n",
      "Texto: Let's just make ourselves obsolete as fast as possible.\n",
      "Palabras: 9\n",
      "Embedding: vector_103\n",
      "\n",
      "st_id: 303\n",
      "Texto: What could possibly go wrong?\n",
      "Palabras: 5\n",
      "Embedding: vector_394\n",
      "\n",
      "st_id: 304\n",
      "Texto: That's one attitude.\n",
      "Palabras: 3\n",
      "Embedding: vector_728\n",
      "\n",
      "st_id: 305\n",
      "Texto: The opposite attitude, I think, is to say, here's this incredible potential, let's think about what kind of future we're really, really excited about.\n",
      "Palabras: 24\n",
      "Embedding: vector_791\n",
      "\n",
      "st_id: 306\n",
      "Texto: What are the shared goals that we can really aspire towards?\n",
      "Palabras: 11\n",
      "Embedding: vector_832\n",
      "\n",
      "st_id: 307\n",
      "Texto: And then let's think really hard about how we can actually get there.\n",
      "Palabras: 13\n",
      "Embedding: vector_868\n",
      "\n",
      "st_id: 308\n",
      "Texto: So start with, don't start thinking about the risks, start thinking about the goals.\n",
      "Palabras: 14\n",
      "Embedding: vector_625\n",
      "\n",
      "st_id: 309\n",
      "Texto: And then when you do that, then you can think about the obstacles you want to avoid.\n",
      "Palabras: 17\n",
      "Embedding: vector_662\n",
      "\n",
      "st_id: 310\n",
      "Texto: I often get students coming in right here into my office for career advice.\n",
      "Palabras: 14\n",
      "Embedding: vector_939\n",
      "\n",
      "st_id: 311\n",
      "Texto: I always ask them this very question, where do you want to be in the future?\n",
      "Palabras: 16\n",
      "Embedding: vector_414\n",
      "\n",
      "st_id: 312\n",
      "Texto: If all she can say is, oh, maybe I'll have cancer, maybe I'll get run over by a truck.\n",
      "Palabras: 19\n",
      "Embedding: vector_167\n",
      "\n",
      "st_id: 313\n",
      "Texto: Yeah, focus on the obstacles instead of the goals.\n",
      "Palabras: 9\n",
      "Embedding: vector_890\n",
      "\n",
      "st_id: 314\n",
      "Texto: She's just going to end up a hypochondriac paranoid.\n",
      "Palabras: 9\n",
      "Embedding: vector_252\n",
      "\n",
      "st_id: 315\n",
      "Texto: Whereas if she comes in and fire in her eyes and is like, I want to be there.\n",
      "Palabras: 18\n",
      "Embedding: vector_393\n",
      "\n",
      "st_id: 316\n",
      "Texto: And then we can talk about the obstacles and see how we can circumvent them.\n",
      "Palabras: 15\n",
      "Embedding: vector_340\n",
      "\n",
      "st_id: 317\n",
      "Texto: That's, I think, a much, much healthier attitude.\n",
      "Palabras: 8\n",
      "Embedding: vector_820\n",
      "\n",
      "st_id: 318\n",
      "Texto: And I feel it's very challenging to come up with a vision for the future, which we are unequivocally excited about.\n",
      "Palabras: 21\n",
      "Embedding: vector_508\n",
      "\n",
      "st_id: 319\n",
      "Texto: I'm not just talking now in the vague terms, like, yeah, let's cure cancer, fine.\n",
      "Palabras: 15\n",
      "Embedding: vector_185\n",
      "\n",
      "st_id: 320\n",
      "Texto: I'm talking about what kind of society do we want to create?\n",
      "Palabras: 12\n",
      "Embedding: vector_489\n",
      "\n",
      "st_id: 321\n",
      "Texto: What do we want it to mean to be human in the age of AI, in the age of AGI?\n",
      "Palabras: 20\n",
      "Embedding: vector_161\n",
      "\n",
      "st_id: 322\n",
      "Texto: So if we can have this conversation, broad, inclusive conversation, and gradually start converging towards some, some future that with some direction, at least, that we want to steer towards, right, then we'll be much more motivated to constructively take on the obstacles.\n",
      "Palabras: 43\n",
      "Embedding: vector_648\n",
      "\n",
      "st_id: 323\n",
      "Texto: And I think if I had, if I had to, if I try to wrap this up in a more succinct way, I think we can all agree already now that we should aspire to build AGI that doesn't overpower us, but that empowers us.\n",
      "Palabras: 45\n",
      "Embedding: vector_338\n",
      "\n",
      "st_id: 324\n",
      "Texto: And think of the many various ways that can do that, whether that's from my side of the world of autonomous vehicles.\n",
      "Palabras: 22\n",
      "Embedding: vector_347\n",
      "\n",
      "st_id: 325\n",
      "Texto: I'm personally actually from the camp that believes this human level intelligence is required to achieve something like vehicles that would actually be something we would enjoy using and being part of.\n",
      "Palabras: 32\n",
      "Embedding: vector_582\n",
      "\n",
      "st_id: 326\n",
      "Texto: So that's one example, and certainly there's a lot of other types of robots and medicine and so on.\n",
      "Palabras: 19\n",
      "Embedding: vector_42\n",
      "\n",
      "st_id: 327\n",
      "Texto: So focusing on those and then coming up with the obstacles, coming up with the ways that that can go wrong and solving those one at a time.\n",
      "Palabras: 28\n",
      "Embedding: vector_411\n",
      "\n",
      "st_id: 328\n",
      "Texto: And just because you can build an autonomous vehicle, even if you could build one that would drive just fine without you, maybe there are some things in life that we would actually want to do ourselves.\n",
      "Palabras: 37\n",
      "Embedding: vector_435\n",
      "\n",
      "st_id: 329\n",
      "Texto: That's right.\n",
      "Palabras: 2\n",
      "Embedding: vector_356\n",
      "\n",
      "st_id: 330\n",
      "Texto: Right, like, for example, if you think of our society as a whole, there are some things that we find very meaningful to do.\n",
      "Palabras: 24\n",
      "Embedding: vector_280\n",
      "\n",
      "st_id: 331\n",
      "Texto: And that doesn't mean we have to stop doing them just because machines can do them better.\n",
      "Palabras: 17\n",
      "Embedding: vector_616\n",
      "\n",
      "st_id: 332\n",
      "Texto: I'm not gonna stop playing tennis just the day someone builds a tennis robot and beat me.\n",
      "Palabras: 17\n",
      "Embedding: vector_609\n",
      "\n",
      "st_id: 333\n",
      "Texto: People are still playing chess and even go.\n",
      "Palabras: 8\n",
      "Embedding: vector_580\n",
      "\n",
      "st_id: 334\n",
      "Texto: Yeah, and in the very near term even, some people are advocating basic income, replace jobs.\n",
      "Palabras: 16\n",
      "Embedding: vector_317\n",
      "\n",
      "st_id: 335\n",
      "Texto: But if the government is gonna be willing to just hand out cash to people for doing nothing, then one should also seriously consider whether the government should also hire a lot more teachers and nurses and the kind of jobs which people often find great fulfillment in doing, right?\n",
      "Palabras: 50\n",
      "Embedding: vector_163\n",
      "\n",
      "st_id: 336\n",
      "Texto: We get very tired of hearing politicians saying, oh, we can't afford hiring more teachers, but we're gonna maybe have basic income.\n",
      "Palabras: 22\n",
      "Embedding: vector_30\n",
      "\n",
      "st_id: 337\n",
      "Texto: If we can have more serious research and thought into what gives meaning to our lives, the jobs give so much more than income, right?\n",
      "Palabras: 25\n",
      "Embedding: vector_742\n",
      "\n",
      "st_id: 338\n",
      "Texto: Mm hmm.\n",
      "Palabras: 2\n",
      "Embedding: vector_984\n",
      "\n",
      "st_id: 339\n",
      "Texto: And then think about in the future, what are the roles that we wanna have people continually feeling empowered by machines?\n",
      "Palabras: 21\n",
      "Embedding: vector_902\n",
      "\n",
      "st_id: 340\n",
      "Texto: And I think sort of, I come from Russia, from the Soviet Union.\n",
      "Palabras: 13\n",
      "Embedding: vector_89\n",
      "\n",
      "st_id: 341\n",
      "Texto: And I think for a lot of people in the 20th century, going to the moon, going to space was an inspiring thing.\n",
      "Palabras: 23\n",
      "Embedding: vector_788\n",
      "\n",
      "st_id: 342\n",
      "Texto: I feel like the universe of the mind, so AI, understanding, creating intelligence is that for the 21st century.\n",
      "Palabras: 19\n",
      "Embedding: vector_190\n",
      "\n",
      "st_id: 343\n",
      "Texto: So it's really surprising.\n",
      "Palabras: 4\n",
      "Embedding: vector_288\n",
      "\n",
      "st_id: 344\n",
      "Texto: And I've heard you mention this.\n",
      "Palabras: 6\n",
      "Embedding: vector_568\n",
      "\n",
      "st_id: 345\n",
      "Texto: It's really surprising to me, both on the research funding side, that it's not funded as greatly as it could be, but most importantly, on the politician side, that it's not part of the public discourse except in the killer bots terminator kind of view, that people are not yet, I think, perhaps excited by the possible positive future that we can build together.\n",
      "Palabras: 64\n",
      "Embedding: vector_753\n",
      "\n",
      "st_id: 346\n",
      "Texto: So we should be, because politicians usually just focus on the next election cycle, right?\n",
      "Palabras: 15\n",
      "Embedding: vector_541\n",
      "\n",
      "st_id: 347\n",
      "Texto: The single most important thing I feel we humans have learned in the entire history of science is they were the masters of underestimation.\n",
      "Palabras: 24\n",
      "Embedding: vector_436\n",
      "\n",
      "st_id: 348\n",
      "Texto: We underestimated the size of our cosmos again and again, realizing that everything we thought existed was just a small part of something grander, right?\n",
      "Palabras: 25\n",
      "Embedding: vector_410\n",
      "\n",
      "st_id: 349\n",
      "Texto: Planet, solar system, the galaxy, clusters of galaxies.\n",
      "Palabras: 8\n",
      "Embedding: vector_463\n",
      "\n",
      "st_id: 350\n",
      "Texto: The universe.\n",
      "Palabras: 2\n",
      "Embedding: vector_98\n",
      "\n",
      "st_id: 351\n",
      "Texto: And we now know that the future has just so much more potential than our ancestors could ever have dreamt of.\n",
      "Palabras: 21\n",
      "Embedding: vector_201\n",
      "\n",
      "st_id: 352\n",
      "Texto: This cosmos, imagine if all of Earth was completely devoid of life, except for Cambridge, Massachusetts.\n",
      "Palabras: 16\n",
      "Embedding: vector_962\n",
      "\n",
      "st_id: 353\n",
      "Texto: Wouldn't it be kind of lame if all we ever aspired to was to stay in Cambridge, Massachusetts forever and then go extinct in one week, even though Earth was gonna continue on for longer?\n",
      "Palabras: 35\n",
      "Embedding: vector_788\n",
      "\n",
      "st_id: 354\n",
      "Texto: That sort of attitude I think we have now on the cosmic scale, life can flourish on Earth, not for four years, but for billions of years.\n",
      "Palabras: 27\n",
      "Embedding: vector_382\n",
      "\n",
      "st_id: 355\n",
      "Texto: I can even tell you about how to move it out of harm's way when the sun gets too hot.\n",
      "Palabras: 20\n",
      "Embedding: vector_666\n",
      "\n",
      "st_id: 356\n",
      "Texto: And then we have so much more resources out here, which today, maybe there are a lot of other planets with bacteria or cow like life on them, but most of this, all this opportunity seems, as far as we can tell, to be largely dead, like the Sahara Desert.\n",
      "Palabras: 50\n",
      "Embedding: vector_798\n",
      "\n",
      "st_id: 357\n",
      "Texto: And yet we have the opportunity to help life flourish around this for billions of years.\n",
      "Palabras: 16\n",
      "Embedding: vector_973\n",
      "\n",
      "st_id: 358\n",
      "Texto: So let's quit squabbling about whether some little border should be drawn one mile to the left or right, and look up into the skies and realize, hey, we can do such incredible things.\n",
      "Palabras: 34\n",
      "Embedding: vector_708\n",
      "\n",
      "st_id: 359\n",
      "Texto: Yeah, and that's, I think, why it's really exciting that you and others are connected with some of the work Elon Musk is doing, because he's literally going out into that space, really exploring our universe, and it's wonderful.\n",
      "Palabras: 39\n",
      "Embedding: vector_567\n",
      "\n",
      "st_id: 360\n",
      "Texto: That is exactly why Elon Musk is so misunderstood, right?\n",
      "Palabras: 10\n",
      "Embedding: vector_806\n",
      "\n",
      "st_id: 361\n",
      "Texto: Misconstrued him as some kind of pessimistic doomsayer.\n",
      "Palabras: 8\n",
      "Embedding: vector_459\n",
      "\n",
      "st_id: 362\n",
      "Texto: The reason he cares so much about AI safety is because he more than almost anyone else appreciates these amazing opportunities that we'll squander if we wipe out here on Earth.\n",
      "Palabras: 31\n",
      "Embedding: vector_629\n",
      "\n",
      "st_id: 363\n",
      "Texto: We're not just going to wipe out the next generation, all generations, and this incredible opportunity that's out there, and that would really be a waste.\n",
      "Palabras: 26\n",
      "Embedding: vector_530\n",
      "\n",
      "st_id: 364\n",
      "Texto: And AI, for people who think that it would be better to do without technology, let me just mention that if we don't improve our technology, the question isn't whether humanity is going to go extinct.\n",
      "Palabras: 36\n",
      "Embedding: vector_621\n",
      "\n",
      "st_id: 365\n",
      "Texto: The question is just whether we're going to get taken out by the next big asteroid or the next super volcano or something else dumb that we could easily prevent with more tech, right?\n",
      "Palabras: 34\n",
      "Embedding: vector_851\n",
      "\n",
      "st_id: 366\n",
      "Texto: And if we want life to flourish throughout the cosmos, AI is the key to it.\n",
      "Palabras: 16\n",
      "Embedding: vector_122\n",
      "\n",
      "st_id: 367\n",
      "Texto: As I mentioned in a lot of detail in my book right there, even many of the most inspired sci fi writers, I feel have totally underestimated the opportunities for space travel, especially at the other galaxies, because they weren't thinking about the possibility of AGI, which just makes it so much easier.\n",
      "Palabras: 53\n",
      "Embedding: vector_303\n",
      "\n",
      "st_id: 368\n",
      "Texto: Right, yeah.\n",
      "Palabras: 2\n",
      "Embedding: vector_465\n",
      "\n",
      "st_id: 369\n",
      "Texto: So that goes to your view of AGI that enables our progress, that enables a better life.\n",
      "Palabras: 17\n",
      "Embedding: vector_378\n",
      "\n",
      "st_id: 370\n",
      "Texto: So that's a beautiful way to put it and then something to strive for.\n",
      "Palabras: 14\n",
      "Embedding: vector_306\n",
      "\n",
      "st_id: 371\n",
      "Texto: So Max, thank you so much.\n",
      "Palabras: 6\n",
      "Embedding: vector_736\n",
      "\n",
      "st_id: 372\n",
      "Texto: Thank you for your time today.\n",
      "Palabras: 6\n",
      "Embedding: vector_303\n",
      "\n",
      "st_id: 373\n",
      "Texto: It's been awesome.\n",
      "Palabras: 3\n",
      "Embedding: vector_183\n",
      "\n",
      "st_id: 374\n",
      "Texto: Thank you so much.\n",
      "Palabras: 4\n",
      "Embedding: vector_507\n",
      "\n",
      "st_id: 375\n",
      "Texto: Thanks.\n",
      "Palabras: 1\n",
      "Embedding: vector_997\n",
      "\n",
      "st_id: 376\n",
      "Texto: Have a great day.\n",
      "Palabras: 4\n",
      "Embedding: vector_64\n",
      "\n",
      "st_id: 377\n",
      "Texto: got cleaned out of the gene pool, right?\n",
      "Palabras: 8\n",
      "Embedding: vector_800\n",
      "\n",
      "st_id: 378\n",
      "Texto: But if you build an artificial general intelligence the mind space that you can design is much, much larger than just a specific subset of minds that can evolve.\n",
      "Palabras: 29\n",
      "Embedding: vector_457\n",
      "\n",
      "st_id: 379\n",
      "Texto: So an AGI mind doesn't necessarily have to have any self preservation instinct.\n",
      "Palabras: 13\n",
      "Embedding: vector_925\n",
      "\n",
      "st_id: 380\n",
      "Texto: It also doesn't necessarily have to be so individualistic as us.\n",
      "Palabras: 11\n",
      "Embedding: vector_204\n",
      "\n",
      "st_id: 381\n",
      "Texto: Like, imagine if you could just, first of all, or we are also very afraid of death.\n",
      "Palabras: 17\n",
      "Embedding: vector_738\n",
      "\n",
      "st_id: 382\n",
      "Texto: You know, I suppose you could back yourself up every five minutes and then your airplane is about to crash.\n",
      "Palabras: 20\n",
      "Embedding: vector_80\n",
      "\n",
      "st_id: 383\n",
      "Texto: You're like, shucks, I'm gonna lose the last five minutes of experiences since my last cloud backup, dang.\n",
      "Palabras: 18\n",
      "Embedding: vector_596\n",
      "\n",
      "st_id: 384\n",
      "Texto: You know, it's not as big a deal.\n",
      "Palabras: 8\n",
      "Embedding: vector_543\n",
      "\n",
      "st_id: 385\n",
      "Texto: Or if we could just copy experiences between our minds easily like we, which we could easily do if we were silicon based, right?\n",
      "Palabras: 24\n",
      "Embedding: vector_181\n",
      "\n",
      "st_id: 386\n",
      "Texto: Then maybe we would feel a little bit more like a hive mind actually, that maybe it's the, so I don't think we should take for granted at all that AGI will have to have any of those sort of competitive as alpha male instincts.\n",
      "Palabras: 45\n",
      "Embedding: vector_455\n",
      "\n",
      "st_id: 387\n",
      "Texto: On the other hand, you know, this is really interesting because I think some people go too far and say, of course we don't have to have any concerns either that advanced AI will have those instincts because we can build anything we want.\n",
      "Palabras: 44\n",
      "Embedding: vector_548\n",
      "\n",
      "st_id: 388\n",
      "Texto: That there's a very nice set of arguments going back to Steve Omohundro and Nick Bostrom and others just pointing out that when we build machines, we normally build them with some kind of goal, you know, win this chess game, drive this car safely or whatever.\n",
      "Palabras: 47\n",
      "Embedding: vector_583\n",
      "\n",
      "st_id: 389\n",
      "Texto: And as soon as you put in a goal into machine, especially if it's kind of open ended goal and the machine is very intelligent, it'll break that down into a bunch of sub goals.\n",
      "Palabras: 35\n",
      "Embedding: vector_403\n",
      "\n",
      "st_id: 390\n",
      "Texto: And one of those goals will almost always be self preservation because if it breaks or dies in the process, it's not gonna accomplish the goal, right?\n",
      "Palabras: 27\n",
      "Embedding: vector_305\n",
      "\n",
      "st_id: 391\n",
      "Texto: Like suppose you just build a little, you have a little robot and you tell it to go down the store market here and get you some food, make you cook an Italian dinner, you know, and then someone mugs it and tries to break it on the way.\n",
      "Palabras: 49\n",
      "Embedding: vector_961\n",
      "\n",
      "st_id: 392\n",
      "Texto: That robot has an incentive to not get destroyed and defend itself or run away, because otherwise it's gonna fail in cooking your dinner.\n",
      "Palabras: 24\n",
      "Embedding: vector_799\n",
      "\n",
      "st_id: 393\n",
      "Texto: It's not afraid of death, but it really wants to complete the dinner cooking goal.\n",
      "Palabras: 15\n",
      "Embedding: vector_967\n",
      "\n",
      "st_id: 394\n",
      "Texto: So it will have a self preservation instinct.\n",
      "Palabras: 8\n",
      "Embedding: vector_50\n",
      "\n",
      "st_id: 395\n",
      "Texto: Continue being a functional agent somehow.\n",
      "Palabras: 6\n",
      "Embedding: vector_761\n",
      "\n",
      "st_id: 396\n",
      "Texto: And similarly, if you give any kind of more ambitious goal to an AGI, it's very likely they wanna acquire more resources so it can do that better.\n",
      "Palabras: 28\n",
      "Embedding: vector_110\n",
      "\n",
      "st_id: 397\n",
      "Texto: And it's exactly from those sort of sub goals that we might not have intended that some of the concerns about AGI safety come.\n",
      "Palabras: 24\n",
      "Embedding: vector_987\n",
      "\n",
      "st_id: 398\n",
      "Texto: You give it some goal that seems completely harmless.\n",
      "Palabras: 9\n",
      "Embedding: vector_561\n",
      "\n",
      "st_id: 399\n",
      "Texto: And then before you realize it, it's also trying to do these other things which you didn't want it to do.\n",
      "Palabras: 21\n",
      "Embedding: vector_459\n",
      "\n",
      "st_id: 400\n",
      "Texto: And it's maybe smarter than us.\n",
      "Palabras: 6\n",
      "Embedding: vector_587\n",
      "\n",
      "st_id: 401\n",
      "Texto: So it's fascinating.\n",
      "Palabras: 3\n",
      "Embedding: vector_183\n",
      "\n",
      "st_id: 402\n",
      "Texto: And let me pause just because I am in a very kind of human centric way, see fear of death as a valuable motivator.\n",
      "Palabras: 24\n",
      "Embedding: vector_304\n",
      "\n",
      "st_id: 403\n",
      "Texto: So you don't think, you think that's an artifact of evolution, so that's the kind of mind space evolution created that we're sort of almost obsessed about self preservation, some kind of genetic flow.\n",
      "Palabras: 34\n",
      "Embedding: vector_171\n",
      "\n",
      "st_id: 404\n",
      "Texto: You don't think that's necessary to be afraid of death.\n",
      "Palabras: 10\n",
      "Embedding: vector_973\n",
      "\n",
      "st_id: 405\n",
      "Texto: So not just a kind of sub goal of self preservation just so you can keep doing the thing, but more fundamentally sort of have the finite thing like this ends for you at some point.\n",
      "Palabras: 36\n",
      "Embedding: vector_649\n",
      "\n",
      "st_id: 406\n",
      "Texto: Interesting.\n",
      "Palabras: 1\n",
      "Embedding: vector_647\n",
      "\n",
      "st_id: 407\n",
      "Texto: Do I think it's necessary for what precisely?\n",
      "Palabras: 8\n",
      "Embedding: vector_35\n",
      "\n",
      "st_id: 408\n",
      "Texto: For intelligence, but also for consciousness.\n",
      "Palabras: 6\n",
      "Embedding: vector_851\n",
      "\n",
      "st_id: 409\n",
      "Texto: So for those, for both, do you think really like a finite death and the fear of it is important?\n",
      "Palabras: 20\n",
      "Embedding: vector_601\n",
      "\n",
      "st_id: 410\n",
      "Texto: So before I can answer, before we can agree on whether it's necessary for intelligence or for consciousness, we should be clear on how we define those two words.\n",
      "Palabras: 29\n",
      "Embedding: vector_725\n",
      "\n",
      "st_id: 411\n",
      "Texto: Cause a lot of really smart people define them in very different ways.\n",
      "Palabras: 13\n",
      "Embedding: vector_658\n",
      "\n",
      "st_id: 412\n",
      "Texto: I was on this panel with AI experts and they couldn't agree on how to define intelligence even.\n",
      "Palabras: 18\n",
      "Embedding: vector_150\n",
      "\n",
      "st_id: 413\n",
      "Texto: So I define intelligence simply as the ability to accomplish complex goals.\n",
      "Palabras: 12\n",
      "Embedding: vector_155\n",
      "\n",
      "st_id: 414\n",
      "Texto: I like your broad definition, because again I don't want to be a carbon chauvinist.\n",
      "Palabras: 15\n",
      "Embedding: vector_723\n",
      "\n",
      "st_id: 415\n",
      "Texto: Right.\n",
      "Palabras: 1\n",
      "Embedding: vector_688\n",
      "\n",
      "st_id: 416\n",
      "Texto: And in that case, no, certainly it doesn't require fear of death.\n",
      "Palabras: 12\n",
      "Embedding: vector_811\n",
      "\n",
      "st_id: 417\n",
      "Texto: I would say alpha go, alpha zero is quite intelligent.\n",
      "Palabras: 10\n",
      "Embedding: vector_933\n",
      "\n",
      "st_id: 418\n",
      "Texto: I don't think alpha zero has any fear of being turned off because it doesn't understand the concept of it even.\n",
      "Palabras: 21\n",
      "Embedding: vector_771\n",
      "\n",
      "st_id: 419\n",
      "Texto: And similarly consciousness.\n",
      "Palabras: 3\n",
      "Embedding: vector_948\n",
      "\n",
      "st_id: 420\n",
      "Texto: I mean, you could certainly imagine very simple kind of experience.\n",
      "Palabras: 11\n",
      "Embedding: vector_754\n",
      "\n",
      "st_id: 421\n",
      "Texto: If certain plants have any kind of experience I don't think they're very afraid of dying or there's nothing they can do about it anyway much.\n",
      "Palabras: 26\n",
      "Embedding: vector_88\n",
      "\n",
      "st_id: 422\n",
      "Texto: So there wasn't that much value in, but more seriously I think if you ask, not just about being conscious but maybe having what you would, we might call an exciting life where you feel passion and really appreciate the things.\n",
      "Palabras: 41\n",
      "Embedding: vector_346\n",
      "\n",
      "st_id: 423\n",
      "Texto: Maybe there somehow, maybe there perhaps it does help having a backdrop that, Hey, it's finite.\n",
      "Palabras: 16\n",
      "Embedding: vector_84\n",
      "\n",
      "st_id: 424\n",
      "Texto: No, let's make the most of this, let's live to the fullest.\n",
      "Palabras: 12\n",
      "Embedding: vector_323\n",
      "\n",
      "st_id: 425\n",
      "Texto: So if you knew you were going to live forever do you think you would change your?\n",
      "Palabras: 17\n",
      "Embedding: vector_18\n",
      "\n",
      "st_id: 426\n",
      "Texto: Yeah, I mean, in some perspective it would be an incredibly boring life living forever.\n",
      "Palabras: 15\n",
      "Embedding: vector_511\n",
      "\n",
      "st_id: 427\n",
      "Texto: So in the sort of loose subjective terms that you said of something exciting and something in this that other humans would understand, I think is, yeah it seems that the finiteness of it is important.\n",
      "Palabras: 36\n",
      "Embedding: vector_8\n",
      "\n",
      "st_id: 428\n",
      "Texto: Well, the good news I have for you then is based on what we understand about cosmology everything is in our universe is probably ultimately probably finite, although.\n",
      "Palabras: 28\n",
      "Embedding: vector_795\n",
      "\n",
      "st_id: 429\n",
      "Texto: Big crunch or big, what's the, the infinite expansion.\n",
      "Palabras: 9\n",
      "Embedding: vector_725\n",
      "\n",
      "st_id: 430\n",
      "Texto: Yeah, we could have a big chill or a big crunch or a big rip or that's the big snap or death bubbles.\n",
      "Palabras: 23\n",
      "Embedding: vector_120\n",
      "\n",
      "st_id: 431\n",
      "Texto: All of them are more than a billion years away.\n",
      "Palabras: 10\n",
      "Embedding: vector_461\n",
      "\n",
      "st_id: 432\n",
      "Texto: So we should, we certainly have vastly more time than our ancestors thought, but there is still it's still pretty hard to squeeze in an infinite number of compute cycles, even though there are some loopholes that just might be possible.\n",
      "Palabras: 41\n",
      "Embedding: vector_114\n",
      "\n",
      "st_id: 433\n",
      "Texto: But I think, you know, some people like to say that you should live as if you're about to you're going to die in five years or so.\n",
      "Palabras: 28\n",
      "Embedding: vector_613\n",
      "\n",
      "st_id: 434\n",
      "Texto: And that's sort of optimal.\n",
      "Palabras: 5\n",
      "Embedding: vector_533\n",
      "\n",
      "st_id: 435\n",
      "Texto: Maybe it's a good assumption.\n",
      "Palabras: 5\n",
      "Embedding: vector_957\n",
      "\n",
      "st_id: 436\n",
      "Texto: We should build our civilization as if it's all finite to be on the safe side.\n",
      "Palabras: 16\n",
      "Embedding: vector_988\n",
      "\n",
      "st_id: 437\n",
      "Texto: Right, exactly.\n",
      "Palabras: 2\n",
      "Embedding: vector_460\n",
      "\n",
      "st_id: 438\n",
      "Texto: So you mentioned defining intelligence as the ability to solve complex goals.\n",
      "Palabras: 12\n",
      "Embedding: vector_415\n",
      "\n",
      "st_id: 439\n",
      "Texto: Where would you draw a line or how would you try to define human level intelligence and superhuman level intelligence?\n",
      "Palabras: 20\n",
      "Embedding: vector_3\n",
      "\n",
      "st_id: 440\n",
      "Texto: Where is consciousness part of that definition?\n",
      "Palabras: 7\n",
      "Embedding: vector_727\n",
      "\n",
      "st_id: 441\n",
      "Texto: No, consciousness does not come into this definition.\n",
      "Palabras: 8\n",
      "Embedding: vector_462\n",
      "\n",
      "st_id: 442\n",
      "Texto: So, so I think of intelligence as it's a spectrum but there are very many different kinds of goals you can have.\n",
      "Palabras: 22\n",
      "Embedding: vector_732\n",
      "\n",
      "st_id: 443\n",
      "Texto: You can have a goal to be a good chess player a good goal player, a good car driver, a good investor good poet, et cetera.\n",
      "Palabras: 26\n",
      "Embedding: vector_137\n",
      "\n",
      "st_id: 444\n",
      "Texto: So intelligence that by its very nature isn't something you can measure by this one number or some overall goodness.\n",
      "Palabras: 20\n",
      "Embedding: vector_842\n",
      "\n",
      "st_id: 445\n",
      "Texto: No, no.\n",
      "Palabras: 2\n",
      "Embedding: vector_715\n",
      "\n",
      "st_id: 446\n",
      "Texto: There are some people who are more better at this.\n",
      "Palabras: 10\n",
      "Embedding: vector_203\n",
      "\n",
      "st_id: 447\n",
      "Texto: Some people are better than that.\n",
      "Palabras: 6\n",
      "Embedding: vector_462\n",
      "\n",
      "st_id: 448\n",
      "Texto: Right now we have machines that are much better than us at some very narrow tasks like multiplying large numbers fast, memorizing large databases, playing chess playing go and soon driving cars.\n",
      "Palabras: 32\n",
      "Embedding: vector_678\n",
      "\n",
      "st_id: 449\n",
      "Texto: But there's still no machine that can match a human child in general intelligence but artificial general intelligence, AGI the name of your course, of course that is by its very definition, the quest to build a machine that can do everything as well as we can.\n",
      "Palabras: 47\n",
      "Embedding: vector_766\n",
      "\n",
      "st_id: 450\n",
      "Texto: So the old Holy grail of AI from back to its inception in the sixties, if that ever happens, of course I think it's going to be the biggest transition in the history of life on earth but it doesn't necessarily have to wait the big impact until machines are better than us at knitting that the really big change doesn't come exactly at the moment they're better than us at everything.\n",
      "Palabras: 72\n",
      "Embedding: vector_912\n",
      "\n",
      "st_id: 451\n",
      "Texto: The really big change comes first there are big changes when they start becoming better at us at doing most of the jobs that we do because that takes away much of the demand for human labor.\n",
      "Palabras: 37\n",
      "Embedding: vector_444\n",
      "\n",
      "st_id: 452\n",
      "Texto: And then the really whopping change comes when they become better than us at AI research, right?\n",
      "Palabras: 17\n",
      "Embedding: vector_898\n",
      "\n",
      "st_id: 453\n",
      "Texto: Because right now the timescale of AI research is limited by the human research and development cycle of years typically, you know how long does it take from one release of some software or iPhone or whatever to the next?\n",
      "Palabras: 40\n",
      "Embedding: vector_377\n",
      "\n",
      "st_id: 454\n",
      "Texto: But once Google can replace 40,000 engineers by 40,000 equivalent pieces of software or whatever but then there's no reason that has to be years it can be in principle much faster and the timescale of future progress in AI and all of science and technology will be driven by machines, not humans.\n",
      "Palabras: 53\n",
      "Embedding: vector_904\n",
      "\n",
      "st_id: 455\n",
      "Texto: So it's this simple point which gives right this incredibly fun controversy about whether there can be intelligence explosion so called singularity as Werner Vinge called it.\n",
      "Palabras: 27\n",
      "Embedding: vector_104\n",
      "\n",
      "st_id: 456\n",
      "Texto: Now the idea is articulated by I.J.\n",
      "Palabras: 7\n",
      "Embedding: vector_480\n",
      "\n",
      "st_id: 457\n",
      "Texto: Good is obviously way back fifties but you can see Alan Turing and others thought about it even earlier.\n",
      "Palabras: 19\n",
      "Embedding: vector_491\n",
      "\n",
      "st_id: 458\n",
      "Texto: So you asked me what exactly would I define human level intelligence, yeah.\n",
      "Palabras: 13\n",
      "Embedding: vector_977\n",
      "\n",
      "st_id: 459\n",
      "Texto: So the glib answer is to say something which is better than us at all cognitive tasks with a better than any human at all cognitive tasks but the really interesting bar I think goes a little bit lower than that actually.\n",
      "Palabras: 42\n",
      "Embedding: vector_624\n",
      "\n",
      "st_id: 460\n",
      "Texto: It's when they can, when they're better than us at AI programming and general learning so that they can if they want to get better than us at anything by just studying.\n",
      "Palabras: 32\n",
      "Embedding: vector_203\n",
      "\n",
      "st_id: 461\n",
      "Texto: So they're better is a key word and better is towards this kind of spectrum of the complexity of goals it's able to accomplish.\n",
      "Palabras: 24\n",
      "Embedding: vector_591\n",
      "\n",
      "st_id: 462\n",
      "Texto: So another way to, and that's certainly a very clear definition of human love.\n",
      "Palabras: 14\n",
      "Embedding: vector_215\n",
      "\n",
      "st_id: 463\n",
      "Texto: So there's, it's almost like a sea that's rising you can do more and more and more things it's a geographic that you show it's really nice way to put it.\n",
      "Palabras: 31\n",
      "Embedding: vector_488\n",
      "\n",
      "st_id: 464\n",
      "Texto: So there's some peaks that and there's an ocean level elevating and you solve more and more problems but just kind of to take a pause and we took a bunch of questions and a lot of social networks and a bunch of people asked a sort of a slightly different direction on creativity and things that perhaps aren't a peak.\n",
      "Palabras: 61\n",
      "Embedding: vector_736\n",
      "\n",
      "st_id: 465\n",
      "Texto: Human beings are flawed and perhaps better means having contradiction being flawed in some way.\n",
      "Palabras: 15\n",
      "Embedding: vector_423\n",
      "\n",
      "st_id: 466\n",
      "Texto: So let me sort of start easy, first of all.\n",
      "Palabras: 10\n",
      "Embedding: vector_433\n",
      "\n",
      "st_id: 467\n",
      "Texto: So you have a lot of cool equations.\n",
      "Palabras: 8\n",
      "Embedding: vector_462\n",
      "\n",
      "st_id: 468\n",
      "Texto: Let me ask, what's your favorite equation, first of all?\n",
      "Palabras: 10\n",
      "Embedding: vector_218\n",
      "\n",
      "st_id: 469\n",
      "Texto: I know they're all like your children, but like which one is that?\n",
      "Palabras: 13\n",
      "Embedding: vector_780\n",
      "\n",
      "st_id: 470\n",
      "Texto: This is the shirt in your equation.\n",
      "Palabras: 7\n",
      "Embedding: vector_208\n",
      "\n",
      "st_id: 471\n",
      "Texto: It's the master key of quantum mechanics of the micro world.\n",
      "Palabras: 11\n",
      "Embedding: vector_52\n",
      "\n",
      "st_id: 472\n",
      "Texto: So this equation will protect everything to do with atoms, molecules and all the way up.\n",
      "Palabras: 16\n",
      "Embedding: vector_754\n",
      "\n",
      "st_id: 473\n",
      "Texto: Right?\n",
      "Palabras: 1\n",
      "Embedding: vector_739\n",
      "\n",
      "st_id: 474\n",
      "Texto: Yeah, so, okay.\n",
      "Palabras: 3\n",
      "Embedding: vector_113\n",
      "\n",
      "st_id: 475\n",
      "Texto: So quantum mechanics is certainly a beautiful mysterious formulation of our world.\n",
      "Palabras: 12\n",
      "Embedding: vector_52\n",
      "\n",
      "st_id: 476\n",
      "Texto: So I'd like to sort of ask you, just as an example it perhaps doesn't have the same beauty as physics does but in mathematics abstract, the Andrew Wiles who proved the Fermat's last theorem.\n",
      "Palabras: 35\n",
      "Embedding: vector_937\n",
      "\n",
      "st_id: 477\n",
      "Texto: So he just saw this recently and it kind of caught my eye a little bit.\n",
      "Palabras: 16\n",
      "Embedding: vector_847\n",
      "\n",
      "st_id: 478\n",
      "Texto: This is 358 years after it was conjectured.\n",
      "Palabras: 8\n",
      "Embedding: vector_977\n",
      "\n",
      "st_id: 479\n",
      "Texto: So this is very simple formulation.\n",
      "Palabras: 6\n",
      "Embedding: vector_733\n",
      "\n",
      "st_id: 480\n",
      "Texto: Everybody tried to prove it, everybody failed.\n",
      "Palabras: 7\n",
      "Embedding: vector_457\n",
      "\n",
      "st_id: 481\n",
      "Texto: And so here's this guy comes along and eventually proves it and then fails to prove it and then proves it again in 94.\n",
      "Palabras: 24\n",
      "Embedding: vector_358\n",
      "\n",
      "st_id: 482\n",
      "Texto: And he said like the moment when everything connected into place in an interview said it was so indescribably beautiful.\n",
      "Palabras: 20\n",
      "Embedding: vector_224\n",
      "\n",
      "st_id: 483\n",
      "Texto: That moment when you finally realize the connecting piece of two conjectures.\n",
      "Palabras: 12\n",
      "Embedding: vector_183\n",
      "\n",
      "st_id: 484\n",
      "Texto: He said, it was so indescribably beautiful.\n",
      "Palabras: 7\n",
      "Embedding: vector_491\n",
      "\n",
      "st_id: 485\n",
      "Texto: It was so simple and so elegant.\n",
      "Palabras: 7\n",
      "Embedding: vector_466\n",
      "\n",
      "st_id: 486\n",
      "Texto: I couldn't understand how I'd missed it.\n",
      "Palabras: 7\n",
      "Embedding: vector_683\n",
      "\n",
      "st_id: 487\n",
      "Texto: And I just stared at it in disbelief for 20 minutes.\n",
      "Palabras: 11\n",
      "Embedding: vector_134\n",
      "\n",
      "st_id: 488\n",
      "Texto: Then during the day, I walked around the department and I keep coming back to my desk looking to see if it was still there.\n",
      "Palabras: 25\n",
      "Embedding: vector_192\n",
      "\n",
      "st_id: 489\n",
      "Texto: It was still there.\n",
      "Palabras: 4\n",
      "Embedding: vector_945\n",
      "\n",
      "st_id: 490\n",
      "Texto: I couldn't contain myself.\n",
      "Palabras: 4\n",
      "Embedding: vector_961\n",
      "\n",
      "st_id: 491\n",
      "Texto: I was so excited.\n",
      "Palabras: 4\n",
      "Embedding: vector_499\n",
      "\n",
      "st_id: 492\n",
      "Texto: It was the most important moment on my working life.\n",
      "Palabras: 10\n",
      "Embedding: vector_737\n",
      "\n",
      "st_id: 493\n",
      "Texto: Nothing I ever do again will mean as much.\n",
      "Palabras: 9\n",
      "Embedding: vector_287\n",
      "\n",
      "st_id: 494\n",
      "Texto: So that particular moment.\n",
      "Palabras: 4\n",
      "Embedding: vector_49\n",
      "\n",
      "st_id: 495\n",
      "Texto: And it kind of made me think of what would it take?\n",
      "Palabras: 12\n",
      "Embedding: vector_448\n",
      "\n",
      "st_id: 496\n",
      "Texto: And I think we have all been there at small levels.\n",
      "Palabras: 11\n",
      "Embedding: vector_410\n",
      "\n",
      "st_id: 497\n",
      "Texto: Maybe let me ask, have you had a moment like that in your life where you just had an idea?\n",
      "Palabras: 20\n",
      "Embedding: vector_603\n",
      "\n",
      "st_id: 498\n",
      "Texto: It's like, wow, yes.\n",
      "Palabras: 4\n",
      "Embedding: vector_590\n",
      "\n",
      "st_id: 499\n",
      "Texto: I wouldn't mention myself in the same breath as Andrew Wiles, but I've certainly had a number of aha moments when I realized something very cool about physics, which has completely made my head explode.\n",
      "Palabras: 35\n",
      "Embedding: vector_26\n",
      "\n",
      "st_id: 500\n",
      "Texto: In fact, some of my favorite discoveries I made later, I later realized that they had been discovered earlier by someone who sometimes got quite famous for it.\n",
      "Palabras: 28\n",
      "Embedding: vector_359\n",
      "\n",
      "st_id: 501\n",
      "Texto: So it's too late for me to even publish it, but that doesn't diminish in any way.\n",
      "Palabras: 17\n",
      "Embedding: vector_751\n",
      "\n",
      "st_id: 502\n",
      "Texto: The emotional experience you have when you realize it, like, wow.\n",
      "Palabras: 11\n",
      "Embedding: vector_154\n",
      "\n",
      "st_id: 503\n",
      "Texto: Yeah, so what would it take in that moment, that wow, that was yours in that moment?\n",
      "Palabras: 17\n",
      "Embedding: vector_256\n",
      "\n",
      "st_id: 504\n",
      "Texto: So what do you think it takes for an intelligence system, an AGI system, an AI system to have a moment like that?\n",
      "Palabras: 23\n",
      "Embedding: vector_780\n",
      "\n",
      "st_id: 505\n",
      "Texto: That's a tricky question because there are actually two parts to it, right?\n",
      "Palabras: 13\n",
      "Embedding: vector_907\n",
      "\n",
      "st_id: 506\n",
      "Texto: One of them is, can it accomplish that proof?\n",
      "Palabras: 9\n",
      "Embedding: vector_616\n",
      "\n",
      "st_id: 507\n",
      "Texto: Can it prove that you can never write A to the N plus B to the N equals three to that equal Z to the N for all integers, et cetera, et cetera, when N is bigger than two?\n",
      "Palabras: 39\n",
      "Embedding: vector_99\n",
      "\n",
      "st_id: 508\n",
      "Texto: That's simply a question about intelligence.\n",
      "Palabras: 6\n",
      "Embedding: vector_969\n",
      "\n",
      "st_id: 509\n",
      "Texto: Can you build machines that are that intelligent?\n",
      "Palabras: 8\n",
      "Embedding: vector_420\n",
      "\n",
      "st_id: 510\n",
      "Texto: And I think by the time we get a machine that can independently come up with that level of proofs, probably quite close to AGI.\n",
      "Palabras: 25\n",
      "Embedding: vector_781\n",
      "\n",
      "st_id: 511\n",
      "Texto: The second question is a question about consciousness.\n",
      "Palabras: 8\n",
      "Embedding: vector_137\n",
      "\n",
      "st_id: 512\n",
      "Texto: When will we, how likely is it that such a machine will actually have any experience at all, as opposed to just being like a zombie?\n",
      "Palabras: 26\n",
      "Embedding: vector_778\n",
      "\n",
      "st_id: 513\n",
      "Texto: And would we expect it to have some sort of emotional response to this or anything at all akin to human emotion where when it accomplishes its machine goal, it views it as somehow something very positive and sublime and deeply meaningful?\n",
      "Palabras: 42\n",
      "Embedding: vector_571\n",
      "\n",
      "st_id: 514\n",
      "Texto: I would certainly hope that if in the future we do create machines that are our peers or even our descendants, that I would certainly hope that they do have this sublime appreciation of life.\n",
      "Palabras: 35\n",
      "Embedding: vector_51\n",
      "\n",
      "st_id: 515\n",
      "Texto: In a way, my absolutely worst nightmare would be that at some point in the future, the distant future, maybe our cosmos is teeming with all this post biological life doing all the seemingly cool stuff.\n",
      "Palabras: 36\n",
      "Embedding: vector_768\n",
      "\n",
      "st_id: 516\n",
      "Texto: And maybe the last humans, by the time our species eventually fizzles out, will be like, well, that's OK because we're so proud of our descendants here.\n",
      "Palabras: 27\n",
      "Embedding: vector_497\n",
      "\n",
      "st_id: 517\n",
      "Texto: And look what all the, my worst nightmare is that we haven't solved the consciousness problem.\n",
      "Palabras: 16\n",
      "Embedding: vector_272\n",
      "\n",
      "st_id: 518\n",
      "Texto: And we haven't realized that these are all the zombies.\n",
      "Palabras: 10\n",
      "Embedding: vector_518\n",
      "\n",
      "st_id: 519\n",
      "Texto: They're not aware of anything any more than a tape recorder has any kind of experience.\n",
      "Palabras: 16\n",
      "Embedding: vector_675\n",
      "\n",
      "st_id: 520\n",
      "Texto: So the whole thing has just become a play for empty benches.\n",
      "Palabras: 12\n",
      "Embedding: vector_200\n",
      "\n",
      "st_id: 521\n",
      "Texto: That would be the ultimate zombie apocalypse.\n",
      "Palabras: 7\n",
      "Embedding: vector_619\n",
      "\n",
      "st_id: 522\n",
      "Texto: So I would much rather, in that case, that we have these beings which can really appreciate how amazing it is.\n",
      "Palabras: 21\n",
      "Embedding: vector_508\n",
      "\n",
      "st_id: 523\n",
      "Texto: And in that picture, what would be the role of creativity?\n",
      "Palabras: 11\n",
      "Embedding: vector_372\n",
      "\n",
      "st_id: 524\n",
      "Texto: A few people ask about creativity.\n",
      "Palabras: 6\n",
      "Embedding: vector_230\n",
      "\n",
      "st_id: 525\n",
      "Texto: When you think about intelligence, certainly the story you told at the beginning of your book involved creating movies and so on, making money.\n",
      "Palabras: 24\n",
      "Embedding: vector_201\n",
      "\n",
      "st_id: 526\n",
      "Texto: You can make a lot of money in our modern world with music and movies.\n",
      "Palabras: 15\n",
      "Embedding: vector_939\n",
      "\n",
      "st_id: 527\n",
      "Texto: So if you are an intelligent system, you may want to get good at that.\n",
      "Palabras: 15\n",
      "Embedding: vector_233\n",
      "\n",
      "st_id: 528\n",
      "Texto: But that's not necessarily what I mean by creativity.\n",
      "Palabras: 9\n",
      "Embedding: vector_144\n",
      "\n",
      "st_id: 529\n",
      "Texto: Is it important on that complex goals where the sea is rising for there to be something creative?\n",
      "Palabras: 18\n",
      "Embedding: vector_15\n",
      "\n",
      "st_id: 530\n",
      "Texto: Or am I being very human centric and thinking creativity somehow special relative to intelligence?\n",
      "Palabras: 15\n",
      "Embedding: vector_246\n",
      "\n",
      "st_id: 531\n",
      "Texto: My hunch is that we should think of creativity simply as an aspect of intelligence.\n",
      "Palabras: 15\n",
      "Embedding: vector_229\n",
      "\n",
      "st_id: 532\n",
      "Texto: And we have to be very careful with human vanity.\n",
      "Palabras: 10\n",
      "Embedding: vector_364\n",
      "\n",
      "st_id: 533\n",
      "Texto: We have this tendency to very often want to say, as soon as machines can do something, we try to diminish it and say, oh, but that's not real intelligence.\n",
      "Palabras: 30\n",
      "Embedding: vector_978\n",
      "\n",
      "st_id: 534\n",
      "Texto: Isn't it creative or this or that?\n",
      "Palabras: 7\n",
      "Embedding: vector_293\n",
      "\n",
      "st_id: 535\n",
      "Texto: The other thing, if we ask ourselves to write down a definition of what we actually mean by being creative, what we mean by Andrew Wiles, what he did there, for example, don't we often mean that someone takes a very unexpected leap?\n",
      "Palabras: 43\n",
      "Embedding: vector_788\n",
      "\n",
      "st_id: 536\n",
      "Texto: It's not like taking 573 and multiplying it by 224 by just a step of straightforward cookbook like rules, right?\n",
      "Palabras: 20\n",
      "Embedding: vector_811\n",
      "\n",
      "st_id: 537\n",
      "Texto: You can maybe make a connection between two things that people had never thought was connected or something like that.\n",
      "Palabras: 20\n",
      "Embedding: vector_521\n",
      "\n",
      "st_id: 538\n",
      "Texto: I think this is an aspect of intelligence.\n",
      "Palabras: 8\n",
      "Embedding: vector_910\n",
      "\n",
      "st_id: 539\n",
      "Texto: And this is actually one of the most important aspects of it.\n",
      "Palabras: 12\n",
      "Embedding: vector_454\n",
      "\n",
      "st_id: 540\n",
      "Texto: Maybe the reason we humans tend to be better at it than traditional computers is because it's something that comes more naturally if you're a neural network than if you're a traditional logic gate based computer machine.\n",
      "Palabras: 37\n",
      "Embedding: vector_666\n",
      "\n",
      "st_id: 541\n",
      "Texto: We physically have all these connections.\n",
      "Palabras: 6\n",
      "Embedding: vector_374\n",
      "\n",
      "st_id: 542\n",
      "Texto: And you activate here, activate here, activate here.\n",
      "Palabras: 8\n",
      "Embedding: vector_436\n",
      "\n",
      "st_id: 543\n",
      "Texto: Bing.\n",
      "Palabras: 1\n",
      "Embedding: vector_32\n",
      "\n",
      "st_id: 544\n",
      "Texto: My hunch is that if we ever build a machine where you could just give it the task, hey, you say, hey, I just realized I want to travel around the world instead this month.\n",
      "Palabras: 35\n",
      "Embedding: vector_689\n",
      "\n",
      "st_id: 545\n",
      "Texto: Can you teach my AGI course for me?\n",
      "Palabras: 8\n",
      "Embedding: vector_937\n",
      "\n",
      "st_id: 546\n",
      "Texto: And it's like, OK, I'll do it.\n",
      "Palabras: 7\n",
      "Embedding: vector_343\n",
      "\n",
      "st_id: 547\n",
      "Texto: And it does everything that you would have done and improvises and stuff.\n",
      "Palabras: 13\n",
      "Embedding: vector_701\n",
      "\n",
      "st_id: 548\n",
      "Texto: That would, in my mind, involve a lot of creativity.\n",
      "Palabras: 10\n",
      "Embedding: vector_858\n",
      "\n",
      "st_id: 549\n",
      "Texto: Yeah, so it's actually a beautiful way to put it.\n",
      "Palabras: 10\n",
      "Embedding: vector_664\n",
      "\n",
      "st_id: 550\n",
      "Texto: I think we do try to grasp at the definition of intelligence is everything we don't understand how to build.\n",
      "Palabras: 20\n",
      "Embedding: vector_738\n",
      "\n",
      "st_id: 551\n",
      "Texto: So we as humans try to find things that we have and machines don't have.\n",
      "Palabras: 15\n",
      "Embedding: vector_399\n",
      "\n",
      "st_id: 552\n",
      "Texto: And maybe creativity is just one of the things, one of the words we use to describe that.\n",
      "Palabras: 18\n",
      "Embedding: vector_210\n",
      "\n",
      "st_id: 553\n",
      "Texto: That's a really interesting way to put it.\n",
      "Palabras: 8\n",
      "Embedding: vector_721\n",
      "\n",
      "st_id: 554\n",
      "Texto: I don't think we need to be that defensive.\n",
      "Palabras: 9\n",
      "Embedding: vector_770\n",
      "\n",
      "st_id: 555\n",
      "Texto: I don't think anything good comes out of saying, well, we're somehow special, you know?\n",
      "Palabras: 15\n",
      "Embedding: vector_475\n",
      "\n",
      "st_id: 556\n",
      "Texto: Contrary wise, there are many examples in history of where trying to pretend that we're somehow superior to all other intelligent beings has led to pretty bad results, right?\n",
      "Palabras: 29\n",
      "Embedding: vector_462\n",
      "\n",
      "st_id: 557\n",
      "Texto: Nazi Germany, they said that they were somehow superior to other people.\n",
      "Palabras: 12\n",
      "Embedding: vector_330\n",
      "\n",
      "st_id: 558\n",
      "Texto: Today, we still do a lot of cruelty to animals by saying that we're so superior somehow, and they can't feel pain.\n",
      "Palabras: 22\n",
      "Embedding: vector_48\n",
      "\n",
      "st_id: 559\n",
      "Texto: Slavery was justified by the same kind of just really weak arguments.\n",
      "Palabras: 12\n",
      "Embedding: vector_730\n",
      "\n",
      "st_id: 560\n",
      "Texto: And I don't think if we actually go ahead and build artificial general intelligence, it can do things better than us, I don't think we should try to found our self worth on some sort of bogus claims of superiority in terms of our intelligence.\n",
      "Palabras: 45\n",
      "Embedding: vector_989\n",
      "\n",
      "st_id: 561\n",
      "Texto: I think we should instead find our calling and the meaning of life from the experiences that we have.\n",
      "Palabras: 19\n",
      "Embedding: vector_11\n",
      "\n",
      "st_id: 562\n",
      "Texto: I can have very meaningful experiences even if there are other people who are smarter than me.\n",
      "Palabras: 17\n",
      "Embedding: vector_239\n",
      "\n",
      "st_id: 563\n",
      "Texto: When I go to a faculty meeting here, and we talk about something, and then I certainly realize, oh, boy, he has an old prize, he has an old prize, he has an old prize, I don't have one.\n",
      "Palabras: 39\n",
      "Embedding: vector_378\n",
      "\n",
      "st_id: 564\n",
      "Texto: Does that make me enjoy life any less or enjoy talking to those people less?\n",
      "Palabras: 15\n",
      "Embedding: vector_607\n",
      "\n",
      "st_id: 565\n",
      "Texto: Of course not.\n",
      "Palabras: 3\n",
      "Embedding: vector_430\n",
      "\n",
      "st_id: 566\n",
      "Texto: And the contrary, I feel very honored and privileged to get to interact with other very intelligent beings that are better than me at a lot of stuff.\n",
      "Palabras: 28\n",
      "Embedding: vector_77\n",
      "\n",
      "st_id: 567\n",
      "Texto: So I don't think there's any reason why we can't have the same approach with intelligent machines.\n",
      "Palabras: 17\n",
      "Embedding: vector_443\n",
      "\n",
      "st_id: 568\n",
      "Texto: That's a really interesting.\n",
      "Palabras: 4\n",
      "Embedding: vector_440\n",
      "\n",
      "st_id: 569\n",
      "Texto: So people don't often think about that.\n",
      "Palabras: 7\n",
      "Embedding: vector_249\n",
      "\n",
      "st_id: 570\n",
      "Texto: They think about when there's going, if there's machines that are more intelligent, you naturally think that that's not going to be a beneficial type of intelligence.\n",
      "Palabras: 27\n",
      "Embedding: vector_175\n",
      "\n",
      "st_id: 571\n",
      "Texto: You don't realize it could be like peers with Nobel prizes that would be just fun to talk with, and they might be clever about certain topics, and you can have fun having a few drinks with them.\n",
      "Palabras: 38\n",
      "Embedding: vector_352\n",
      "\n",
      "st_id: 572\n",
      "Texto: Well, also, another example we can all relate to of why it doesn't have to be a terrible thing to be in the presence of people who are even smarter than us all around is when you and I were both two years old, I mean, our parents were much more intelligent than us, right?\n",
      "Palabras: 55\n",
      "Embedding: vector_236\n",
      "\n",
      "st_id: 573\n",
      "Texto: Worked out OK, because their goals were aligned with our goals.\n",
      "Palabras: 11\n",
      "Embedding: vector_746\n",
      "\n",
      "st_id: 574\n",
      "Texto: And that, I think, is really the number one key issue we have to solve if we value align the value alignment problem, exactly.\n",
      "Palabras: 24\n",
      "Embedding: vector_298\n",
      "\n",
      "st_id: 575\n",
      "Texto: Because people who see too many Hollywood movies with lousy science fiction plot lines, they worry about the wrong thing, right?\n",
      "Palabras: 21\n",
      "Embedding: vector_800\n",
      "\n",
      "st_id: 576\n",
      "Texto: They worry about some machine suddenly turning evil.\n",
      "Palabras: 8\n",
      "Embedding: vector_846\n",
      "\n",
      "st_id: 577\n",
      "Texto: It's not malice that is the concern.\n",
      "Palabras: 7\n",
      "Embedding: vector_796\n",
      "\n",
      "st_id: 578\n",
      "Texto: It's competence.\n",
      "Palabras: 2\n",
      "Embedding: vector_319\n",
      "\n",
      "st_id: 579\n",
      "Texto: By definition, intelligent makes you very competent.\n",
      "Palabras: 7\n",
      "Embedding: vector_924\n",
      "\n",
      "st_id: 580\n",
      "Texto: If you have a more intelligent goal playing, computer playing is a less intelligent one.\n",
      "Palabras: 15\n",
      "Embedding: vector_57\n",
      "\n",
      "st_id: 581\n",
      "Texto: And when we define intelligence as the ability to accomplish goal winning, it's going to be the more intelligent one that wins.\n",
      "Palabras: 22\n",
      "Embedding: vector_786\n",
      "\n",
      "st_id: 582\n",
      "Texto: And if you have a human and then you have an AGI that's more intelligent in all ways and they have different goals, guess who's going to get their way, right?\n",
      "Palabras: 31\n",
      "Embedding: vector_225\n",
      "\n",
      "st_id: 583\n",
      "Texto: So I was just reading about this particular rhinoceros species that was driven extinct just a few years ago.\n",
      "Palabras: 19\n",
      "Embedding: vector_859\n",
      "\n",
      "st_id: 584\n",
      "Texto: Ellen Bummer is looking at this cute picture of a mommy rhinoceros with its child.\n",
      "Palabras: 15\n",
      "Embedding: vector_59\n",
      "\n",
      "st_id: 585\n",
      "Texto: And why did we humans drive it to extinction?\n",
      "Palabras: 9\n",
      "Embedding: vector_659\n",
      "\n",
      "st_id: 586\n",
      "Texto: It wasn't because we were evil rhino haters as a whole.\n",
      "Palabras: 11\n",
      "Embedding: vector_792\n",
      "\n",
      "st_id: 587\n",
      "Texto: It was just because our goals weren't aligned with those of the rhinoceros.\n",
      "Palabras: 13\n",
      "Embedding: vector_292\n",
      "\n",
      "st_id: 588\n",
      "Texto: And it didn't work out so well for the rhinoceros because we were more intelligent, right?\n",
      "Palabras: 16\n",
      "Embedding: vector_730\n",
      "\n",
      "st_id: 589\n",
      "Texto: So I think it's just so important that if we ever do build AGI, before we unleash anything, we have to make sure that it learns to understand our goals, that it adopts our goals, and that it retains those goals.\n",
      "Palabras: 41\n",
      "Embedding: vector_239\n",
      "\n",
      "st_id: 590\n",
      "Texto: So the cool, interesting problem there is us as human beings trying to formulate our values.\n",
      "Palabras: 16\n",
      "Embedding: vector_490\n",
      "\n",
      "st_id: 591\n",
      "Texto: So you could think of the United States Constitution as a way that people sat down, at the time a bunch of white men, which is a good example, I should say.\n",
      "Palabras: 32\n",
      "Embedding: vector_216\n",
      "\n",
      "st_id: 592\n",
      "Texto: They formulated the goals for this country.\n",
      "Palabras: 7\n",
      "Embedding: vector_558\n",
      "\n",
      "st_id: 593\n",
      "Texto: And a lot of people agree that those goals actually held up pretty well.\n",
      "Palabras: 14\n",
      "Embedding: vector_686\n",
      "\n",
      "st_id: 594\n",
      "Texto: That's an interesting formulation of values and failed miserably in other ways.\n",
      "Palabras: 12\n",
      "Embedding: vector_733\n",
      "\n",
      "st_id: 595\n",
      "Texto: So for the value alignment problem and the solution to it, we have to be able to put on paper or in a program human values.\n",
      "Palabras: 26\n",
      "Embedding: vector_857\n",
      "\n",
      "st_id: 596\n",
      "Texto: How difficult do you think that is?\n",
      "Palabras: 7\n",
      "Embedding: vector_468\n",
      "\n",
      "st_id: 597\n",
      "Texto: Very.\n",
      "Palabras: 1\n",
      "Embedding: vector_404\n",
      "\n",
      "st_id: 598\n",
      "Texto: But it's so important.\n",
      "Palabras: 4\n",
      "Embedding: vector_58\n",
      "\n",
      "st_id: 599\n",
      "Texto: We really have to give it our best.\n",
      "Palabras: 8\n",
      "Embedding: vector_55\n",
      "\n",
      "st_id: 600\n",
      "Texto: And it's difficult for two separate reasons.\n",
      "Palabras: 7\n",
      "Embedding: vector_116\n",
      "\n",
      "st_id: 601\n",
      "Texto: There's the technical value alignment problem of figuring out just how to make machines understand our goals, adopt them, and retain them.\n",
      "Palabras: 22\n",
      "Embedding: vector_123\n",
      "\n",
      "st_id: 602\n",
      "Texto: And then there's the separate part of it, the philosophical part.\n",
      "Palabras: 11\n",
      "Embedding: vector_125\n",
      "\n",
      "st_id: 603\n",
      "Texto: Whose values anyway?\n",
      "Palabras: 3\n",
      "Embedding: vector_672\n",
      "\n",
      "st_id: 604\n",
      "Texto: And since it's not like we have any great consensus on this planet on values, what mechanism should we create then to aggregate and decide, OK, what's a good compromise?\n",
      "Palabras: 30\n",
      "Embedding: vector_697\n",
      "\n",
      "st_id: 605\n",
      "Texto: That second discussion can't just be left to tech nerds like myself.\n",
      "Palabras: 12\n",
      "Embedding: vector_122\n",
      "\n",
      "st_id: 606\n",
      "Texto: And if we refuse to talk about it and then AGI gets built, who's going to be actually making the decision about whose values?\n",
      "Palabras: 24\n",
      "Embedding: vector_741\n",
      "\n",
      "st_id: 607\n",
      "Texto: It's going to be a bunch of dudes in some tech company.\n",
      "Palabras: 12\n",
      "Embedding: vector_860\n",
      "\n",
      "st_id: 608\n",
      "Texto: And are they necessarily so representative of all of humankind that we want to just entrust it to them?\n",
      "Palabras: 19\n",
      "Embedding: vector_79\n",
      "\n",
      "st_id: 609\n",
      "Texto: Are they even uniquely qualified to speak to future human happiness just because they're good at programming AI?\n",
      "Palabras: 18\n",
      "Embedding: vector_682\n",
      "\n",
      "st_id: 610\n",
      "Texto: I'd much rather have this be a really inclusive conversation.\n",
      "Palabras: 10\n",
      "Embedding: vector_946\n",
      "\n",
      "st_id: 611\n",
      "Texto: But do you think it's possible?\n",
      "Palabras: 6\n",
      "Embedding: vector_748\n",
      "\n",
      "st_id: 612\n",
      "Texto: So you create a beautiful vision that includes the diversity, cultural diversity, and various perspectives on discussing rights, freedoms, human dignity.\n",
      "Palabras: 21\n",
      "Embedding: vector_124\n",
      "\n",
      "st_id: 613\n",
      "Texto: But how hard is it to come to that consensus?\n",
      "Palabras: 10\n",
      "Embedding: vector_520\n",
      "\n",
      "st_id: 614\n",
      "Texto: Do you think it's certainly a really important thing that we should all try to do?\n",
      "Palabras: 16\n",
      "Embedding: vector_129\n",
      "\n",
      "st_id: 615\n",
      "Texto: But do you think it's feasible?\n",
      "Palabras: 6\n",
      "Embedding: vector_351\n",
      "\n",
      "st_id: 616\n",
      "Texto: I think there's no better way to guarantee failure than to refuse to talk about it or refuse to try.\n",
      "Palabras: 20\n",
      "Embedding: vector_684\n",
      "\n",
      "st_id: 617\n",
      "Texto: And I also think it's a really bad strategy to say, OK, let's first have a discussion for a long time.\n",
      "Palabras: 21\n",
      "Embedding: vector_434\n",
      "\n",
      "st_id: 618\n",
      "Texto: And then once we reach complete consensus, then we'll try to load it into some machine.\n",
      "Palabras: 16\n",
      "Embedding: vector_582\n",
      "\n",
      "st_id: 619\n",
      "Texto: No, we shouldn't let perfect be the enemy of good.\n",
      "Palabras: 10\n",
      "Embedding: vector_790\n",
      "\n",
      "st_id: 620\n",
      "Texto: Instead, we should start with the kindergarten ethics that pretty much everybody agrees on and put that into machines now.\n",
      "Palabras: 20\n",
      "Embedding: vector_686\n",
      "\n",
      "st_id: 621\n",
      "Texto: We're not doing that even.\n",
      "Palabras: 5\n",
      "Embedding: vector_753\n",
      "\n",
      "st_id: 622\n",
      "Texto: Look at anyone who builds this passenger aircraft, wants it to never under any circumstances fly into a building or a mountain.\n",
      "Palabras: 22\n",
      "Embedding: vector_697\n",
      "\n",
      "st_id: 623\n",
      "Texto: Yet the September 11 hijackers were able to do that.\n",
      "Palabras: 10\n",
      "Embedding: vector_278\n",
      "\n",
      "st_id: 624\n",
      "Texto: And even more embarrassingly, Andreas Lubitz, this depressed Germanwings pilot, when he flew his passenger jet into the Alps killing over 100 people, he just told the autopilot to do it.\n",
      "Palabras: 31\n",
      "Embedding: vector_239\n",
      "\n",
      "st_id: 625\n",
      "Texto: He told the freaking computer to change the altitude to 100 meters.\n",
      "Palabras: 12\n",
      "Embedding: vector_59\n",
      "\n",
      "st_id: 626\n",
      "Texto: And even though it had the GPS maps, everything, the computer was like, OK.\n",
      "Palabras: 14\n",
      "Embedding: vector_397\n",
      "\n",
      "st_id: 627\n",
      "Texto: So we should take those very basic values, where the problem is not that we don't agree.\n",
      "Palabras: 17\n",
      "Embedding: vector_96\n",
      "\n",
      "st_id: 628\n",
      "Texto: The problem is just we've been too lazy to try to put it into our machines and make sure that from now on, airplanes will just, which all have computers in them, but will just refuse to do something like that.\n",
      "Palabras: 41\n",
      "Embedding: vector_72\n",
      "\n",
      "st_id: 629\n",
      "Texto: Go into safe mode, maybe lock the cockpit door, go over to the nearest airport.\n",
      "Palabras: 15\n",
      "Embedding: vector_50\n",
      "\n",
      "st_id: 630\n",
      "Texto: And there's so much other technology in our world as well now, where it's really becoming quite timely to put in some sort of very basic values like this.\n",
      "Palabras: 29\n",
      "Embedding: vector_452\n",
      "\n",
      "st_id: 631\n",
      "Texto: Even in cars, we've had enough vehicle terrorism attacks by now, where people have driven trucks and vans into pedestrians, that it's not at all a crazy idea to just have that hardwired into the car.\n",
      "Palabras: 36\n",
      "Embedding: vector_974\n",
      "\n",
      "st_id: 632\n",
      "Texto: Because yeah, there are a lot of, there's always going to be people who for some reason want to harm others, but most of those people don't have the technical expertise to figure out how to work around something like that.\n",
      "Palabras: 41\n",
      "Embedding: vector_545\n",
      "\n",
      "st_id: 633\n",
      "Texto: So if the car just won't do it, it helps.\n",
      "Palabras: 10\n",
      "Embedding: vector_159\n",
      "\n",
      "st_id: 634\n",
      "Texto: So let's start there.\n",
      "Palabras: 4\n",
      "Embedding: vector_109\n",
      "\n",
      "st_id: 635\n",
      "Texto: So there's a lot of, that's a great point.\n",
      "Palabras: 9\n",
      "Embedding: vector_859\n",
      "\n",
      "st_id: 636\n",
      "Texto: So not chasing perfect.\n",
      "Palabras: 4\n",
      "Embedding: vector_83\n",
      "\n",
      "st_id: 637\n",
      "Texto: There's a lot of things that most of the world agrees on.\n",
      "Palabras: 12\n",
      "Embedding: vector_371\n",
      "\n",
      "st_id: 638\n",
      "Texto: Yeah, let's start there.\n",
      "Palabras: 4\n",
      "Embedding: vector_342\n",
      "\n",
      "st_id: 639\n",
      "Texto: Let's start there.\n",
      "Palabras: 3\n",
      "Embedding: vector_930\n",
      "\n",
      "st_id: 640\n",
      "Texto: And then once we start there, we'll also get into the habit of having these kind of conversations about, okay, what else should we put in here and have these discussions?\n",
      "Palabras: 31\n",
      "Embedding: vector_356\n",
      "\n",
      "st_id: 641\n",
      "Texto: This should be a gradual process then.\n",
      "Palabras: 7\n",
      "Embedding: vector_1\n",
      "\n",
      "st_id: 642\n",
      "Texto: Great, so, but that also means describing these things and describing it to a machine.\n",
      "Palabras: 15\n",
      "Embedding: vector_373\n",
      "\n",
      "st_id: 643\n",
      "Texto: So one thing, we had a few conversations with Stephen Wolfram.\n",
      "Palabras: 11\n",
      "Embedding: vector_521\n",
      "\n",
      "st_id: 644\n",
      "Texto: I'm not sure if you're familiar with Stephen.\n",
      "Palabras: 8\n",
      "Embedding: vector_134\n",
      "\n",
      "st_id: 645\n",
      "Texto: Oh yeah, I know him quite well.\n",
      "Palabras: 7\n",
      "Embedding: vector_291\n",
      "\n",
      "st_id: 646\n",
      "Texto: So he is, he works with a bunch of things, but cellular automata, these simple computable things, these computation systems.\n",
      "Palabras: 20\n",
      "Embedding: vector_0\n",
      "\n",
      "st_id: 647\n",
      "Texto: And he kind of mentioned that, we probably have already within these systems already something that's AGI, meaning like we just don't know it because we can't talk to it.\n",
      "Palabras: 30\n",
      "Embedding: vector_544\n",
      "\n",
      "st_id: 648\n",
      "Texto: So if you give me this chance to try to at least form a question out of this is, I think it's an interesting idea to think that we can have intelligent systems, but we don't know how to describe something to them and they can't communicate with us.\n",
      "Palabras: 49\n",
      "Embedding: vector_637\n",
      "\n",
      "st_id: 649\n",
      "Texto: I know you're doing a little bit of work in explainable AI, trying to get AI to explain itself.\n",
      "Palabras: 19\n",
      "Embedding: vector_43\n",
      "\n",
      "st_id: 650\n",
      "Texto: So what are your thoughts of natural language processing or some kind of other communication?\n",
      "Palabras: 15\n",
      "Embedding: vector_251\n",
      "\n",
      "st_id: 651\n",
      "Texto: How does the AI explain something to us?\n",
      "Palabras: 8\n",
      "Embedding: vector_456\n",
      "\n",
      "st_id: 652\n",
      "Texto: How do we explain something to it, to machines?\n",
      "Palabras: 9\n",
      "Embedding: vector_303\n",
      "\n",
      "st_id: 653\n",
      "Texto: Or you think of it differently?\n",
      "Palabras: 6\n",
      "Embedding: vector_746\n",
      "\n",
      "st_id: 654\n",
      "Texto: So there are two separate parts to your question there.\n",
      "Palabras: 10\n",
      "Embedding: vector_593\n",
      "\n",
      "st_id: 655\n",
      "Texto: One of them has to do with communication, which is super interesting, I'll get to that in a sec.\n",
      "Palabras: 19\n",
      "Embedding: vector_993\n",
      "\n",
      "st_id: 656\n",
      "Texto: The other is whether we already have AGI but we just haven't noticed it there.\n",
      "Palabras: 15\n",
      "Embedding: vector_179\n",
      "\n",
      "st_id: 657\n",
      "Texto: Right.\n",
      "Palabras: 1\n",
      "Embedding: vector_688\n",
      "\n",
      "st_id: 658\n",
      "Texto: There I beg to differ.\n",
      "Palabras: 5\n",
      "Embedding: vector_696\n",
      "\n",
      "st_id: 659\n",
      "Texto: I don't think there's anything in any cellular automaton or anything or the internet itself or whatever that has artificial general intelligence and that it can really do exactly everything we humans can do better.\n",
      "Palabras: 35\n",
      "Embedding: vector_286\n",
      "\n",
      "st_id: 660\n",
      "Texto: I think the day that happens, when that happens, we will very soon notice, we'll probably notice even before because in a very, very big way.\n",
      "Palabras: 26\n",
      "Embedding: vector_822\n",
      "\n",
      "st_id: 661\n",
      "Texto: But for the second part, though.\n",
      "Palabras: 6\n",
      "Embedding: vector_182\n",
      "\n",
      "st_id: 662\n",
      "Texto: Wait, can I ask, sorry.\n",
      "Palabras: 5\n",
      "Embedding: vector_839\n",
      "\n",
      "st_id: 663\n",
      "Texto: So, because you have this beautiful way to formulating consciousness as information processing, and you can think of intelligence as information processing, and you can think of the entire universe as these particles and these systems roaming around that have this information processing power.\n",
      "Palabras: 44\n",
      "Embedding: vector_688\n",
      "\n",
      "st_id: 664\n",
      "Texto: You don't think there is something with the power to process information in the way that we human beings do that's out there that needs to be sort of connected to.\n",
      "Palabras: 31\n",
      "Embedding: vector_346\n",
      "\n",
      "st_id: 665\n",
      "Texto: It seems a little bit philosophical, perhaps, but there's something compelling to the idea that the power is already there, which the focus should be more on being able to communicate with it.\n",
      "Palabras: 33\n",
      "Embedding: vector_694\n",
      "\n",
      "st_id: 666\n",
      "Texto: Well, I agree that in a certain sense, the hardware processing power is already out there because our universe itself can think of it as being a computer already, right?\n",
      "Palabras: 30\n",
      "Embedding: vector_28\n",
      "\n",
      "st_id: 667\n",
      "Texto: It's constantly computing what water waves, how it devolved the water waves in the River Charles and how to move the air molecules around.\n",
      "Palabras: 24\n",
      "Embedding: vector_997\n",
      "\n",
      "st_id: 668\n",
      "Texto: Seth Lloyd has pointed out, my colleague here, that you can even in a very rigorous way think of our entire universe as being a quantum computer.\n",
      "Palabras: 27\n",
      "Embedding: vector_699\n",
      "\n",
      "st_id: 669\n",
      "Texto: It's pretty clear that our universe supports this amazing processing power because you can even, within this physics computer that we live in, right?\n",
      "Palabras: 24\n",
      "Embedding: vector_606\n",
      "\n",
      "st_id: 670\n",
      "Texto: We can even build actual laptops and stuff, so clearly the power is there.\n",
      "Palabras: 14\n",
      "Embedding: vector_430\n",
      "\n",
      "st_id: 671\n",
      "Texto: It's just that most of the compute power that nature has, it's, in my opinion, kind of wasting on boring stuff like simulating yet another ocean wave somewhere where no one is even looking, right?\n",
      "Palabras: 35\n",
      "Embedding: vector_235\n",
      "\n",
      "st_id: 672\n",
      "Texto: So in a sense, what life does, what we are doing when we build computers is we're rechanneling all this compute that nature is doing anyway into doing things that are more interesting than just yet another ocean wave, and let's do something cool here.\n",
      "Palabras: 45\n",
      "Embedding: vector_303\n",
      "\n",
      "st_id: 673\n",
      "Texto: So the raw hardware power is there, for sure, but then even just computing what's going to happen for the next five seconds in this water bottle, takes a ridiculous amount of compute if you do it on a human computer.\n",
      "Palabras: 41\n",
      "Embedding: vector_968\n",
      "\n",
      "st_id: 674\n",
      "Texto: This water bottle just did it.\n",
      "Palabras: 6\n",
      "Embedding: vector_464\n",
      "\n",
      "st_id: 675\n",
      "Texto: But that does not mean that this water bottle has AGI because AGI means it should also be able to, like I've written my book, done this interview.\n",
      "Palabras: 28\n",
      "Embedding: vector_328\n",
      "\n",
      "st_id: 676\n",
      "Texto: And I don't think it's just communication problems.\n",
      "Palabras: 8\n",
      "Embedding: vector_234\n",
      "\n",
      "st_id: 677\n",
      "Texto: I don't really think it can do it.\n",
      "Palabras: 8\n",
      "Embedding: vector_569\n",
      "\n",
      "st_id: 678\n",
      "Texto: Although Buddhists say when they watch the water and that there is some beauty, that there's some depth and beauty in nature that they can communicate with.\n",
      "Palabras: 27\n",
      "Embedding: vector_658\n",
      "\n",
      "st_id: 679\n",
      "Texto: Communication is also very important though because I mean, look, part of my job is being a teacher.\n",
      "Palabras: 18\n",
      "Embedding: vector_345\n",
      "\n",
      "st_id: 680\n",
      "Texto: And I know some very intelligent professors even who just have a bit of hard time communicating.\n",
      "Palabras: 17\n",
      "Embedding: vector_52\n",
      "\n",
      "st_id: 681\n",
      "Texto: They come up with all these brilliant ideas, but to communicate with somebody else, you have to also be able to simulate their own mind.\n",
      "Palabras: 25\n",
      "Embedding: vector_671\n",
      "\n",
      "st_id: 682\n",
      "Texto: Yes, empathy.\n",
      "Palabras: 2\n",
      "Embedding: vector_379\n",
      "\n",
      "st_id: 683\n",
      "Texto: Build well enough and understand model of their mind that you can say things that they will understand.\n",
      "Palabras: 18\n",
      "Embedding: vector_855\n",
      "\n",
      "st_id: 684\n",
      "Texto: And that's quite difficult.\n",
      "Palabras: 4\n",
      "Embedding: vector_475\n",
      "\n",
      "st_id: 685\n",
      "Texto: And that's why today it's so frustrating if you have a computer that makes some cancer diagnosis and you ask it, well, why are you saying I should have this surgery?\n",
      "Palabras: 31\n",
      "Embedding: vector_662\n",
      "\n",
      "st_id: 686\n",
      "Texto: And if it can only reply, I was trained on five terabytes of data and this is my diagnosis, boop, boop, beep, beep.\n",
      "Palabras: 23\n",
      "Embedding: vector_350\n",
      "\n",
      "st_id: 687\n",
      "Texto: It doesn't really instill a lot of confidence, right?\n",
      "Palabras: 9\n",
      "Embedding: vector_325\n",
      "\n",
      "st_id: 688\n",
      "Texto: So I think we have a lot of work to do on communication there.\n",
      "Palabras: 14\n",
      "Embedding: vector_940\n",
      "\n",
      "st_id: 689\n",
      "Texto: So what kind of, I think you're doing a little bit of work in explainable AI.\n",
      "Palabras: 16\n",
      "Embedding: vector_384\n",
      "\n",
      "st_id: 690\n",
      "Texto: What do you think are the most promising avenues?\n",
      "Palabras: 9\n",
      "Embedding: vector_732\n",
      "\n",
      "st_id: 691\n",
      "Texto: Is it mostly about sort of the Alexa problem of natural language processing of being able to actually use human interpretable methods of communication?\n",
      "Palabras: 24\n",
      "Embedding: vector_563\n",
      "\n",
      "st_id: 692\n",
      "Texto: So being able to talk to a system and it talk back to you, or is there some more fundamental problems to be solved?\n",
      "Palabras: 24\n",
      "Embedding: vector_556\n",
      "\n",
      "st_id: 693\n",
      "Texto: I think it's all of the above.\n",
      "Palabras: 7\n",
      "Embedding: vector_557\n",
      "\n",
      "st_id: 694\n",
      "Texto: The natural language processing is obviously important, but there are also more nerdy fundamental problems.\n",
      "Palabras: 15\n",
      "Embedding: vector_953\n",
      "\n",
      "st_id: 695\n",
      "Texto: Like if you take, you play chess?\n",
      "Palabras: 7\n",
      "Embedding: vector_804\n",
      "\n",
      "st_id: 696\n",
      "Texto: Of course, I'm Russian.\n",
      "Palabras: 4\n",
      "Embedding: vector_745\n",
      "\n",
      "st_id: 697\n",
      "Texto: I have to.\n",
      "Palabras: 3\n",
      "Embedding: vector_772\n",
      "\n",
      "st_id: 698\n",
      "Texto: You speak Russian?\n",
      "Palabras: 3\n",
      "Embedding: vector_259\n",
      "\n",
      "st_id: 699\n",
      "Texto: Yes, I speak Russian.\n",
      "Palabras: 4\n",
      "Embedding: vector_311\n",
      "\n",
      "st_id: 700\n",
      "Texto: Excellent, I didn't know.\n",
      "Palabras: 4\n",
      "Embedding: vector_612\n",
      "\n",
      "st_id: 701\n",
      "Texto: When did you learn Russian?\n",
      "Palabras: 5\n",
      "Embedding: vector_832\n",
      "\n",
      "st_id: 702\n",
      "Texto: I speak very bad Russian, I'm only an autodidact, but I bought a book, Teach Yourself Russian, read a lot, but it was very difficult.\n",
      "Palabras: 25\n",
      "Embedding: vector_533\n",
      "\n",
      "st_id: 703\n",
      "Texto: Wow.\n",
      "Palabras: 1\n",
      "Embedding: vector_480\n",
      "\n",
      "st_id: 704\n",
      "Texto: That's why I speak so bad.\n",
      "Palabras: 6\n",
      "Embedding: vector_499\n",
      "\n",
      "st_id: 705\n",
      "Texto: How many languages do you know?\n",
      "Palabras: 6\n",
      "Embedding: vector_769\n",
      "\n",
      "st_id: 706\n",
      "Texto: Wow, that's really impressive.\n",
      "Palabras: 4\n",
      "Embedding: vector_917\n",
      "\n",
      "st_id: 707\n",
      "Texto: I don't know, my wife has some calculation, but my point was, if you play chess, have you looked at the AlphaZero games?\n",
      "Palabras: 23\n",
      "Embedding: vector_517\n",
      "\n",
      "st_id: 708\n",
      "Texto: The actual games, no.\n",
      "Palabras: 4\n",
      "Embedding: vector_843\n",
      "\n",
      "st_id: 709\n",
      "Texto: Check it out, some of them are just mind blowing, really beautiful.\n",
      "Palabras: 12\n",
      "Embedding: vector_693\n",
      "\n",
      "st_id: 710\n",
      "Texto: And if you ask, how did it do that?\n",
      "Palabras: 9\n",
      "Embedding: vector_297\n",
      "\n",
      "st_id: 711\n",
      "Texto: You go talk to Demis Hassabis, I know others from DeepMind, all they'll ultimately be able to give you is big tables of numbers, matrices, that define the neural network.\n",
      "Palabras: 30\n",
      "Embedding: vector_720\n",
      "\n",
      "st_id: 712\n",
      "Texto: And you can stare at these tables of numbers till your face turn blue, and you're not gonna understand much about why it made that move.\n",
      "Palabras: 26\n",
      "Embedding: vector_272\n",
      "\n",
      "st_id: 713\n",
      "Texto: And even if you have natural language processing that can tell you in human language about, oh, five, seven, points, two, eight, still not gonna really help.\n",
      "Palabras: 27\n",
      "Embedding: vector_89\n",
      "\n",
      "st_id: 714\n",
      "Texto: So I think there's a whole spectrum of fun challenges that are involved in taking a computation that does intelligent things and transforming it into something equally good, equally intelligent, but that's more understandable.\n",
      "Palabras: 34\n",
      "Embedding: vector_435\n",
      "\n",
      "st_id: 715\n",
      "Texto: And I think that's really valuable because I think as we put machines in charge of ever more infrastructure in our world, the power grid, the trading on the stock market, weapon systems and so on, it's absolutely crucial that we can trust these AIs to do all we want.\n",
      "Palabras: 50\n",
      "Embedding: vector_468\n",
      "\n",
      "st_id: 716\n",
      "Texto: And trust really comes from understanding in a very fundamental way.\n",
      "Palabras: 11\n",
      "Embedding: vector_627\n",
      "\n",
      "st_id: 717\n",
      "Texto: And that's why I'm working on this, because I think the more, if we're gonna have some hope of ensuring that machines have adopted our goals and that they're gonna retain them, that kind of trust, I think, needs to be based on things you can actually understand, preferably even improve theorems on.\n",
      "Palabras: 53\n",
      "Embedding: vector_475\n",
      "\n",
      "st_id: 718\n",
      "Texto: Even with a self driving car, right?\n",
      "Palabras: 7\n",
      "Embedding: vector_719\n",
      "\n",
      "st_id: 719\n",
      "Texto: If someone just tells you it's been trained on tons of data and it never crashed, it's less reassuring than if someone actually has a proof.\n",
      "Palabras: 26\n",
      "Embedding: vector_189\n",
      "\n",
      "st_id: 720\n",
      "Texto: Maybe it's a computer verified proof, but still it says that under no circumstances is this car just gonna swerve into oncoming traffic.\n",
      "Palabras: 23\n",
      "Embedding: vector_970\n",
      "\n",
      "st_id: 721\n",
      "Texto: And that kind of information helps to build trust and helps build the alignment of goals, at least awareness that your goals, your values are aligned.\n",
      "Palabras: 26\n",
      "Embedding: vector_406\n",
      "\n",
      "st_id: 722\n",
      "Texto: And I think even in the very short term, if you look at how, you know, today, right?\n",
      "Palabras: 18\n",
      "Embedding: vector_614\n",
      "\n",
      "st_id: 723\n",
      "Texto: This absolutely pathetic state of cybersecurity that we have, where is it?\n",
      "Palabras: 12\n",
      "Embedding: vector_658\n",
      "\n",
      "st_id: 724\n",
      "Texto: Three billion Yahoo accounts we can't pack, almost every American's credit card and so on.\n",
      "Palabras: 15\n",
      "Embedding: vector_451\n",
      "\n",
      "st_id: 725\n",
      "Texto: Why is this happening?\n",
      "Palabras: 4\n",
      "Embedding: vector_232\n",
      "\n",
      "st_id: 726\n",
      "Texto: It's ultimately happening because we have software that nobody fully understood how it worked.\n",
      "Palabras: 14\n",
      "Embedding: vector_502\n",
      "\n",
      "st_id: 727\n",
      "Texto: That's why the bugs hadn't been found, right?\n",
      "Palabras: 8\n",
      "Embedding: vector_494\n",
      "\n",
      "st_id: 728\n",
      "Texto: And I think AI can be used very effectively for offense, for hacking, but it can also be used for defense.\n",
      "Palabras: 21\n",
      "Embedding: vector_52\n",
      "\n",
      "st_id: 729\n",
      "Texto: Hopefully automating verifiability and creating systems that are built in different ways so you can actually prove things about them.\n",
      "Palabras: 20\n",
      "Embedding: vector_211\n",
      "\n",
      "st_id: 730\n",
      "Texto: And it's important.\n",
      "Palabras: 3\n",
      "Embedding: vector_636\n",
      "\n",
      "st_id: 731\n",
      "Texto: So speaking of software that nobody understands how it works, of course, a bunch of people ask about your paper, about your thoughts of why does deep and cheap learning work so well?\n",
      "Palabras: 33\n",
      "Embedding: vector_525\n",
      "\n",
      "st_id: 732\n",
      "Texto: That's the paper.\n",
      "Palabras: 3\n",
      "Embedding: vector_781\n",
      "\n",
      "st_id: 733\n",
      "Texto: But what are your thoughts on deep learning?\n",
      "Palabras: 8\n",
      "Embedding: vector_901\n",
      "\n",
      "st_id: 734\n",
      "Texto: These kind of simplified models of our own brains have been able to do some successful perception work, pattern recognition work, and now with AlphaZero and so on, do some clever things.\n",
      "Palabras: 32\n",
      "Embedding: vector_570\n",
      "\n",
      "st_id: 735\n",
      "Texto: What are your thoughts about the promise limitations of this piece?\n",
      "Palabras: 11\n",
      "Embedding: vector_608\n",
      "\n",
      "st_id: 736\n",
      "Texto: Great, I think there are a number of very important insights, very important lessons we can always draw from these kinds of successes.\n",
      "Palabras: 23\n",
      "Embedding: vector_337\n",
      "\n",
      "st_id: 737\n",
      "Texto: One of them is when you look at the human brain, you see it's very complicated, 10th of 11 neurons, and there are all these different kinds of neurons and yada, yada, and there's been this long debate about whether the fact that we have dozens of different kinds is actually necessary for intelligence.\n",
      "Palabras: 54\n",
      "Embedding: vector_54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simular las columnas ep_id y st_id basándonos en la estructura del dataset\n",
    "processed_data = []\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    ep_id = row['id']  # Asignamos el ID del episodio\n",
    "    text = row['text']  # El texto completo del episodio\n",
    "\n",
    "    # Dividir el texto en oraciones usando sent_tokenize\n",
    "    sentences = sent_tokenize(str(text))  # Aseguramos que 'text' sea una cadena\n",
    "    for st_id, sentence in enumerate(sentences, start=1):\n",
    "        processed_data.append({\n",
    "            'ep_id': ep_id,\n",
    "            'st_id': st_id,\n",
    "            'text': sentence,\n",
    "            'emb': None  # Placeholder para embeddings\n",
    "        })\n",
    "\n",
    "# Crear un nuevo DataFrame con la estructura ep_id, st_id, text, emb\n",
    "df = pd.DataFrame(processed_data)\n",
    "\n",
    "# Calcular conteo de palabras para cada oración\n",
    "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Simular embeddings (puedes reemplazar esto con un modelo real)\n",
    "df['emb'] = df['text'].apply(lambda x: f\"vector_{hash(x) % 1000}\")\n",
    "\n",
    "# Mostrar los resultados para un episodio específico (por ejemplo, ep_id = 1)\n",
    "episodio_id = 1  # Cambia este valor según el episodio que desees analizar\n",
    "episodio = df[df['ep_id'] == episodio_id]\n",
    "\n",
    "# Imprimir los resultados en forma vertical\n",
    "print(f\"Resultados para el episodio {episodio_id}:\")\n",
    "for _, row in episodio.iterrows():\n",
    "    print(f\"st_id: {row['st_id']}\")\n",
    "    print(f\"Texto: {row['text']}\")\n",
    "    print(f\"Palabras: {row['word_count']}\")\n",
    "    print(f\"Embedding: {row['emb']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T13:29:14.800799Z",
     "iopub.status.busy": "2025-01-14T13:29:14.800384Z",
     "iopub.status.idle": "2025-01-14T13:32:36.801110Z",
     "shell.execute_reply": "2025-01-14T13:32:36.799563Z",
     "shell.execute_reply.started": "2025-01-14T13:29:14.800765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Collecting torch>=1.11.0\n",
      "  Downloading torch-2.5.1-cp310-cp310-win_amd64.whl (203.1 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting huggingface-hub>=0.20.0\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.15.1)\n",
      "Collecting Pillow\n",
      "  Downloading pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Collecting transformers<5.0.0,>=4.41.0\n",
      "  Downloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Collecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Installing collected packages: pyyaml, fsspec, filelock, mpmath, MarkupSafe, huggingface-hub, tokenizers, sympy, safetensors, networkx, jinja2, transformers, torch, Pillow, sentence-transformers\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.1.0 filelock-3.16.1 fsspec-2024.12.0 huggingface-hub-0.27.1 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 pyyaml-6.0.2 safetensors-0.5.2 sentence-transformers-3.3.1 sympy-1.13.1 tokenizers-0.21.0 torch-2.5.1 transformers-4.48.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando embeddings para cada sección del texto. Esto puede tomar un tiempo...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cargar el modelo preentrenado de SentenceTransformers\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Puedes elegir otro modelo si es necesario\n",
    "\n",
    "# Simular las columnas ep_id y st_id basándonos en la estructura del dataset\n",
    "processed_data = []\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    ep_id = row['id']  # Asignamos el ID del episodio\n",
    "    text = row['text']  # El texto completo del episodio\n",
    "\n",
    "    # Dividir el texto en oraciones usando sent_tokenize\n",
    "    sentences = sent_tokenize(str(text))  # Aseguramos que 'text' sea una cadena\n",
    "    for st_id, sentence in enumerate(sentences, start=1):\n",
    "        processed_data.append({\n",
    "            'ep_id': ep_id,\n",
    "            'st_id': st_id,\n",
    "            'text': sentence\n",
    "        })\n",
    "\n",
    "# Crear un nuevo DataFrame con la estructura ep_id, st_id, text\n",
    "df = pd.DataFrame(processed_data)\n",
    "\n",
    "# Calcular conteo de palabras para cada oración\n",
    "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Generar embeddings reales para cada texto usando el modelo\n",
    "print(\"Generando embeddings para cada sección del texto. Esto puede tomar un tiempo...\")\n",
    "df['emb'] = df['text'].apply(lambda x: model.encode(x).tolist())  # Convertimos a lista para facilitar el uso\n",
    "\n",
    "# Mostrar una muestra del DataFrame procesado con embeddings\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4750111,
     "sourceId": 8200261,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
